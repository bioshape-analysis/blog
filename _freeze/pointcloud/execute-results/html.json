{
  "hash": "cedab5247ac32c2ed17242328a5574e0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Introduction\njupyter: python3\n---\n\n\n\n\n\nIn the context of cryo-EM, many computationaly exhaustive methods rely on simpler representations of cryo-EM density maps to overcome their scalability challenges. There are many choices to the form of the simpler representation, such as vectors (ref vesper) or mixture of gussians (ref). In this post we discuss a format which is probably the simplest and that is using a set of points (called point cloud). \n\nThis problem can be formulated in a much more general sense rather than cryo-EM. In this sense we are given a probability distribution over $\\mathbb{R}^3$ and we want to generate a set of 3D points that represent this distribution. The naive approach to find such a point cloud is to just sample points from the distribution. Although this approach is guaranteed to find a good representation, it needs lots of points to cover the distribution evenly. Since methods used in this field can be computationally intensive with cubic or higher time complexity, generating a point cloud that covers the give distribution with a smaller point cloud could lead to a significant improvement in their runtime.\n\nIn this approach, we present two methods for generating a point cloud from a cryo-EM density map or a distribution in general. The first one is based on the Topological Representing Network (TRN) (ref) and the second one combines the usage the Optimal Transport (OT) theory and and some computational geometry object named Centroidal Vornoi Tessellation (CVT).\n\n\n## Data\nFor the sake of simplicity in this post we assume we are given a primal distribution over $\\mathbb{R}^2$. As an example we will work on multivariate gaussian distribution that it's domain is limited to $[0, 1]^2$. The following code prepares and illustrates the pdf of the example distribution.\n\n::: {#26693096 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport scipy as scp\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\n\n\nmean = np.array([0,0])\ncov = np.array([[0.5, 0.25], [0.25, 0.5]])\ndistr = scp.stats.multivariate_normal(cov = cov, mean = mean, seed = 1)\n\n\nfig, ax = plt.subplots(figsize=(8,8))\nim = ax.imshow([[distr.pdf([i/100,j/100]) for i in range(100,-100,-1)] for j in range(-100,100)], extent=[-1, 1, -1, 1])\ncbar = ax.figure.colorbar(im, ax=ax)\nplt.title(\"The pdf of our primal distribution\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-2-output-1.png){width=644 height=611}\n:::\n:::\n\n\nBoth of the methods that we are going to cover are iterative methods. For generating a point cloud of size $n$, they begin by randomly sampling $n$ points and refining it over iterations. To make the illustration interesting we used a uniform point cloud for initial samples. We use $n=200$ in our examples.\n\n::: {#1f158a87 .cell execution_count=2}\n``` {.python .cell-code}\ndef sampler(rvs):\n    while True:\n        sample = rvs(1)\n        if abs(sample[0]) > 1 or abs(sample[1]) > 1:\n            continue\n        return sample\n\n# The commented code will begin with initial samples drawn from the primal distribution instead of uniform\n\n# initial_samples = []\n# while len(initial_samples) < 200:\n#     sample = sampler(distr.rvs)\n#     initial_samples.append(list(sample))\n# initial_samples = np.array(initial_samples)\ninitial_samples = np.random.uniform(-1,1,(200,2))\n\nl = list(zip(*initial_samples))\nx = list(l[0])\ny = list(l[1])\n\nfig, ax = plt.subplots(figsize=(8,8))\nax.scatter(x, y)\nax.plot((-1,-1), (-1,1), 'k-')\nax.plot((-1,1), (-1,-1), 'k-')\nax.plot((1,1), (1,-1), 'k-')\nax.plot((-1,1), (1,1), 'k-')\nplt.ylim(-1.1,1.1)\nplt.xlim(-1.1,1.1)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-3-output-1.png){width=665 height=633}\n:::\n:::\n\n\n# Topology Representing Networks (TRN)\n## Summary\nThis method is an iterative method relies on randomly sampling an initial point cloud $r_m(0)_{i=1,\\dots,n}$ from the given probability distribution $p$. At each step $t$, we sample a new point ($r_t$) from $p$, and compute the distnace from points in $r_m(t)$ to $r_t$ and rank them from zero (closest) to $n-1$ (called $k_m$). Then we update the position of points based on:\n$$r_m(t+1) = r_m(t) + \\epsilon(t)exp(-k_m/\\lambda(t))(r_t - r_m(t)),$$\n$$\\epsilon(t) = \\epsilon_0(\\frac{\\epsilon_f}{\\epsilon_0})^{t/t_f},$$\n$$\\lambda(t) = \\lambda_0(\\frac{\\lambda_f}{\\lambda_0})^{t/t_f}$$\nThese fomulas are designed in a way that makes the movement of points slower as the number of iteration increases.\n\n::: {#d6528e04 .cell execution_count=3}\n``` {.python .cell-code}\ne0=2\nef=0.5\nl0=3\nlf=0.25\ntf=10000\n```\n:::\n\n\n::: {#8db8493d .cell execution_count=4}\n``` {.python .cell-code}\nfig, axs = plt.subplots(2, 2, figsize=(10,10))\n\nr = initial_samples\nfor t in range(tf):\n    rt = sampler(distr.rvs)\n    dist2 = ((rt - r)**2).sum(1) \n    order = dist2.argsort()\n    rank = order.argsort().reshape(-1,1)\n    l = l0*(lf/l0)**(t/tf)\n    e = e0*(ef/e0)**(t/tf)\n    r = r + e*np.exp(-rank/l)*(rt-r)\n    \n    if (t+1)%2500 == 0:\n        l = list(zip(*r))\n        x = list(l[0])\n        y = list(l[1])\n\n        index = t//2500\n        axs[index//2][index%2].scatter(x, y, s=10)\n        axs[index//2][index%2].title.set_text('Position of points after t=%d iterations'%(t+1,))\n        axs[index//2][index%2].plot((-1,-1), (-1,1), 'k-')\n        axs[index//2][index%2].plot((-1,1), (-1,-1), 'k-')\n        axs[index//2][index%2].plot((1,1), (1,-1), 'k-')\n        axs[index//2][index%2].plot((-1,1), (1,1), 'k-')\n        plt.ylim(-1.1,1.1)\n        plt.xlim(-1.1,1.1)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-5-output-1.png){width=813 height=801}\n:::\n:::\n\n\n# Centroidal Vornoi Tessellation (CVT)\nAlthough TRN is intuitive it doesn't minimize any specific objective function. Among the mtrics that can be to determine the distance between a point cloud and a continuous distribution the semidiscrete Wasserstein distance (based on the Optimal Transport theory (ref)) is of our interest. In other words we want a point cloud that minimizes the semidicrete Wasserestein distance to a given primal distribution. One can prove that such a point cloud forms a geometrical object named Centroidal Voronoi Tessellation (CVT) over the distribution. A CVT is a the Voronoi diagram generated by a point cloud such that each point is centroid and generator of it's Voronoi cell. Such a tessellation can be computed using Lloyd's iterations by alteranating between computing centroids and Voronoi cells.\n\n::: {#96276f3e .cell execution_count=5}\n``` {.python .cell-code}\ndef in_box(robots, bounding_box):\n    return np.logical_and(np.logical_and(bounding_box[0] <= robots[:, 0],\n                                         robots[:, 0] <= bounding_box[1]),\n                          np.logical_and(bounding_box[2] <= robots[:, 1],\n                                         robots[:, 1] <= bounding_box[3]))\n\n\ndef voronoi(robots, bounding_box):\n    i = in_box(robots, bounding_box)\n    points_center = robots[i, :]\n    points_left = np.copy(points_center)\n    points_left[:, 0] = bounding_box[0] - (points_left[:, 0] - bounding_box[0])\n    points_right = np.copy(points_center)\n    points_right[:, 0] = bounding_box[1] + (bounding_box[1] - points_right[:, 0])\n    points_down = np.copy(points_center)\n    points_down[:, 1] = bounding_box[2] - (points_down[:, 1] - bounding_box[2])\n    points_up = np.copy(points_center)\n    points_up[:, 1] = bounding_box[3] + (bounding_box[3] - points_up[:, 1])\n    points = np.append(points_center,\n                       np.append(np.append(points_left,\n                                           points_right,\n                                           axis=0),\n                                 np.append(points_down,\n                                           points_up,\n                                           axis=0),\n                                 axis=0),\n                       axis=0)\n    # Compute Voronoi\n    vor = scp.spatial.Voronoi(points)\n    # Filter regions and select corresponding points\n    regions = []\n    points_to_filter = [] # we'll need to gather points too\n    ind = np.arange(points.shape[0])\n    ind = np.expand_dims(ind,axis= 1)\n\n    for i,region in enumerate(vor.regions): # enumerate the regions\n        if not region: # nicer to skip the empty region altogether\n            continue\n\n        flag = True\n        for index in region:\n            if index == -1:\n                flag = False\n                break\n            else:\n                x = vor.vertices[index, 0]\n                y = vor.vertices[index, 1]\n                if not(bounding_box[0] - eps <= x and x <= bounding_box[1] + eps and\n                       bounding_box[2] - eps <= y and y <= bounding_box[3] + eps):\n                    flag = False\n                    break\n        if flag:\n            regions.append(region)\n\n            # find the point which lies inside\n            points_to_filter.append(vor.points[vor.point_region == i][0,:])\n\n    vor.filtered_points = np.array(points_to_filter)\n    vor.filtered_regions = regions\n    return vor\n\ndef centroid_region(vertices):\n    A = 0\n    C_x = 0\n    C_y = 0\n    for i in range(len(vertices)):\n        p = distr.pdf(vertices[i])\n        A += p\n        C_x += vertices[i,0] * p\n        C_y += vertices[i,1] * p\n        \n    C_x /= A\n    C_y /= A\n    return np.array([[C_x, C_y]]), A\n\ndef plot(r,ax):\n    vor = voronoi(r, bounding_box)\n    ax.set_xlim([-1.1, 1.1])\n    ax.set_ylim([-1.1, 1.1])\n    \n    for region in vor.filtered_regions:\n        vertices = vor.vertices[region + [region[0]], :]\n        ax.plot(vertices[:, 0], vertices[:, 1], 'k-')\n        \n    centroids = []\n    weights = []\n    \n    for region in vor.filtered_regions:\n        vertices = vor.vertices[region + [region[0]], :]\n        centroid, w = centroid_region(vertices)\n        centroids.append(list(centroid[0, :]))\n        weights.append(w)\n        \n    \n    ax.scatter(vor.filtered_points[:, 0], vor.filtered_points[:, 1], s=5, c='b', alpha=weights/max(weights))\n        \n    centroids = np.asarray(centroids)\n    return centroids, weights\n```\n:::\n\n\n::: {#5b4bf62e .cell execution_count=6}\n``` {.python .cell-code}\nimport sys\nbounding_box = np.array([-1., 1., -1., 1.]) \neps = sys.float_info.epsilon\nsamples = initial_samples\nfig, axs = plt.subplots(3,3,figsize=(12,12))\nfor i in range(9):\n    axs[i//3][i%3].title.set_text('iteration t=%d'%(i + 1,))\n    centroids, weights = plot(samples,axs[i//3][i%3])\n    samples = np.copy(centroids)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-7-output-1.png){width=962 height=949}\n:::\n:::\n\n\n# More Examples\n\n# Application on Cryo-EM\n\nIn this post we use a map of Escherichia coli ribosome (EMDB-1717). To download visit [Electron Microscopy Data Bank](https://www.ebi.ac.uk/emdb/EMD-1717) and selecet \"3D volume\" option under the \"Download\" dropdown. Then unzip the downloaded file and put it beside your code. In practice, before using either of these two methods we might threshold the density map to reduce the noice that affects the quality of point clouds.\n\n",
    "supporting": [
      "pointcloud_files"
    ],
    "filters": [],
    "includes": {}
  }
}