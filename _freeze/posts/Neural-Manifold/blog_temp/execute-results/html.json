{
  "hash": "a4d4f57e6cbbbb2bdf8f171e456cc024",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Understanding Animal Navigation Using Neural Manifolds With CEBRA\"\njupyter: python3\n\nauthor:\n  - name: \"Deven Shidfar\" \n    email: \"devenshidfar@math.ubc.ca\"\n    affiliations:\n      - name: KDD Group\n        url: \"https://rtviii.xyz/\"\n      - name: NC4 Lab\n        url: https://www.nc4.sbme.ubc.ca/\n      - name: Department of Mathematics, UBC\n        url: \"https://www.math.ubc.ca/\"\n      - name: Department of Biomedical Engineering, UBC\n        url: https://bme.ubc.ca/\n\ndate: \"September 18, 2024\"\ncategories: [biology, bioinformatics, mathematics, biomedical engineering, neuroscience]    \n\ncallout-icon: false\nformat:\n  html:\n    code-fold: true\nbibliography: bibliography.bib\n\nexecute:\n  echo: true\n  freeze: auto\n  warning: false\n\n---\n\n\n## Problem Description\n\nSeeing, hearing, touching – every moment, our brain receives numerous sensory inputs. How does it organize this wealth of information and extract relevant details? We know that the brain forms a coherent neural representation of the external world, known as the **cognitive map** (Tolman, 1948), formed by the combined firing activity of neurons in the hippocampal formation. For example, **place cells** are neurons that fire when a rat is at a particular location (Moser et al., 2008). Together, the activity of hundreds of these place cells can be modeled as a continuous surface—a *manifold*—where points on the manifold correspond to the rat’s location in physical space. Essentially, the rat is building an internal cognitive map of its environment.\n\nMore specifically, the hippocampus plays a central role in this process by using **path integration** to track the animal’s position through various **idiothetic** (self-motion) cues, such as optic flow, vestibular inputs, and proprioception. **Manifold learning** has emerged as a powerful technique for mapping complex, high-dimensional neural data onto lower-dimensional geometric representations (Mitchell-Heggs et al., 2023; Schneider et al., 2023; Chaudhuri et al., 2019). Until now, it has not been feasible to learn these manifolds “online”—i.e., during the experiment itself. Doing so would enable **closed-loop** experiments, allowing immediate feedback to the animal based on its internal representation, and letting us probe how these representations are formed and maintained in real-time.\n\n**The question then arises:** How can we manipulate hippocampal neurons by presenting conflicting visual cues? By studying what happens when we perturb normal self-motion cues and observing changes in the brain’s navigation system, we can better understand how animals navigate and form their internal maps. This blog focuses on experiments conducted in \"Control and recalibration of path integration in place cells using optic flow\" (@madhav2024) and \"Recalibration of path integration in hippocampal place cells\" (@jayakumar2019).\n\n## Experimental Setup\n\nIn (@madhav2024; @jayakumar2019), Dr. Madhav and colleagues designed experiments to investigate how optic flow cues influence hippocampal place cells in freely moving rats.\n\nTo understand place cells, consider a rat moving along a horizontal linear track. Suppose there are just **3** place cells: **Neuron 1** fires at the very left of the track, **Neuron 2** in the middle, and **Neuron 3** at the very right. (Insert figure!!!) As the rat moves, these cells fire in sequence, helping the rat construct an internal cognitive map of its environment.\n\n### The Dome Apparatus\n\nIn these experiments, rats ran on a circular platform surrounded by a hemispherical projection surface called the **Dome**.\n\n::: {#vr_dome .cell .figure}\n![Figure 1 - Virtual reality Dome apparatus. The rat runs on a circular platform surrounded by a hemispherical shell. A projector image reflects off a hemispherical mirror onto the inner surface of the shell, creating controlled visual stimuli.](images/dome_apparatus.jpeg){ width=80% }\n:::\n\nThis dome projected moving stripes, providing controlled optic flow cues. The movement of the stripes depended on the rat’s motion through a parameter called the **stripe gain** \\(\\mathcal{S}\\):\n\n- \\(\\mathcal{S} = 1\\): Stripes are stationary relative to the lab frame; the rat receives no conflicting cues.\n- \\(\\mathcal{S} > 1\\): Stripes move opposite to the rat’s direction, making it feel as if it’s moving faster than it really is.\n- \\(\\mathcal{S} < 1\\): Stripes move in the same direction but slower, making the rat feel as if it’s moving slower than it really is.\n\nElectrodes implanted into the **CA1 region** of the hippocampus of **male Evan’s rats** recorded spike-rate neural activity. From these data, Dr. Madhav and colleagues defined the **Hippocampal Gain** \\(\\mathcal{H}\\):\n\n$$\n\\mathcal{H} = \\frac{\\text{distance traveled in hippocampal reference frame}}{\\text{distance traveled in lab reference frame}}\n$$\n\n- \\(\\mathcal{H} = 1\\): The rat perceives its speed accurately.\n- \\(\\mathcal{H} > 1\\): The rat perceives itself as moving faster than it actually is.\n- \\(\\mathcal{H} < 1\\): The rat perceives itself as moving slower than it actually is.\n\nFor instance, if \\(\\mathcal{H} = 2\\), a place cell that normally fires once per lap will now fire twice per lap, reflecting the altered internal perception of movement speed.\n\n### Crux of the Problem\n\n**Method of Determining \\(\\mathcal{H}\\):** Traditionally, \\(\\mathcal{H}\\) is determined by analyzing the spatial periodicity of place cell firing over multiple laps using Fourier transforms (see @jayakumar2019; @madhav2024). Below is a figure showing the conventional spectral decoding approach:\n\n::: {#spectral_decode .cell .figure}\n![Figure 2 - Spectral decoding algorithm. As visual landmarks are presented and moved at an experimental gain \\(G\\), place fields reoccur at intervals determined by \\(G\\). The cell’s firing frequency over laps encodes this gain. (Figure adapted from the referenced studies.)](images/spectral_decode.jpeg){ width=100% }\n:::\n\nWhile this method works, it is cumbersome and lacks the temporal precision to decode \\(\\mathcal{H}\\) within individual laps. We seek a method that provides finer temporal resolution, allowing us to observe how \\(\\mathcal{H}\\) changes moment-to-moment. Additionally, the traditional method’s direct tie to spatial firing patterns makes it less flexible if we introduce more variables (e.g., an auditory cue) that might form more complex manifolds like a torus.\n\n**Manifold Learning to the Rescue:** Manifold learning could help us overcome these limitations by providing a way to \"decouple\" different neural representations. For example, consider introducing a second varying neural representation, such as an auditory cue \\(\\mathcal{A}\\), alongside the spatial information \\(\\mathcal{H}\\). The combined neural data might form a **torus** instead of a simple circle, where one dimension encodes \\(\\mathcal{H}\\) and the other encodes \\(\\mathcal{A}\\).\n\n::: {.grid}\n::: {.g-col-6}\n![](images/varying_spatial.jpg){width=100%}\n:::\n::: {.g-col-6}\n![](images/varying_audio.jpg){width=100%}\n:::\n:::\n:::\n\nThis approach allows us to potentially **decouple** and **decode** multiple representations from the manifold, providing a richer understanding of how the brain integrates various sensory inputs.\n\n## Main Goal\n\nOur main goal is to determine \\(\\mathcal{H}\\) without using Fourier transforms, aiming for a more temporally precise (within-lap) estimation. This would allow us to:\n\n- **Investigate how the rat’s velocity influences \\(\\mathcal{H}\\).**\n- **Examine how \\(\\mathcal{H}\\) fluctuates over the course of a single lap and its relation to other behavioral variables.**\n\nAnother major objective is to **decode \\(\\mathcal{H}\\) online**, providing real-time feedback during experiments to adjust conditions dynamically based on the animal’s internal state. To address these challenges, we turn to **CEBRA** (@schneider2023), a robust method for reliable neural manifold learning.\n\n## What is CEBRA?\n\n**CEBRA** (Contrastive Embedding for Balanced Representations of Activity) is a self-supervised learning algorithm designed to produce consistent, interpretable embeddings of high-dimensional neural recordings using auxiliary variables such as behavior or time. Unlike traditional dimensionality reduction methods like PCA, t-SNE, or UMAP, CEBRA excels at capturing temporal dynamics and ensuring consistency across different sessions or animals.\n\n### The Need for CEBRA\n\nIn neuroscience, understanding how neural populations encode behavior is a significant challenge. Traditional linear methods like PCA or even non-linear approaches like UMAP and t-SNE fall short because they:\n\n- **Fail to capture temporal dynamics:** These methods often ignore the temporal structure inherent in neural data.\n- **Lack consistency across sessions or animals:** Embeddings can vary significantly between different experimental conditions, making comparisons difficult.\n\n**CEBRA** addresses these limitations by using **contrastive learning** to structure the embedding space around auxiliary variables such as time, ensuring that temporally close data points are mapped close together and those far apart are separated.\n\n### How Does CEBRA Work?\n\nCEBRA uses a **convolutional neural network (CNN) encoder** trained with a **contrastive loss function** to produce a latent space. The algorithm identifies positive and negative pairs of data points based on temporal proximity:\n\n- **Positive pairs:** Data points that are temporally close.\n- **Negative pairs:** Data points that are temporally distant.\n\nThe contrastive loss function encourages the model to map positive pairs closer together and push negative pairs farther apart. The loss function is defined as:\n\n$$\n\\mathcal{L} = - \\log \\frac{e^{\\text{sim}(f(x), f(y^+)) / \\tau}}{e^{\\text{sim}(f(x), f(y^+)) / \\tau} + \\sum_{i=1}^{K} e^{\\text{sim}(f(x), f(y_i^-)) / \\tau}}\n$$\n\nWhere:\n\n- \\(f(x)\\) and \\(f(y)\\) are the encoded representations of the neural data after passing through the CNN.\n- \\(\\text{sim}(f(x), f(y))\\) represents a similarity measure between the two embeddings, implemented as **cosine similarity**.\n- \\(y^{+}\\) denotes the positive pair (similar in time to \\(x\\)).\n- \\(y_{i}^{-}\\) denotes the negative pairs (dissimilar in time to \\(x\\)).\n- \\(\\tau\\) is a temperature parameter that controls the sharpness of the distribution.\n\n### Key Features of CEBRA\n\n- **Nonlinear Embedding:** CEBRA can capture complex, nonlinear patterns in neural data.\n- **Consistency Across Sessions and Animals:** Embeddings are stable and comparable across different experimental conditions.\n- **Temporal Encoding:** Specifically designed to handle time-varying neural data, preserving temporal relationships in the latent space.\n\n### CEBRA Architecture\n\n::: {#cebra_pipeline .cell .figure}\n![Figure 3 - CEBRA Architecture. Neural spike data (time × neurons) enters a CNN encoder. Contrastive learning ensures that data points close in time map near each other in the embedding space. (Adapted from Schneider et al., 2023.)](images/CEBRA_pipeline.png){ width=100% }\n:::\n\nBy applying CEBRA, we aim to uncover the underlying **1D ring structure** representing the **hippocampal angle**. The embedding should form a continuous loop if it accurately reflects the rat’s internal navigation variable.\n\n## Persistent Homology\n\nTo confirm that the embedding forms a **1D ring**, we use **persistent homology**—a mathematical tool that quantifies topological features like loops in a point cloud at different scales.\n\n### What is Persistent Homology?\n\nPersistent homology analyzes the shape of data by building simplicial complexes (e.g., connections between points) and tracking how features like connected components and holes appear and persist as the scale changes. For a ring, the expected **Betti numbers** are:\n\n- \\(\\beta_0 = 1\\): One connected component.\n- \\(\\beta_1 = 1\\): One loop (our 1D hole).\n- \\(\\beta_2 = 0\\): No higher-dimensional voids.\n\n### Validating the 1D Ring Manifold\n\n::: {#persistent_homology .cell .figure}\n![Figure 4 - Persistent Homology. By tracking how topological features (loops, holes) persist across scales, we verify that the embedded manifold indeed forms a ring.](images/persistent_cohomology.jpeg){ width=80% }\n:::\n\nBelow is a visual illustrating Betti numbers for simple shapes:\n\n::: {#betti_numbers .cell .figure}\n![Figure 5 - Betti Numbers Illustrated. A circle has \\(\\beta_0=1\\) and \\(\\beta_1=1\\), confirming the presence of a single loop.](images/betti_numbers_illustrate.png){ width=80% }\n:::\n\nIf persistent homology analysis matches these expectations, it confirms that the neural data forms a ring manifold corresponding to the rat’s navigation variable.\n\n## SPUD Method: Spline Parameterization\n\nOnce we confirm that our data forms a ring, we need to parameterize it. We use the **SPUD method** (Spline Parameterization for Unsupervised Decoding) from @chaudhuri2019, which fits a spline to the point cloud on the manifold. This spline provides a continuous parameter—essentially an angle—along the ring.\n\n### Overview of the SPUD Method\n\nSPUD is a multi-step method designed to parameterize a neural manifold by fitting a spline that accurately traces the manifold's structure. The spline is defined by a set of points (knots) initialized using **k-medoids clustering** (@jin2011) and then refined by minimizing a loss function that balances distance, curvature, length, and density:\n\n$$\n\\text{cost} = \\text{dist} + \\text{curvature} + \\text{length} - \\log(\\text{density})\n$$\n\n### Natural Parameterization\n\nA **natural parameterization** ensures that equal distances along the spline correspond to equal changes in the latent variable. This is consistent with how neural systems typically encode variables uniformly. For example, in head direction cells, each angle is equally probable and encoded without bias. Similarly, in the hippocampal formation, no specific location in a non-biased circular maze should receive extra encoding resources.\n\n### Fitting the Spline\n\n::: {#hipp_angle_with_curve .cell .figure}\n![Figure 6 - Spline Fit on the CEBRA Embedding. The fitted spline (red) aligns with the hippocampal angle (color map), indicating that the embedding accurately represents the rat’s internal spatial variable.](images/hipp_angle.gif){ width=80% }\n:::\n\nWith an accurate spline parameterization, we can now decode \\(\\mathcal{H}\\) from the manifold.\n\n## Decoding Hippocampal Gain (\\(\\mathcal{H}\\)) From the Manifold\n\nWith the spline providing a continuous hippocampal angle, \\(\\mathcal{H}\\) can be decoded by comparing the rate of change of this angle to the rat’s actual physical movement:\n\n$$\n\\mathcal{H} = \\frac{d\\theta_{\\mathcal{H}}}{d\\theta_{\\mathcal{L}}}\n$$\n\nWhere:\n- \\(\\theta_{\\mathcal{H}}\\) is the change in the hippocampal angle from the manifold spline.\n- \\(\\theta_{\\mathcal{L}}\\) is the actual angle traveled by the rat in the lab frame.\n\nThis approach allows for a fine-grained, within-lap estimation of \\(\\mathcal{H}\\), providing insights into moment-to-moment updates of the internal cognitive map.\n\n## Results\n\nApplying this method to real experimental data from \"Control and recalibration of path integration in place cells\" (@madhav2024), we observed varying degrees of success across different trials.\n\n### Point Clouds and Parameterization\n\nSuccessful trials exhibit a clear **1D ring topology** in the CEBRA embedding, allowing accurate spline fitting and \\(\\mathcal{H}\\) decoding. Unsuccessful trials, often with fewer recorded neurons, fail to form a stable ring, leading to inaccurate \\(\\mathcal{H}\\) estimates.\n\n::: {#hipp_angle_with_curve2 .cell .figure}\n![Figure 7 - Embeddings for Successful and Unsuccessful Trials. (a) Session 50 and Session 36 show clear ring structures with accurate spline fits (red). (b) Session 26 and Session 29 lack a coherent ring, resulting in poor spline fits.](images/hipp_joined.jpg){ width=100% }\n:::\n\n### \\(\\mathcal{H}\\) Values\n\nWe compared manifold-decoded \\(\\mathcal{H}\\) (red) against the traditional Fourier-based \\(\\mathcal{H}\\) (blue) across different sessions:\n\n::: {.grid}\n::: {.g-col-6}\n**a. Session 50**\n![](images/H_session_50.png){width=100%}\n:::\n::: {.g-col-6}\n**b. Session 26**\n![](images/H_session_26.png){width=100%}\n:::\n\n::: {.g-col-6}\n**c. Session 36**\n![](images/H_session_36.png){width=100%}\n:::\n::: {.g-col-6}\n**d. Session 29**\n![](images/H_session_29.png){width=100%}\n:::\n:::\n\n::: {.cell .figure}\nFigure 8 - Plot of manifold-decoded gain (red) vs gain from traditional method (blue) for various sessions: (a) Session 50 and (c) Session 36 are successful trials; (b) Session 26 and (d) Session 29 are unsuccessful trials.\n:::\n\n### The \"Curse of Clusters\"\n\nWe identified that the number of recorded neurons significantly impacts the quality of the embedding and the accuracy of \\(\\mathcal{H}\\) decoding. To quantify embedding quality, we used the **Structure Index (SI)** score (@sebastian2022), which measures how well the hippocampal angle is distributed around the point cloud.\n\n- **High SI Scores (>0.85):** Correspond to successful trials with accurate \\(\\mathcal{H}\\) decoding.\n- **Low SI Scores (<0.85):** Correspond to unsuccessful trials with poor embeddings and inaccurate \\(\\mathcal{H}\\) estimates.\n\n::: {#curse_of_clusters .cell .figure}\n![Figure 9 - Number of Clusters (Neurons) vs. SI Score. A logistic fit demonstrates that trials with fewer than ~35 neurons have significantly lower SI scores, leading to poor \\(\\mathcal{H}\\) decoding accuracy.](images/Linear_and_logistic_fit.jpg){ width=100% }\n:::\n\nThis phenomenon, termed the \"curse of clusters,\" indicates that a minimum number of neurons (~35) is required to form a stable manifold and achieve accurate \\(\\mathcal{H}\\) decoding.\n\n### Decoding Error\n\nWe also analyzed the relationship between the number of neurons and the mean \\(\\mathcal{H}\\) decoding error:\n\n$$\n\\text{Mean } \\mathcal{H} \\text{ Decode Error} = \\sum_{i} \\left( \\mathcal{H}_{\\text{decode}}[i] - \\mathcal{H}_{\\text{traditional}}[i] \\right)\n$$\n\n::: {#decoding_error .cell .figure}\n![Figure 10 - Number of Clusters (Neurons) vs. Mean \\(\\mathcal{H}\\) Decode Error. Trials with more than 35 neurons generally exhibit a mean error < 0.01, while those below show higher errors.](images/num_clusters_vs_mean_H_error.jpg){ width=100% }\n:::\n\nMost trials with more than 35 neurons had a mean \\(\\mathcal{H}\\) decode error below 0.01, indicating high accuracy. However, some trials still exhibited higher errors due to inconsistencies in the manifold topology, even with sufficient neurons.\n\n## Next Steps\n\n1. **Apply to Raw Unfiltered Spike Data:**\n   - Instead of performing manual, ad-hoc clustering of neurons to determine spike trains, directly input raw neural data into CEBRA. This approach aims to mitigate issues related to the \"curse of clusters\" by leveraging CEBRA’s ability to handle high-dimensional data more effectively.\n\n2. **Test in an Online Environment:**\n   - Implement the manifold learning and \\(\\mathcal{H}\\) decoding pipeline in a simulated \"online\" setup, allowing real-time decoding and feedback during experiments. This step is crucial for enabling closed-loop experiments where adjustments can be made on-the-fly based on the animal’s internal state.\n\n3. **Enhance CEBRA with Topology Bias:**\n   - Modify CEBRA’s loss function to bias the latent space toward a predefined topology (e.g., a 1D ring). This adjustment would help ensure a consistent manifold structure, even in cases with fewer neurons or noisier data, thereby improving the stability and accuracy of \\(\\mathcal{H}\\) decoding.\n\n4. **Expand to Multi-Modal Representations:**\n   - Explore the application of manifold learning to scenarios with multiple varying neural representations (e.g., spatial and auditory cues). This would involve extending the current approach to decode and separate multiple internal variables from the combined neural data, potentially uncovering more complex cognitive mapping strategies used by the brain.\n\n5. **Validate with Additional Behavioral Variables:**\n   - Incorporate and decode additional behavioral variables alongside \\(\\mathcal{H}\\) to understand how different types of sensory and motor information are integrated within the hippocampal cognitive map. This could provide a more comprehensive picture of the neural mechanisms underlying navigation and spatial memory.\n\n6. **Improve Recording Techniques:**\n   - Enhance neural recording methods to capture more neurons with higher fidelity, thereby reducing the impact of the \"curse of clusters\" and improving the overall quality of manifold learning and \\(\\mathcal{H}\\) decoding.\n\nBy pursuing these next steps, we aim to refine and extend our manifold learning approach, enabling more precise and real-time decoding of internal navigation variables. This advancement will not only enhance our understanding of hippocampal function but also pave the way for sophisticated closed-loop experiments that can dynamically probe the neural basis of navigation and cognition in real-time.\n\n",
    "supporting": [
      "blog_temp_files"
    ],
    "filters": [],
    "includes": {}
  }
}