{
  "hash": "d1ccb5cd5439407a802a7fcc42c733b0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Hand gesture classification with EMG data using Riemannian metrics\nformat:\n    html:\n        code-fold: true\n        toc: true\n        toc-depth: 3\n        toc-title: \"Table of Contents\"\n        code-summary: \"Show/Hide Code\"\n---\n\nLead author: Marius Guerard.\n\nIn this notebook we are using EMG time series collected by 8 electrodes placed on the arm skin. We are going to show how to:\n\n- Process these kind of signal into covariance matrices that we can manipulate with geomstats tools.\n- How to apply ML algorithms on this data to classify four different hand gestures present in the data (Rock, Paper, Scissors, Ok).\n- How do the different methods (using Riemanian metrics, projecting on tangent space, Euclidean metric) compare to each other.\n\n<img src=\"paper_rock_scissors.png\" />\n\n## Context\n\nThe data are acquired from somOS-interface: an sEMG armband that allows you to interact via bluetooth with an Android smartphone (you can contact Marius Guerard (marius.guerard@gmail.com) or Renaud Renault (renaud.armand.renault@gmail.com) for more info on how to make this kind of armband yourself). \n\nAn example of application is to record static signs that are linked with different actions (moving a cursor and clicking, sign recognition for command based personal assistants, ...). In these experiments, we want to evaluate the difference in performance (measured as the accuracy of sign recognition) between three different real life situations where we change the conditions of training (when user record signs or \"calibrate\" the device) and testing (when the app guess what sign the user is doing):\n\n- 1. What is the accuracy when doing sign recognition right after training?\n- 2. What is the accuracy when calibrating, removing and replacing the armband at the same position and then testing? \n- 3. What is the accuracy when calibrating, removing the armband and giving it to someone else that is testing it without calibration?\n\nTo simulate these situations, we record data from two different users (rr and mg) and in two different sessions (s1 or s2). The user put the bracelet before every session and remove it after every session.\n\nQuick description of the data:\n\n- Each row corresponds to one acquisition, there is an acquisition every ~4 ms for 8 electrodes which correspond to a 250Hz acquisition rate.\n- The time column is in ms.\n- The columns c0 to c7 correspond to the electrical value recorded at each of the 8 electrodes (arbitrary unit).\n- The label correspond to the sign being recorded by the user at this time point ('rest', 'rock', 'paper', 'scissors', or 'ok). 'rest' correspond to a rested arm.\n- the exp identify the user (rr and mg) and the session (s1 or s2)\n\nNote: Another interesting use case, not explored in this notebook, would be to test what is the accruacy when calibrating, removing the armband and giving it to someone else that is calibrating it on its own arm before testing it. The idea being that transfer learning might help getting better results (or faster calibration) than calibrating on one user.\n\n::: {#f2d7a5cc .cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport geomstats.backend as gs\n\nmatplotlib.interactive(True)\ngs.random.seed(2021)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nINFO: Using numpy backend\n```\n:::\n:::\n\n\n## Parameters\n\n::: {#521aadb7 .cell execution_count=2}\n``` {.python .cell-code}\nN_ELECTRODES = 8\nN_SIGNS = 4\n```\n:::\n\n\n## The Data\n\n::: {#8caac26a .cell execution_count=3}\n``` {.python .cell-code}\nimport geomstats.datasets.utils as data_utils\n\ndata = data_utils.load_emg()\n```\n:::\n\n\n::: {#71db41fc .cell execution_count=4}\n``` {.python .cell-code}\ndata.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c4</th>\n      <th>c5</th>\n      <th>c6</th>\n      <th>c7</th>\n      <th>label</th>\n      <th>exp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>127</td>\n      <td>123</td>\n      <td>128</td>\n      <td>134</td>\n      <td>125</td>\n      <td>128</td>\n      <td>130</td>\n      <td>124</td>\n      <td>rest</td>\n      <td>mg_s1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>126</td>\n      <td>130</td>\n      <td>128</td>\n      <td>119</td>\n      <td>129</td>\n      <td>128</td>\n      <td>126</td>\n      <td>133</td>\n      <td>rest</td>\n      <td>mg_s1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>129</td>\n      <td>130</td>\n      <td>127</td>\n      <td>125</td>\n      <td>129</td>\n      <td>129</td>\n      <td>127</td>\n      <td>130</td>\n      <td>rest</td>\n      <td>mg_s1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>127</td>\n      <td>128</td>\n      <td>126</td>\n      <td>123</td>\n      <td>128</td>\n      <td>127</td>\n      <td>125</td>\n      <td>131</td>\n      <td>rest</td>\n      <td>mg_s1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40</td>\n      <td>127</td>\n      <td>128</td>\n      <td>129</td>\n      <td>124</td>\n      <td>127</td>\n      <td>129</td>\n      <td>127</td>\n      <td>128</td>\n      <td>rest</td>\n      <td>mg_s1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#36786c28 .cell tags='[\"nbsphinx-thumbnail\"]' execution_count=5}\n``` {.python .cell-code}\nfig, ax = plt.subplots(N_SIGNS, figsize=(20, 20))\nlabel_list = [\"rock\", \"scissors\", \"paper\", \"ok\"]\nfor i, label_i in enumerate(label_list):\n    sign_df = data[data.label == label_i].iloc[:100]\n    for electrode in range(N_ELECTRODES):\n        ax[i].plot(sign_df.iloc[:, 1 + electrode])\n        ax[i].title.set_text(label_i)\n```\n\n::: {.cell-output .cell-output-display}\n![](12_rwa_emg_sign_classification_files/figure-html/cell-6-output-1.png){width=1542 height=1540}\n:::\n:::\n\n\nWe are removing the sign 'rest' for the rest of the analysis.\n\n::: {#5f27cd9e .cell execution_count=6}\n``` {.python .cell-code}\ndata = data[data.label != \"rest\"]\n```\n:::\n\n\n### Preprocessing into covariance matrices\n\n::: {#4d6b3ba8 .cell execution_count=7}\n``` {.python .cell-code}\nimport numpy as np\n\n### Parameters.\nN_STEPS = 100\nLABEL_MAP = {\"rock\": 0, \"scissors\": 1, \"paper\": 2, \"ok\": 3}\nMARGIN = 1000\n```\n:::\n\n\nUnpacking data into arrays for batching\n\n::: {#0a64a832 .cell execution_count=8}\n``` {.python .cell-code}\ndata_dict = {\n    \"time\": gs.array(data.time),\n    \"raw_data\": gs.array(data[[\"c{}\".format(i) for i in range(N_ELECTRODES)]]),\n    \"label\": gs.array(data.label),\n    \"exp\": gs.array(data.exp),\n}\n```\n:::\n\n\n::: {#8304e130 .cell execution_count=9}\n``` {.python .cell-code}\nfrom geomstats.datasets.prepare_emg_data import TimeSeriesCovariance\n\ncov_data = TimeSeriesCovariance(data_dict, N_STEPS, N_ELECTRODES, LABEL_MAP, MARGIN)\ncov_data.transform()\n```\n:::\n\n\nWe check that these matrics belong to the space of SPD matrices.\n\n::: {#77d96132 .cell execution_count=10}\n``` {.python .cell-code}\nfrom geomstats.geometry.spd_matrices import SPDMatrices\n\nmanifold = SPDMatrices(N_ELECTRODES, equip=False)\n```\n:::\n\n\n::: {#c6608065 .cell execution_count=11}\n``` {.python .cell-code}\ngs.all(manifold.belongs(cov_data.covs))\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nTrue\n```\n:::\n:::\n\n\n#### Covariances plot of the euclidean average\n\n::: {#19997dd9 .cell execution_count=12}\n``` {.python .cell-code}\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nfor label_i, i in cov_data.label_map.items():\n    label_ids = np.where(cov_data.labels == i)[0]\n    sign_cov_mat = cov_data.covs[label_ids]\n    mean_cov = np.mean(sign_cov_mat, axis=0)\n    ax[i // 2, i % 2].matshow(mean_cov)\n    ax[i // 2, i % 2].title.set_text(label_i)\n```\n\n::: {.cell-output .cell-output-display}\n![](12_rwa_emg_sign_classification_files/figure-html/cell-13-output-1.png){width=1185 height=805}\n:::\n:::\n\n\nLooking at the euclidean average of the spd matrices for each sign, does not show a striking difference between 3 of our signs (scissors, paper, and ok). Minimum Distance to Mean (MDM) algorithm will probably performed poorly if using euclidean mean here.\n\n#### Covariances plot of the Frechet Mean of the affine invariant metric\n\n::: {#c60aaab0 .cell execution_count=13}\n``` {.python .cell-code}\nfrom geomstats.geometry.spd_matrices import SPDAffineMetric\nfrom geomstats.learning.frechet_mean import FrechetMean\n```\n:::\n\n\n::: {#d19a467f .cell execution_count=14}\n``` {.python .cell-code}\nmanifold.equip_with_metric(SPDAffineMetric)\n\nmean_affine = FrechetMean(manifold)\n```\n:::\n\n\n::: {#da1b42e6 .cell execution_count=15}\n``` {.python .cell-code}\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\nfor label_i, i in cov_data.label_map.items():\n    label_ids = np.where(cov_data.labels == i)[0]\n    sign_cov_mat = cov_data.covs[label_ids]\n    mean_affine.fit(X=sign_cov_mat)\n    mean_cov = mean_affine.estimate_\n    ax[i // 2, i % 2].matshow(mean_cov)\n    ax[i // 2, i % 2].title.set_text(label_i)\n```\n\n::: {.cell-output .cell-output-display}\n![](12_rwa_emg_sign_classification_files/figure-html/cell-16-output-1.png){width=1185 height=805}\n:::\n:::\n\n\nWe see that the average matrices computed using the affine invariant metric are now more differenciated from each other and can potentially give better results, when using MDM to predict the sign linked to a matrix sample.\n\n## Sign Classification\n\nWe are now going to train some classifiers on those matrices to see how we can accurately discriminate these 4 hand positions.\nThe baseline accuracy is defined as the accuracy we get by randomly guessing the signs. In our case, the baseline accuracy is 25%.\n\n::: {#bfc732d6 .cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\n::: {#0582ed12 .cell execution_count=17}\n``` {.python .cell-code}\n# Hiding the numerous sklearn warnings\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n```\n:::\n\n\n::: {#51357caf .cell execution_count=18}\n``` {.python .cell-code}\nimport tensorflow as tf\nfrom scikeras.wrappers import KerasClassifier\n```\n:::\n\n\nN_EPOCHS is the number of epochs on which to train the MLP. Recommended is ~100\n\n::: {#4624f08f .cell execution_count=19}\n``` {.python .cell-code}\nN_EPOCHS = 10\nN_FEATURES = int(N_ELECTRODES * (N_ELECTRODES + 1) / 2)\n```\n:::\n\n\n### A. Test on the same session and user as Training/Calibration \n\nIn this first part we are training our model on the same session that we are testing it on. In real life, it corresponds to a user calibrating his armband right before using it. To do this, we are splitting every session in k-folds, training on $(k-1)$ fold to test on the $k^{th}$ last fold. \n\n::: {#a5da5685 .cell execution_count=20}\n``` {.python .cell-code}\nclass ExpResults:\n    \"\"\"Class handling the score collection and plotting among the different experiments.\"\"\"\n\n    def __init__(self, exps):\n        self.exps = exps\n        self.results = {}\n        self.exp_ids = {}\n        # Compute the index corresponding to each session only once at initialization.\n        for exp in set(self.exps):\n            self.exp_ids[exp] = np.where(self.exps == exp)[0]\n\n    def add_result(self, model_name, model, X, y):\n        \"\"\"Add the results from the cross validated pipeline.\n\n        For the model 'pipeline', it will add the cross validated results of every session in the model_name\n        entry of self.results.\n\n        Parameters\n        ----------\n        model_name : str\n            Name of the pipeline/model that we are adding results from.\n        model : sklearn.pipeline.Pipeline\n            sklearn pipeline that we are evaluating.\n        X : array\n            data that we are ingesting in the pipeline.\n        y : array\n            labels corresponding to the data.\n        \"\"\"\n        self.results[model_name] = {\n            \"fit_time\": [],\n            \"score_time\": [],\n            \"test_score\": [],\n            \"train_score\": [],\n        }\n        for exp in self.exp_ids.keys():\n            ids = self.exp_ids[exp]\n            exp_result = cross_validate(\n                pipeline, X[ids], y[ids], return_train_score=True\n            )\n            for key in exp_result.keys():\n                self.results[model_name][key] += list(exp_result[key])\n        print(\n            \"Average training score: {:.4f}, Average test score: {:.4f}\".format(\n                np.mean(self.results[model_name][\"train_score\"]),\n                np.mean(self.results[model_name][\"test_score\"]),\n            )\n        )\n\n    def plot_results(\n        self,\n        title,\n        variables,\n        err_bar=None,\n        save_name=None,\n        xlabel=\"Model\",\n        ylabel=\"Acc\",\n    ):\n        \"\"\"Plot bar plot comparing the different pipelines' results.\n\n        Compare the results added previously using the 'add_result' method with bar plots.\n\n        Parameters\n        ----------\n        title : str\n            Title of the plot.\n        variables : list of array\n            List of the variables to plot (e.g. train_score, test_score,...)\n        err_bar : list of float\n            list of error to use for plotting error bars. If None, std is used by default.\n        save_name : str\n            path to save the plot. If None, plot is not saved.\n        xlabel : str\n            Label of the x-axis.\n        ylabel : str\n            Label of the y-axis.\n        \"\"\"\n        ### Some defaults parameters.\n        w = 0.5\n        colors = [\"b\", \"r\", \"gray\"]\n\n        ### Reshaping the results for plotting.\n        x_labels = self.results.keys()\n        list_vec = []\n        for variable in variables:\n            list_vec.append(\n                np.array(\n                    [self.results[model][variable] for model in x_labels]\n                ).transpose()\n            )\n        rand_m1 = lambda size: np.random.random(size) * 2 - 1\n\n        ### Plots parameters.\n        label_loc = np.arange(len(x_labels))\n        center_bar = [w * (i - 0.5) for i in range(len(list_vec))]\n\n        ### Plots values.\n        avg_vec = [np.nanmean(vec, axis=0) for vec in list_vec]\n        if err_bar is None:\n            err_bar = [np.nanstd(vec, axis=0) for vec in list_vec]\n\n        ### Plotting the data.\n        fig, ax = plt.subplots(figsize=(20, 15))\n        for i, vec in enumerate(list_vec):\n            label_i = variable[i] + \" (n = {})\".format(len(vec))\n            ax.bar(\n                label_loc + center_bar[i],\n                avg_vec[i],\n                w,\n                label=label_i,\n                yerr=err_bar[i],\n                color=colors[i],\n                alpha=0.6,\n            )\n            for j, x in enumerate(label_loc):\n                ax.scatter(\n                    (x + center_bar[i]) + rand_m1(vec[:, j].size) * w / 4,\n                    vec[:, j],\n                    color=colors[i],\n                    edgecolor=\"k\",\n                )\n\n        # Add some text for labels, title and custom x-axis tick labels, etc.\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.set_title(title)\n        ax.set_xticks(label_loc)\n        ax.set_xticklabels(x_labels)\n        ax.legend()\n        plt.legend()\n\n        ### Saving the figure with a timestamp as a name.\n        if save_name is not None:\n            plt.savefig(save_name)\n```\n:::\n\n\n::: {#045cf5b6 .cell execution_count=21}\n``` {.python .cell-code}\nexp_arr = data.exp.iloc[cov_data.batches]\nintra_sessions_results = ExpResults(exp_arr)\n```\n:::\n\n\n#### A.0. Using Logistic Regression on the vectorized Matrix (Euclidean Method)\n\n::: {#a7248568 .cell execution_count=22}\n``` {.python .cell-code}\npipeline = Pipeline(\n    steps=[\n        (\"standardize\", StandardScaler()),\n        (\"logreg\", LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")),\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"logreg_eucl\", model=pipeline, X=cov_data.covecs, y=cov_data.labels\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.9938, Average test score: 0.9168\n```\n:::\n:::\n\n\n#### A.1. Using MLP on the vectorized Matrix (Euclidean Method)\n\n::: {#e6d2c637 .cell execution_count=23}\n``` {.python .cell-code}\ndef create_model(weights=\"initial.weights.h5\", n_features=N_FEATURES, n_signs=N_SIGNS):\n    \"\"\"Create model.\n\n    Function to create model, required for using KerasClassifier and wrapp a Keras model inside a\n    scikitlearn form.\n    We added a weight saving/loading to remove the randomness of the weight initialization (for better comparison).\n    \"\"\"\n    model = tf.keras.models.Sequential(\n        [\n            tf.keras.layers.Dense(\n                n_features, activation=\"relu\", input_shape=(n_features,)\n            ),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Dense(17, activation=\"relu\"),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Dense(n_signs, activation=\"softmax\"),\n        ]\n    )\n\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        optimizer=\"rmsprop\",\n        metrics=[\"accuracy\"],\n    )\n    if weights is None:\n        model.save_weights(\"initial.weights.h5\")\n    else:\n        model.load_weights(weights)\n    return model\n\n\ndef create_model_covariance(weights=\"initial.weights.h5\"):\n    \"\"\"Create model covariance.\"\"\"\n    return create_model(weights=weights, n_features=N_FEATURES)\n```\n:::\n\n\nUse the line below to generate the 'initial.weights.h5' file\n\n::: {#0a8c003c .cell execution_count=24}\n``` {.python .cell-code}\ngenerate_weights = create_model(weights=None)\n```\n:::\n\n\n::: {#4a45a6c0 .cell execution_count=25}\n``` {.python .cell-code}\npipeline = Pipeline(\n    steps=[\n        (\"standardize\", StandardScaler()),\n        (\"mlp\", KerasClassifier(build_fn=create_model, epochs=N_EPOCHS, verbose=0)),\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"mlp_eucl\", model=pipeline, X=cov_data.covecs, y=cov_data.labels\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.9463, Average test score: 0.8715\n```\n:::\n:::\n\n\n#### A.2. Using Tangent space projection + Logistic Regression\n\n::: {#962eb943 .cell execution_count=26}\n``` {.python .cell-code}\nfrom geomstats.learning.preprocessing import ToTangentSpace\n\npipeline = Pipeline(\n    steps=[\n        (\"feature_ext\", ToTangentSpace(manifold)),\n        (\"standardize\", StandardScaler()),\n        (\"logreg\", LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\")),\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"logreg_affinvariant_tangent\",\n    model=pipeline,\n    X=cov_data.covs,\n    y=cov_data.labels,\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.9959, Average test score: 0.9200\n```\n:::\n:::\n\n\n#### A.3. Using Tangent space projection + MLP\n\n::: {#ad2c0449 .cell execution_count=27}\n``` {.python .cell-code}\npipeline = Pipeline(\n    steps=[\n        (\"feature_ext\", ToTangentSpace(manifold)),\n        (\"standardize\", StandardScaler()),\n        (\n            \"mlp\",\n            KerasClassifier(\n                build_fn=create_model_covariance, epochs=N_EPOCHS, verbose=0\n            ),\n        ),\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"mlp_affinvariant_tangent\",\n    model=pipeline,\n    X=cov_data.covs,\n    y=cov_data.labels,\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.9586, Average test score: 0.8756\n```\n:::\n:::\n\n\n#### A.4. Using Euclidean MDM\n\n::: {#eb2b2340 .cell execution_count=28}\n``` {.python .cell-code}\nfrom geomstats.geometry.spd_matrices import SPDEuclideanMetric\nfrom geomstats.learning.mdm import RiemannianMinimumDistanceToMean\n\nmanifold.equip_with_metric(SPDEuclideanMetric)\n\npipeline = Pipeline(\n    steps=[\n        (\n            \"clf\",\n            RiemannianMinimumDistanceToMean(manifold),\n        )\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"mdm_eucl\", model=pipeline, X=cov_data.covs, y=cov_data.labels\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.8498, Average test score: 0.7999\n```\n:::\n:::\n\n\n#### A.5. Using Riemannian MDM\n\n::: {#781b5378 .cell execution_count=29}\n``` {.python .cell-code}\npipeline = Pipeline(\n    steps=[\n        (\n            \"clf\",\n            RiemannianMinimumDistanceToMean(manifold),\n        )\n    ]\n)\n\nintra_sessions_results.add_result(\n    model_name=\"mdm_affinvariant\", model=pipeline, X=cov_data.covs, y=cov_data.labels\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage training score: 0.8498, Average test score: 0.7999\n```\n:::\n:::\n\n\n#### Summary plots\n\n::: {#6b4571aa .cell execution_count=30}\n``` {.python .cell-code}\nintra_sessions_results.plot_results(\"intra_sess\", [\"test_score\"])\n```\n\n::: {.cell-output .cell-output-display}\n![](12_rwa_emg_sign_classification_files/figure-html/cell-31-output-1.png){width=1556 height=1189}\n:::\n:::\n\n\n",
    "supporting": [
      "12_rwa_emg_sign_classification_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}