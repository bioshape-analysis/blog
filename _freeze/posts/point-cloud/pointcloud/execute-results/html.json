{
  "hash": "21abd543ff5e782c3ffdd0dbb65cfd0a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Point cloud representation of 3D volumes\"\nsubtitle: \"Application to cryoEM density maps\"\n\nengine: \"jupyter\"\nauthor:\n  - name: \"Aryan Tajmir Riahi\" \n    email: \"artajmir@cs.ubc.ca\"\n    affiliations:\n      - name: KDD Group\n        url: \"https://rtviii.xyz/\"\n\n  - name: \"Khanh Dao Duc\" \n    email: \"kdd@math.ubc.ca\"\n    affiliations:\n      - name: Department of Mathematics, UBC\n        url: \"https://www.math.ubc.ca/\"\n      - name: Department of Computer Science, UBC\n        url: \"https://www.cs.ubc.ca/\"\n\ndate: \"August 15 2024\"\ncategories: [biology, bioinformatics]   \nbibliography: references.bib\n--- \n\n\n# Introduction\n\nIn the context of cryo-EM, many computationally exhaustive methods rely on simpler representations of cryo-EM density maps to overcome their scalability challenges. There are many choices for the form of the simpler representation, such as vectors [@han2021vesper] or a mixture of Gaussians [@kawabata2008multiple]. In this post, we discuss a format that is probably the simplest and uses a set of points (called a point cloud). \n\nThis problem can be formulated in a much more general sense rather than cryo-EM. In this sense, we are given a probability distribution over $\\mathbb{R}^3$ and we want to generate a set of 3D points that represent this distribution. The naive approach for finding such a point cloud is to just sample points from the distribution. Although this approach is guaranteed to find a good representation, it needs many points to cover the distribution evenly. Since methods used in this field can be computationally intensive with cubic or higher time complexity, generating a point cloud that covers the given distribution with a smaller point-cloud size leads to a significant improvement in their runtime.\n\nIn this approach, we present two methods for generating a point cloud from a cryo-EM density map or a distribution in general. The first one is based on the Topological Representing Network (TRN) [@martinetz1994topology] and the second one combines the usage of the Optimal Transport (OT) [@peyre2019computational] theory and a computational geometry object named Centroidal Voronoi Tessellation (CVT).\n\n## Data\nFor the sake of simplicity in this post, we assume we are given a primal distribution over $\\mathbb{R}^2$. As an example, we will work on a multivariate Gaussian distribution that it's domain is limited to $[0, 1]^2$. The following code prepares and illustrates the pdf of the example distribution.\n\n::: {#840f6e5a .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport scipy as scp\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\n\n\nmean = np.array([0,0])\ncov = np.array([[0.5, 0.25], [0.25, 0.5]])\ndistr = scp.stats.multivariate_normal(cov = cov, mean = mean, seed = 1)\n\n\nfig, ax = plt.subplots(figsize=(8,8))\nim = ax.imshow([[distr.pdf([i/100,j/100]) for i in range(100,-100,-1)] for j in range(-100,100)], extent=[-1, 1, -1, 1])\ncbar = ax.figure.colorbar(im, ax=ax)\nplt.title(\"The pdf of our primal distribution\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-2-output-1.png){width=644 height=611}\n:::\n:::\n\n\nBoth of the methods that we are going to cover are iterative methods relying on an initial sample of points. For generating a point cloud with size $n$, they begin by randomly sampling $n$ points and refining it over iterations. We use $n=200$ in our examples.\n\n::: {#40de2bb8 .cell execution_count=2}\n``` {.python .cell-code}\ndef sampler(rvs):\n    while True:\n        sample = rvs(1)\n        if abs(sample[0]) > 1 or abs(sample[1]) > 1:\n            continue\n        return sample\n\ninitial_samples = []\nwhile len(initial_samples) < 200:\n    sample = sampler(distr.rvs)\n    initial_samples.append(list(sample))\ninitial_samples = np.array(initial_samples)\n\nl = list(zip(*initial_samples))\nx = list(l[0])\ny = list(l[1])\n\nfig, ax = plt.subplots(figsize=(8,8))\nax.scatter(x, y)\nax.plot((-1,-1), (-1,1), 'k-')\nax.plot((-1,1), (-1,-1), 'k-')\nax.plot((1,1), (1,-1), 'k-')\nax.plot((-1,1), (1,1), 'k-')\nplt.ylim(-1.1,1.1)\nplt.xlim(-1.1,1.1)\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-3-output-1.png){width=614 height=611}\n:::\n:::\n\n\n# Topology Representing Networks (TRN)\nTRN is an iterative method that relies on randomly sampling an initial point cloud $r_m(0)_{i=1,\\dots,n}$ from the given probability distribution $p$. At each step $t$, they sample a new point ($r_t$) from $p$ and compute the distance from points in $r_m(t)$ to $r_t$ and rank them from zero (closest) to $n-1$ (called $k_m$). Then they update the position of points based on:\n$$r_m(t+1) = r_m(t) + \\epsilon(t)exp(-k_m/\\lambda(t))(r_t - r_m(t)),$$\n$$\\epsilon(t) = \\epsilon_0(\\frac{\\epsilon_f}{\\epsilon_0})^{t/t_f},$$\n$$\\lambda(t) = \\lambda_0(\\frac{\\lambda_f}{\\lambda_0})^{t/t_f}$$\nThese equations are designed in a way that moves points slower as the number of iterations increases.\n\n::: {#fdadd9a5 .cell execution_count=3}\n``` {.python .cell-code}\ne0=0.5\nef=0.05\nl0=1\nlf=0.5\ntf=2000\n```\n:::\n\n\n::: {#acf5c064 .cell execution_count=4}\n``` {.python .cell-code}\nfig, axs = plt.subplots(2, 2, figsize=(9.5,9.5))\n\nr = initial_samples\nfor t in range(tf):\n    rt = sampler(distr.rvs)\n    dist2 = ((rt - r)**2).sum(1) \n    order = dist2.argsort()\n    rank = order.argsort().reshape(-1,1)\n    l = l0*(lf/l0)**(t/tf)\n    e = e0*(ef/e0)**(t/tf)\n    r = r + e*np.exp(-rank/l)*(rt-r)\n    \n    if (t+1)%500 == 0:\n        l = list(zip(*r))\n        x = list(l[0])\n        y = list(l[1])\n\n        index = t//500\n        axs[index//2][index%2].scatter(x, y, s=10)\n        axs[index//2][index%2].title.set_text('Position of points after t=%d iterations'%(t+1,))\n        axs[index//2][index%2].plot((-1,-1), (-1,1), 'k-')\n        axs[index//2][index%2].plot((-1,1), (-1,-1), 'k-')\n        axs[index//2][index%2].plot((1,1), (1,-1), 'k-')\n        axs[index//2][index%2].plot((-1,1), (1,1), 'k-')\n        plt.ylim(-1.1,1.1)\n        plt.xlim(-1.1,1.1)\n        axs[index//2][index%2].set_xticks([])\n        axs[index//2][index%2].set_yticks([])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-5-output-1.png){width=731 height=741}\n:::\n:::\n\n\n# Centroidal Vornoi Tessellation (CVT)\nAlthough TRN is intuitive it doesn't minimize any specific objective function. Among the metrics that can be for determining the distance between a point cloud and a continuous distribution the semidiscrete Wasserstein distance (based on the Optimal Transport theory [@peyre2019computational]) is of our interest. In other words, we want a point cloud that minimizes the semidiscrete Wasserstein distance to a given primal distribution. One can prove that such a point cloud forms a geometrical object named Centroidal Voronoi Tessellation (CVT) over the distribution. A CVT is a Voronoi diagram generated by a point cloud such that each point is centroid and generator of it's Voronoi cell. More details about this object will be covered in future posts. Such a tessellation can be computed using Lloyd's iterations by alternating between computing centroids and Voronoi cells. Unlike TRN this method generated a weighted point cloud.\n\n::: {#f58688b1 .cell execution_count=5}\n``` {.python .cell-code}\ndef in_box(robots, bounding_box):\n    return np.logical_and(np.logical_and(bounding_box[0] <= robots[:, 0],\n                                         robots[:, 0] <= bounding_box[1]),\n                          np.logical_and(bounding_box[2] <= robots[:, 1],\n                                         robots[:, 1] <= bounding_box[3]))\n\n\ndef voronoi(robots, bounding_box):\n    i = in_box(robots, bounding_box)\n    points_center = robots[i, :]\n    points_left = np.copy(points_center)\n    points_left[:, 0] = bounding_box[0] - (points_left[:, 0] - bounding_box[0])\n    points_right = np.copy(points_center)\n    points_right[:, 0] = bounding_box[1] + (bounding_box[1] - points_right[:, 0])\n    points_down = np.copy(points_center)\n    points_down[:, 1] = bounding_box[2] - (points_down[:, 1] - bounding_box[2])\n    points_up = np.copy(points_center)\n    points_up[:, 1] = bounding_box[3] + (bounding_box[3] - points_up[:, 1])\n    points = np.append(points_center,\n                       np.append(np.append(points_left,\n                                           points_right,\n                                           axis=0),\n                                 np.append(points_down,\n                                           points_up,\n                                           axis=0),\n                                 axis=0),\n                       axis=0)\n    # Compute Voronoi\n    vor = scp.spatial.Voronoi(points)\n    # Filter regions and select corresponding points\n    regions = []\n    points_to_filter = [] # we'll need to gather points too\n    ind = np.arange(points.shape[0])\n    ind = np.expand_dims(ind,axis= 1)\n\n    for i,region in enumerate(vor.regions): # enumerate the regions\n        if not region: # nicer to skip the empty region altogether\n            continue\n\n        flag = True\n        for index in region:\n            if index == -1:\n                flag = False\n                break\n            else:\n                x = vor.vertices[index, 0]\n                y = vor.vertices[index, 1]\n                if not(bounding_box[0] - eps <= x and x <= bounding_box[1] + eps and\n                       bounding_box[2] - eps <= y and y <= bounding_box[3] + eps):\n                    flag = False\n                    break\n        if flag:\n            regions.append(region)\n\n            # find the point which lies inside\n            points_to_filter.append(vor.points[vor.point_region == i][0,:])\n\n    vor.filtered_points = np.array(points_to_filter)\n    vor.filtered_regions = regions\n    return vor\n\ndef centroid_region(vertices):\n    A = 0\n    C_x = 0\n    C_y = 0\n    for i in range(len(vertices)):\n        p = distr.pdf(vertices[i])\n        A += p\n        C_x += vertices[i,0] * p\n        C_y += vertices[i,1] * p\n        \n    C_x /= A\n    C_y /= A\n    return np.array([[C_x, C_y]]), A\n\ndef plot(r,ax):\n    vor = voronoi(r, bounding_box)\n    ax.set_xlim([-1.1, 1.1])\n    ax.set_ylim([-1.1, 1.1])\n    \n    for region in vor.filtered_regions:\n        vertices = vor.vertices[region + [region[0]], :]\n        ax.plot(vertices[:, 0], vertices[:, 1], 'k-')\n        \n    centroids = []\n    weights = []\n    \n    for region in vor.filtered_regions:\n        vertices = vor.vertices[region + [region[0]], :]\n        centroid, w = centroid_region(vertices)\n        centroids.append(list(centroid[0, :]))\n        weights.append(w)\n        \n    \n    ax.scatter(vor.filtered_points[:, 0], vor.filtered_points[:, 1], s=5, c='b', alpha=weights/max(weights))\n        \n    ax.set_xticks([])\n    ax.set_yticks([])\n        \n    centroids = np.asarray(centroids)\n    return centroids, weights\n```\n:::\n\n\n::: {#8ad84d5f .cell execution_count=6}\n``` {.python .cell-code}\nimport sys\nbounding_box = np.array([-1., 1., -1., 1.]) \neps = sys.float_info.epsilon\nsamples = initial_samples\nfig, axs = plt.subplots(3,3,figsize=(9,9))\nfor i in range(9):\n    axs[i//3][i%3].title.set_text('iteration t=%d'%(i + 1,))\n    centroids, weights = plot(samples,axs[i//3][i%3])\n    samples = np.copy(centroids)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](pointcloud_files/figure-html/cell-7-output-1.png){width=689 height=704}\n:::\n:::\n\n\n# More Examples\n\n To further examine the effectiveness of these methods, we performed a simulation on a more complex distribution obtained by normalizing the intensities of a sketch of Naqsh-e Jahan Square and $n=10^5$ points. This image shows the convergence of methods as well as the primal distribution.\n\n![Covering a more complex distribution with point clouds generated by TRN and CVT.](img/example1.png)\n\n# Application on Cryo-EM\n\nBoth of these methods are easily applicable to a 3D density map. A full implementation of both methods in ChimeraX (the standard visualization tool for cryo-EM) [@pettersen2021ucsf] is in this [GitHub repo](https://github.com/artajmir3/ot_alignment). TRN was first used in the field of cryo-EM by [@zhang2021state], later on, we used it in our alignment methods [@riahi2023alignot, @riahi2023empot]. An example of its performance on cryo-EM density map [EMDB:1717](https://www.ebi.ac.uk/emdb/EMD-1717) is illustrated below. To the best of our knowledge, no paper has used CVT in the field of cryo-EM yet.\n\n![An example of covering EMDB:1717 with 200 points using TRN.](img/example-cryoem.png)\n\n",
    "supporting": [
      "pointcloud_files"
    ],
    "filters": [],
    "includes": {}
  }
}