<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Deven Shidfar">
<meta name="dcterms.date" content="2024-09-18">

<title>Understanding Animal Navigation using Neural Manifolds With CEBRA – bioshape-analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-659650fc26dc25888fc1474f317bb8ac.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">bioshape-analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Understanding Animal Navigation using Neural Manifolds With CEBRA</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">biology</div>
                <div class="quarto-category">bioinformatics</div>
                <div class="quarto-category">mathematics</div>
                <div class="quarto-category">biomedical engineering</div>
                <div class="quarto-category">neuroscience</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliations</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Deven Shidfar <a href="mailto:devenshidfar@math.ubc.ca" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              <a href="https://rtviii.xyz/">
              KDD Group
              </a>
            </p>
          <p class="affiliation">
              <a href="https://www.nc4.sbme.ubc.ca/">
              NC4 Lab
              </a>
            </p>
          <p class="affiliation">
              <a href="https://www.math.ubc.ca/">
              Department of Mathematics, UBC
              </a>
            </p>
          <p class="affiliation">
              <a href="https://bme.ubc.ca/">
              Department of Biomedical Engineering, UBC
              </a>
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 18, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#problem-description" id="toc-problem-description" class="nav-link active" data-scroll-target="#problem-description">Problem Description:</a></li>
  <li><a href="#experimental-setup" id="toc-experimental-setup" class="nav-link" data-scroll-target="#experimental-setup">Experimental Setup</a>
  <ul class="collapse">
  <li><a href="#the-dome-apparatus" id="toc-the-dome-apparatus" class="nav-link" data-scroll-target="#the-dome-apparatus">The Dome Apparatus</a></li>
  <li><a href="#crux-of-the-problem" id="toc-crux-of-the-problem" class="nav-link" data-scroll-target="#crux-of-the-problem">Crux of the problem</a></li>
  </ul></li>
  <li><a href="#main-goal" id="toc-main-goal" class="nav-link" data-scroll-target="#main-goal">Main Goal</a></li>
  <li><a href="#what-is-cebra" id="toc-what-is-cebra" class="nav-link" data-scroll-target="#what-is-cebra">What is CEBRA?</a>
  <ul class="collapse">
  <li><a href="#the-need-for-cebra" id="toc-the-need-for-cebra" class="nav-link" data-scroll-target="#the-need-for-cebra">The Need for CEBRA</a></li>
  <li><a href="#how-does-cebra-work" id="toc-how-does-cebra-work" class="nav-link" data-scroll-target="#how-does-cebra-work">How Does CEBRA Work?</a></li>
  <li><a href="#key-features-of-cebra" id="toc-key-features-of-cebra" class="nav-link" data-scroll-target="#key-features-of-cebra">Key Features of CEBRA</a></li>
  <li><a href="#cebra-architecture" id="toc-cebra-architecture" class="nav-link" data-scroll-target="#cebra-architecture">CEBRA Architecture</a></li>
  </ul></li>
  <li><a href="#persistent-homology" id="toc-persistent-homology" class="nav-link" data-scroll-target="#persistent-homology">Persistent Homology</a>
  <ul class="collapse">
  <li><a href="#validating-a-1d-ring-manifold" id="toc-validating-a-1d-ring-manifold" class="nav-link" data-scroll-target="#validating-a-1d-ring-manifold">Validating a 1D Ring Manifold</a></li>
  </ul></li>
  <li><a href="#spud-method" id="toc-spud-method" class="nav-link" data-scroll-target="#spud-method">SPUD Method</a>
  <ul class="collapse">
  <li><a href="#overview-of-the-spud-method" id="toc-overview-of-the-spud-method" class="nav-link" data-scroll-target="#overview-of-the-spud-method">Overview of the SPUD Method</a></li>
  <li><a href="#deciding-the-parameterization-of-the-latent-variable" id="toc-deciding-the-parameterization-of-the-latent-variable" class="nav-link" data-scroll-target="#deciding-the-parameterization-of-the-latent-variable">Deciding the Parameterization of the Latent Variable</a></li>
  </ul></li>
  <li><a href="#decoding-hippocampal-gain-mathcalh" id="toc-decoding-hippocampal-gain-mathcalh" class="nav-link" data-scroll-target="#decoding-hippocampal-gain-mathcalh">Decoding Hippocampal Gain (<span class="math inline">\(\mathcal{H}\)</span>)</a>
  <ul class="collapse">
  <li><a href="#final-step" id="toc-final-step" class="nav-link" data-scroll-target="#final-step">Final Step</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next steps</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="problem-description" class="level2">
<h2 class="anchored" data-anchor-id="problem-description">Problem Description:</h2>
<p>Understanding how animals navigate is an important area of research that has applications in early detection of diseases such as Alzheimers and Huntington as well as advancing autonomous robotics and reinforcement learning. One way that the brain encodes spatial information is through a mechanism known as the “Cognitive Map” (<span class="citation" data-cites="behrens2018">Behrens et al. (<a href="#ref-behrens2018" role="doc-biblioref">2018</a>)</span>). Specifically, the hippocampus plays a key role in this process by using path integration to keep track of an animal’s position through the integration various idiothetic cues (self-motion signals), such as optic flow, vestibular inputs, and proprioception.</p>
<p><strong>The question then arises:</strong> How can we manipulate hippocampal neurons by presenting conflicting visual cues? Basically, by studying what happens when we perturb normal self-motion cues in an animal’s environment and observing the resulting changes in the brain’s navigation system, we can understand better how animals navigate and map their environments. This blog will focus on experiments conducted in “Control and recalibration of path integration in place cells using optic flow” (<span class="citation" data-cites="madhav2024">Madhav et al. (<a href="#ref-madhav2024" role="doc-biblioref">2024</a>)</span>).</p>
</section>
<section id="experimental-setup" class="level2">
<h2 class="anchored" data-anchor-id="experimental-setup">Experimental Setup</h2>
<p>In the paper “Control and recalibration of path integration in place cells using optic flow” (<span class="citation" data-cites="madhav2024">Madhav et al. (<a href="#ref-madhav2024" role="doc-biblioref">2024</a>)</span>), Dr.&nbsp;Madhav and colleagues designed an experimental setup to investigate how optic flow cues influence hippocampal <strong>place cells</strong> in freely moving rats. <strong>Place cells</strong> are neurons that fire when an animal is in a <strong>specific</strong> location within its environment, effectively encoding spatial information.</p>
<p>For example, imagine a rat moving along a horizontal linear track. For simplicity let’s say the rat has only <strong>3</strong> place cell neurons. In this case, <strong>Neuron 1</strong> would fire when the rat is at the very left of the track, <strong>Neuron 2</strong> would fire when the rat is in the middle of the track, and <strong>Neuron 3</strong> would fire at the very right of the track. As the rat moves along the track, the specific place cells corresponding to each location become activated, helping the rat to construct an internal <strong>cognitive map</strong> of its environment.</p>
<section id="the-dome-apparatus" class="level3">
<h3 class="anchored" data-anchor-id="the-dome-apparatus">The Dome Apparatus</h3>
<p>In the experiment, rats ran on a circular platform surrounded by a hemispherical projection surface called the Dome.</p>
<div id="vr_dome" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/dome_apparatus.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Fig. 1 - Virtual reality Dome apparatus. Rats ran on a circular table surrounded by a hemispherical shell. A projector image reflects off a hemispherical mirror onto the inner surface of the shell.</figcaption>
</figure>
</div>
</div>
<p>The dome projected moving stripes that provided controlled optic flow cues. The movement of the stripes was tied to the rats’ movement, with the stripe gain (<span class="math inline">\(\mathcal{S}\)</span>) determining the relationship between the rat’s speed and the stripes’ speed.</p>
<ul>
<li><p><span class="math inline">\(\mathcal{S}\)</span> = 1: Stripes are stationary relative to the lab frame, meaning the rat is not recieving conflicting cues.</p></li>
<li><p><span class="math inline">\(\mathcal{S}\)</span> &gt; 1: Stripes move opposite to the rat’s direction, causing the rat to percieve itself as moving faster than it is.</p></li>
<li><p><span class="math inline">\(\mathcal{S}\)</span> &lt; 1: Stripes move in the same direction but slower than the rat, causing the rat to percieve itself as moving slower than it is.</p></li>
</ul>
<p>Electrodes were inserted into the <strong>CA1</strong> of the hippocampus of <strong>male evan’s rats</strong> and spike rate neural activity was recorded during the experiment. Dr.&nbsp;Madhav and colleagues introduce a value <span class="math inline">\(\mathcal{H}\)</span>, called the <strong>Hippocampal Gain</strong>. It is defined as the relationship between the rat’s physical movement and the updating of its position on the internal hippocampal map. Specifically,</p>
<p><span class="math display">\[
  \mathcal{H} = \frac{\text{distance travelled in hippocampal reference frame}}{\text{distance travelled in lab reference frame}}.
\]</span></p>
<p>In this equation, <strong>distance travelled in the hippocampal frame</strong> refers to the distance that the rat <strong>“thinks”</strong> it’s moving.</p>
<ul>
<li><p><span class="math inline">\(\mathcal{H} = 1\)</span>: The rat perceives itself as moving the “correct” speed</p></li>
<li><p><span class="math inline">\(\mathcal{H} &gt; 1\)</span>: The rat perceives itself as moving faster than it actually is with respect to the lab frame.</p></li>
<li><p><span class="math inline">\(\mathcal{H} &lt; 1\)</span>: The rat perceives itself as moving slower than it actually is with respect to the lab frame.</p></li>
</ul>
<p><span class="math inline">\(\mathcal{H}\)</span> gives valuable insights into how these visual cues such as the moving stripes affect the rats’ internal <strong>cognitive map</strong> during the task. It gives an understanding of how the rats update their <strong>perceived</strong> position in the environment.</p>
<p>For example, an <span class="math inline">\(\mathcal{H}\)</span> value of 2, would mean that the rat <strong>perceives</strong> itself as moving twice as fast as it actually is. Consequently each place cell corresponding to a specific <strong>location</strong> in the maze, will fire twice per lap rather than once.</p>
</section>
<section id="crux-of-the-problem" class="level3">
<h3 class="anchored" data-anchor-id="crux-of-the-problem">Crux of the problem</h3>
<p><strong>Method of Determining <span class="math inline">\(\mathcal{H}\)</span></strong>: Traditionally, <span class="math inline">\(\mathcal{H}\)</span> is determined by analyzing the spatial periodicity of place cell firing over multiple laps using <strong>Fourier transforms</strong>, as seen in (<span class="citation" data-cites="jayakumar2019">Jayakumar et al. (<a href="#ref-jayakumar2019" role="doc-biblioref">2019</a>)</span>,<span class="citation" data-cites="madhav2024">Madhav et al. (<a href="#ref-madhav2024" role="doc-biblioref">2024</a>)</span>). However, this method is cumbersome and lacks temporal precision <strong>within</strong> individual laps. A more precise, <strong>within-lap</strong> decoding of Hippocampal Gain (<span class="math inline">\(\mathcal{H}\)</span>) could provide a deeper understanding of how path integration updates occur with finer <strong>temporal resolution</strong>. This could lead to new insights into how the brain updates its <strong>cognitive map</strong>when receiving conflicting visual cues.</p>
</section>
</section>
<section id="main-goal" class="level2">
<h2 class="anchored" data-anchor-id="main-goal">Main Goal</h2>
<p>Our main goal is therefore to determine this <span class="math inline">\(\mathcal{H}\)</span> value without using a Fourier Transform and instead somehow find a <strong>temporally finer</strong>, within lap estimation of <span class="math inline">\(\mathcal{H}\)</span>. Some key questions that <strong>motivate</strong> this research include:</p>
<ul>
<li><p>How does the <strong>velocity</strong> of the rat affect the <span class="math inline">\(\mathcal{H}\)</span> value?</p></li>
<li><p>What patterns does the <span class="math inline">\(\mathcal{H}\)</span> value exhibit over the course of a lap? Does it relate to <strong>other</strong> behavioural variables?</p></li>
<li><p>Can we somehow decode the hippocampal gain <strong>online</strong>, by looking only at the raw neural data? (this is a longer term goal.)</p></li>
</ul>
<p>We turn to <strong>CEBRA</strong> <span class="citation" data-cites="schneider2023">Schneider, Lee, and Mathis (<a href="#ref-schneider2023" role="doc-biblioref">2023</a>)</span> to address this question and explore some potential answers. In the next section, we will see how <strong>CEBRA</strong> can help decode <span class="math inline">\(\mathcal{H}\)</span> reliably.</p>
<p>The basic idea is <strong>as follows</strong>: First, we aim to project the neural data into some latent space (likely, but not necessarily a lower dimensional space). In this space, we want the points to map out the topology of the task - specifically, to encode <strong>hippocampal position</strong> (the rat’s position in the hippocampal reference frame).</p>
<p>We assume that this task forms a <strong>1D ring topology</strong>, given the cyclic nature of the dome setup and the periodic firing of place cells. Our first goal is to validate and construct a latent parametrization of this manifold, specifically designed to directly reflect the <strong>hippocampal position</strong>. With an accurate hippocampal position parametrization, we could then decode <span class="math inline">\(\mathcal{H}\)</span>, giving us a more temporally fine estimation of <span class="math inline">\(\mathcal{H}\)</span>.</p>
<p>Next, we move on to what <strong>CEBRA</strong> is and how it can help us achieve our goal.</p>
</section>
<section id="what-is-cebra" class="level2">
<h2 class="anchored" data-anchor-id="what-is-cebra">What is CEBRA?</h2>
<p><strong>CEBRA</strong>, introduced in <span class="citation" data-cites="schneider2023">Schneider, Lee, and Mathis (<a href="#ref-schneider2023" role="doc-biblioref">2023</a>)</span>, is a powerful self-supervised learning algorithm designed to create consistent, interpretable embeddings of high-dimensional neural recordings using auxiliary variables such as behavior or time. CEBRA generates consistent embeddings across trials, animals, and even different recording modalities​.</p>
<p>In our analysis, we will use the <strong>discovery mode</strong> of CEBRA, with only time as our auxiliary variable. CEBRA is implemented in python, with extensive documentation and demos for users. The code and data used in the paper is open source.</p>
<section id="the-need-for-cebra" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-cebra">The Need for CEBRA</h3>
<p>In neuroscience, understanding how neural populations encode behavior is a large challenge. Traditional linear methods like PCA, or even non-linear approaches like UMAP and t-SNE, fall short because they fail to capture temporal dynamics and lack consistency across different sessions or animals. CEBRA addresses these limitations by using contrastive learning to structure the embedding space around auxiliary variables such as time. The ability to encode temporal information makes CEBRA a powerful tool for analyzing our neural data, as time plays a crucial role in our experimental set up.</p>
</section>
<section id="how-does-cebra-work" class="level3">
<h3 class="anchored" data-anchor-id="how-does-cebra-work">How Does CEBRA Work?</h3>
<p>CEBRA uses a convolutional neural network (CNN) encoder trained with contrastive learning to produce a latent space. The algorithm identifies positive and negative pairs of data points, using temporal proximity to structure the embedding space. For example, in our experiment, data points that are temporally close will be mapped closer together in the latent space, while those further apart in time will be separated​.</p>
</section>
<section id="key-features-of-cebra" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-cebra">Key Features of CEBRA</h3>
<ul>
<li><p><strong>Nonlinear Embedding</strong>: CEBRA allows the discovery of non linear patterns in neural data.</p></li>
<li><p><strong>Consistency Across Sessions and Animals</strong>: Unlike other methods, CEBRA produces embeddings that are consistent across animals and sessions, making it highly generalizable for multi-session or multi-animal experiments.</p></li>
<li><p><strong>Temporal Encoding</strong>: CEBRA captures neural representations with high temporal resolution, enabling finer decoding of neural activity over time.</p></li>
</ul>
</section>
<section id="cebra-architecture" class="level3">
<h3 class="anchored" data-anchor-id="cebra-architecture">CEBRA Architecture</h3>
<section id="cnn" class="level4">
<h4 class="anchored" data-anchor-id="cnn">CNN</h4>
<p>In CEBRA, the first layer is a <strong>Convolutional Neural Network (CNN)</strong>, which serves as the encoder that processes the high-dimensional neural time series data, such as spike trains, into a lower-dimensional latent space. The CNN’s primary role is to transform the neural activity into representations that capture the underlying neural dynamics (in our case, hippocampal place cell firing). The CNN is designed to detect and extract hierarchical features from the neural data. This is especially effective in identifying spatial and temporal patterns in the neural activity. For example, in the case of neural recordings, the CNN could extract firing rate patterns or local correlations between neurons. This is useful for our purposes since we want to know how the neurons relate to one another at a population level as the mouse traverses the dome apparatus. These layers are followed by fully connected layers (typical in a CNN) that map the high-level features into a compact, low-dimensional representation or <strong>embedding</strong>.</p>
</section>
<section id="contrastive-learning" class="level4">
<h4 class="anchored" data-anchor-id="contrastive-learning">Contrastive Learning</h4>
<p>Once the latent space is produced, it is then trained on a network using a <strong>contrastive learning loss function</strong>. In CEBRA, this is achieved through <strong>InfoNCE</strong> (Noise Contrastive Estimation), which encourages the model to distinguish between similar (positive) and dissimilar (negative) samples.</p>
<p>The loss function is defined as:</p>
<p><span class="math display">\[
\mathcal{L} = - \log \frac{\exp(\text{sim}(f(x), f(y^+)) / \tau)}{\exp(\text{sim}(f(x), f(y^+)) / \tau) + \sum_{i=1}^{K} \exp(\text{sim}(f(x), f(y_i^-)) / \tau)}
\]</span></p>
<p>Where f(x) and f(y) are the <strong>encoded representations</strong> of the neural data after passing through the CNN, $ (f(x), f(y)) $ is a similarity measure between two embeddings, implemented as <strong>cosine similarity</strong>, <span class="math inline">\(y^+\)</span> represents the <strong>positive pair</strong> (similar to $ x $ in time), $ y_i^- $ represents the <strong>negative pairs</strong> (dissimilar to $ x $ in time), $ $ is a <strong>temperature parameter</strong> that controls the sharpness of the distribution.</p>
<p>Note that the similarity measure depends on the CEBRA mode used, and we have used time as our similarity measure. The contrastive loss encourages the encoder to map temporally close data points (positive pairs) to close points in the latent space, while mapping temporally distant data points (negative pairs) further apart. This way, the embeddings reflect the temporal structure of the data. The final output is then the embedding value in the latent space. Below is a schematic taken from the original paper, showing the CEBRA architecture.</p>
<p><br></p>
<div id="cebra_pipeline" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/CEBRA_pipeline.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 1 - CEBRA Architecture</figcaption>
</figure>
</div>
</div>
<p><br></p>
<p>Once we obtain the neural embeddings from CEBRA, the next step is to determine the underlying manifold that describes structure of the resulting point cloud. For example, let’s consider the output of a CEBRA embedding from one experimental session.</p>
<p><br></p>
<div id="hipp_angle_no_curve" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/hipp_angle_no_curve.gif" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Figure 2: Cebra Embedding for an experiment with Hippocampal Position Annotated as a Color Map</figcaption>
</figure>
</div>
</div>
<p><br></p>
<p>The embedding appears to form a 1D circle in 3D space. We can also see that the hippocampal position correctly traces the rat’s hippocampal position throughout the experiment. This observation aligns with our expectations, since we predict that the neural activity encodes the <strong>hippocampal reference frame</strong> position, not the <strong>lab frame</strong> position. To validate the 1D ring topology, we apply a technique known as Persistent Homology.</p>
</section>
</section>
</section>
<section id="persistent-homology" class="level2">
<h2 class="anchored" data-anchor-id="persistent-homology">Persistent Homology</h2>
<p>Persistent homology allows us to quantify and verify the topological features of our embedded space. Specifically, we want to validate the assumption that the neural representation forms a 1D ring manifold, which corresponds to the rat’s navigation behavior within the environment. The idea of persistent homology is to create spheres of varying radii around each point in the point cloud, and from those spheres, track how the topological features of the shape change as the radius grows. By systematically increasing the radius, we can observe when distinct clusters merge, when loops (1D holes) appear, and when higher-dimensional voids form. These features persist across different radius sizes, and their persistence provides a measure of their significance. In the context of neural data, this allows us to detect the underlying topological structure of the manifold. Below is a figure describing showing this method <span class="citation" data-cites="schneider2023">Schneider, Lee, and Mathis (<a href="#ref-schneider2023" role="doc-biblioref">2023</a>)</span>:</p>
<p><br></p>
<div id="betti_numbers" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/persistent_cohomology.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Figure 3: Persistent Homology</figcaption>
</figure>
</div>
</div>
<p><br></p>
<section id="validating-a-1d-ring-manifold" class="level3">
<h3 class="anchored" data-anchor-id="validating-a-1d-ring-manifold">Validating a 1D Ring Manifold</h3>
<p>To confirm the circular nature of the embedding, we analyze the Betti numbers derived from the point cloud. Betti numbers describe the topological features of a space, with the $ k $-th Betti number counting the number of $ k $-dimensional “holes” in the manifold. Below is a figure showing a few basic topological spaces and their corresponding Betti numbers <span class="citation" data-cites="walker2008">Walker (<a href="#ref-walker2008" role="doc-biblioref">2008</a>)</span>:</p>
<p><br></p>
<div id="betti_numbers" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/betti_numbers_illustrate.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Figure 3: Some simple topological spaces and their Betti numbers&nbsp;</figcaption>
</figure>
</div>
</div>
<p><br></p>
<p>For a 1D ring, the expected Betti numbers are: <span class="math display">\[
\beta_0 = 1 : \text{One connected component.}
\]</span> <span class="math display">\[
\beta_1 = 1 : \text{One 1D hole (i.e., the circular loop).}
\]</span> <span class="math display">\[
\beta_2 = 0 : \text{No 2D voids.}
\]</span></p>
<p>Thus, the expected Betti numbers for our manifold are (1, 1, 0). If the Betti numbers extracted from the persistent homology analysis align with these values, it confirms that the neural dynamics trace a 1D circular trajectory, supporting our hypothesis that the hippocampal representation forms a ring corresponding to the rat’s navigation path.</p>
</section>
</section>
<section id="spud-method" class="level2">
<h2 class="anchored" data-anchor-id="spud-method">SPUD Method</h2>
<p>Once we’ve validated the assumption that our data forms a 1D ring manifold, we can proceed to fitting a spline to the data. There are many different methods, but the one chosen for this purpose was taken from <span class="citation" data-cites="chaudhuri2019">Chaudhuri et al. (<a href="#ref-chaudhuri2019" role="doc-biblioref">2019</a>)</span>, called Spline Parametrization and SPUD. They worked with similar experiments and goals. The spline is defined by a set of points, or knots, which are initialized using kmedoids clustering <span class="citation" data-cites="jin2011">Jin and Han (<a href="#ref-jin2011" role="doc-biblioref">2011</a>)</span>. The knots are then fit to the data further by minimizing a loss function defined as follows:</p>
<p><span class="math display">\[
\text{cost} = \text{dist} + \text{curvature} + \text{length} - \text{log(density)}
\]</span></p>
<p>where <em>dist</em> is the distance of each point to the spline, <em>curvature</em> is the total curvature of the spline, <em>length</em> is the total length of the spline, and <em>density</em> is the point cloud density of each knot.</p>
<section id="overview-of-the-spud-method" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-the-spud-method">Overview of the SPUD Method</h3>
<p>Spline Parameterization for Unsupervised Decoding (SPUD) <span class="citation" data-cites="chaudhuri2019">Chaudhuri et al. (<a href="#ref-chaudhuri2019" role="doc-biblioref">2019</a>)</span> is a multi-step method designed to parametrize a neural manifold. The goal of SPUD is to provide an <strong>on-manifold local parameterization</strong> using a <strong>local coordinate system</strong> rather than a global one. This method is particularly useful when dealing with <strong>topologically non-trivial variables</strong> that have a circular structure. The researchers developed this method to understand head direction representations in rats moving in a 2D environment.</p>
<p><strong>Spline Parameterization</strong>: SPUD parameterizes the manifold by first fitting a spline to the underlying structure. <span class="citation" data-cites="chaudhuri2019">Chaudhuri et al. (<a href="#ref-chaudhuri2019" role="doc-biblioref">2019</a>)</span> demonstrated that this works for head direction cells in mice to accurately parametrize, i.e.&nbsp;decode the head direction. Our goal is to have the parametrization accurately decode our latent variable of interest, the Hippocampal Gain (<span class="math inline">\(\mathcal{H}\)</span>).</p>
</section>
<section id="deciding-the-parameterization-of-the-latent-variable" class="level3">
<h3 class="anchored" data-anchor-id="deciding-the-parameterization-of-the-latent-variable">Deciding the Parameterization of the Latent Variable</h3>
<section id="natural-parametrization" class="level4">
<h4 class="anchored" data-anchor-id="natural-parametrization">Natural Parametrization</h4>
<p>A <strong>natural parameterization</strong> would mean that equal distances in the embedding space correspond to equal changes in the latent variable. The belief in the <strong>natural parameterization</strong> is rooted in the idea that neural systems allocate resources based on the significance or frequency of stimuli. For example, in systems like the visual cortex, stimuli that occur frequently (e.g., vertical or horizontal orientations) might be encoded with higher resolution. However, for systems like head direction, where all angles are equally probable, the natural parameterization reflects this uniform encoding strategy, with no overrepresentation of certain angles (<span class="citation" data-cites="chaudhuri2019">Chaudhuri et al. (<a href="#ref-chaudhuri2019" role="doc-biblioref">2019</a>)</span>). This would be expected with the hippocampal formation as well, that no place in a non biased circular maze should be allocated extra resources than another place in the maze.</p>
</section>
<section id="alternative-parameterization-and-its-limitations" class="level4">
<h4 class="anchored" data-anchor-id="alternative-parameterization-and-its-limitations">Alternative Parameterization and its Limitations</h4>
<p>An alternative parameterization method was considered, in which intervals between consecutive knots in the spline were set to represent equal changes in the latent variable. This approach was designed to counteract any potential biases in the data due to over- or under-sampling in certain regions of the manifold.</p>
<p>However, this alternative was not determined to be effective in practice by <span class="citation" data-cites="chaudhuri2019">Chaudhuri et al. (<a href="#ref-chaudhuri2019" role="doc-biblioref">2019</a>)</span>. Given sufficient data, the natural parameterization performed better, supporting the conclusion that it better reflects how neural systems encode variables. In preliminary results, this is what seems to be the case for our experiment. Look to the following figure, in which a spline is fit to the data and a color map is applied to the natural parametrization. We can see that it aligns almost exactly with the hippocampal angle. Great, that’s exactly what we wanted!</p>
<p><br></p>
<div id="hipp_angle_with_curve" class="cell figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/hipp_angle.gif" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Figure 4: Spline fit on CEBRA embedding</figcaption>
</figure>
</div>
</div>
<p><br></p>
<p>So, what do we do now?</p>
</section>
</section>
</section>
<section id="decoding-hippocampal-gain-mathcalh" class="level2">
<h2 class="anchored" data-anchor-id="decoding-hippocampal-gain-mathcalh">Decoding Hippocampal Gain (<span class="math inline">\(\mathcal{H}\)</span>)</h2>
<section id="final-step" class="level3">
<h3 class="anchored" data-anchor-id="final-step">Final Step</h3>
<p>The next step is to determine if we can accurately decode Hippocampal Gain from the CEBRA embedding <em>alone</em>. The method to do this is straightforward (after all the setup is complete). Once we have parametrized the spline accurately to the neural data, we calculate the hippocampal gain by comparing the distance traveled in the neural manifold (derived from our spline) to the distance in the lab frame (actual movement of the rat).</p>
<p>The idea is that:</p>
<p><span class="math display">\[
\mathcal{H} = \frac{d\theta_\mathcal{H}}{d\theta_\mathcal{L}}
\]</span></p>
<p>where <span class="math inline">\(\theta_H\)</span> is the change in distance in the hippocampal reference frame, decoded from our spline parametrization of the neural manifold, and <span class="math inline">\(\theta_L\)</span> is the physical distance traveled by the rat in the lab frame.</p>
<p>Note that this is actually just the original definition of $ $, but now <span class="math inline">\(\theta_H\)</span> is determined by our spline parameter, not the Fourier Transform method.</p>
<p>For example, let’s take a time interval, say 1–2 seconds. To determine the hippocampal gain within that frame, we observe where the neural activity at times 1 and 2 maps in our manifold, calling these $ <em>{H1} $ and $ </em>{H2} $, respectively. Then, using the lab frame angles at times 1 and 2, which we’ll call $ <em>{L1} $ and $ </em>{L2} $, we find that:</p>
<p><span class="math display">\[
  \mathcal{H}(\text{between } t=1 \text{ and } t=2) = \frac{\theta_{\mathcal{H2}} - \theta_{\mathcal{H1}}}{\theta_{\mathcal{L2}} - \theta_{\mathcal{L1}}}
\]</span></p>
<p>We can apply this approach to any time interval (up to our sampling rate) to determine our <span class="math inline">\(H\)</span> value with precision.</p>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>Next steps will be to first validate our natural parametrization quantitavely among the many experiments to see how accurately it decodes hippocampal position. And then to actually decode the hippocampal gain and explore the results we get and (hopefully) gain new insights into the neural mechanisms of navigation.</p>
<ol type="1">
<li><p><strong>Validate the Natural Parametrization</strong>: We will quantitatively assess the accuracy of our natural parametrization across multiple experiments to ensure it reliably decodes hippocampal position. This validation will confirm that the manifold is a faithful representation of the neural dynamics.</p></li>
<li><p><strong>Decode the Hippocampal Gain</strong>: Once validated, we will proceed with decoding the hippocampal gain (<span class="math inline">\(H\)</span>) from the neural manifold and explore the results. This analysis will allow us to gain new insights into the neural mechanisms underlying navigation and path integration, potentially revealing novel aspects of how the hippocampus processes spatial information.</p></li>
<li><p><strong>Apply to New Sessions</strong>: We can then leverage the cross-session consistency of CEBRA embeddings to apply this method to knew experimental sessions and modalities.</p></li>
</ol>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-behrens2018" class="csl-entry" role="listitem">
Behrens, Timothy E. J., Timothy H. Muller, James C. R. Whittington, Shirley Mark, Alon B. Baram, Kimberly L. Stachenfeld, and Zeb Kurth-Nelson. 2018. <span>“What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior.”</span> <em>Neuron</em> 100 (2): 490–509. <a href="https://doi.org/10.1016/j.neuron.2018.10.002">https://doi.org/10.1016/j.neuron.2018.10.002</a>.
</div>
<div id="ref-chaudhuri2019" class="csl-entry" role="listitem">
Chaudhuri, Rishidev, Berk Gerçek, Biraj Pandey, Adrien Peyrache, and Ila Fiete. 2019. <span>“The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit Across Waking and Sleep.”</span> <em>Nature Neuroscience</em> 22: 1512–20. <a href="https://doi.org/10.1038/s41593-019-0460-x">https://doi.org/10.1038/s41593-019-0460-x</a>.
</div>
<div id="ref-jayakumar2019" class="csl-entry" role="listitem">
Jayakumar, Ravikrishnan P., Manu S. Madhav, Francesco Savelli, Hugh T. Blair, Noah J. Cowan, and James J. Knierim. 2019. <span>“Recalibration of Path Integration in Hippocampal Place Cells.”</span> <em>Nature</em> 566 (February): 533–37. <a href="https://doi.org/10.1038/s41586-019-0939-3">https://doi.org/10.1038/s41586-019-0939-3</a>.
</div>
<div id="ref-jin2011" class="csl-entry" role="listitem">
Jin, Xiang, and Jiawei Han. 2011. <span>“K-Medoids Clustering.”</span> In <em>Encyclopedia of Machine Learning</em>, edited by Claude Sammut and Geoffrey I. Webb. Boston, MA: Springer. <a href="https://doi.org/10.1007/978-0-387-30164-8_426">https://doi.org/10.1007/978-0-387-30164-8_426</a>.
</div>
<div id="ref-madhav2024" class="csl-entry" role="listitem">
Madhav, Manu S., Ravikrishnan P. Jayakumar, Brian Y. Li, Shahin G. Lashkari, Kelly Wright, Francesco Savelli, James J. Knierim, and Noah J. Cowan. 2024. <span>“Control and Recalibration of Path Integration in Place Cells Using Optic Flow.”</span> <em>Nature Neuroscience</em>. <a href="https://doi.org/10.1038/s41593-024-01681-9">https://doi.org/10.1038/s41593-024-01681-9</a>.
</div>
<div id="ref-schneider2023" class="csl-entry" role="listitem">
Schneider, Steffen, Jin Hwa Lee, and Mackenzie Weygandt Mathis. 2023. <span>“Learnable Latent Embeddings for Joint Behavioural and Neural Analysis.”</span> <em>Nature</em> 617: 360–68. <a href="https://doi.org/10.1038/s41586-023-05842-x">https://doi.org/10.1038/s41586-023-05842-x</a>.
</div>
<div id="ref-walker2008" class="csl-entry" role="listitem">
Walker, Brenton. 2008. <span>“Using Persistent Homology to Recover Spatial Information from Encounter Traces.”</span> <em>In Proceedings of the ACM</em>. <a href="https://doi.org/10.1145/1374618.1374668">https://doi.org/10.1145/1374618.1374668</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/bioshape-analysis\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>