[
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html",
    "href": "posts/outlier-detection/DeCOr-MDS.html",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "",
    "text": "Multidimensional scaling (MDS) is known to be sensitive to such orthogonal outliers, we present here a robust MDS method, called DeCOr-MDS, short for Detection and Correction of Orthogonal outliers using MDS. DeCOr-MDS takes advantage of geometrical characteristics of the data to reduce the influence of orthogonal outliers, and estimate the dimension of the dataset. The full paper is available at Li et al. (2023)."
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#multidimensional-scaling-mds",
    "href": "posts/outlier-detection/DeCOr-MDS.html#multidimensional-scaling-mds",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Multidimensional scaling (MDS)",
    "text": "Multidimensional scaling (MDS)\nMDS is a statistical technique used for visualizing data points in a low-dimensional space, typically two or three dimensions. It is particularly useful when the data is represented in the form of a distance matrix, where each entry indicates the distance between pairs of items. MDS aims to place each item in this lower-dimensional space in such a way that the distances between the items are preserved as faithfully as possible. This allows complex, high-dimensional data to be more easily interpreted, as the visual representation can reveal patterns, clusters, or relationships among the data points that might not be immediately apparent in the original high-dimensional space. MDS is widely used in fields such as psychology, market research, and bioinformatics for tasks like visualizing similarities among stimuli, products, or genetic sequences (Carroll and Arabie 1998; Hout, Papesh, and Goldinger 2013)."
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#orthogonal-outliers",
    "href": "posts/outlier-detection/DeCOr-MDS.html#orthogonal-outliers",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Orthogonal outliers",
    "text": "Orthogonal outliers\nOutlier detection has been widely used in biological data. Sheih and Yeung proposed a method using principal component analysis (PCA) and robust estimation of Mahalanobis distances to detect outlier samples in microarray data (Shieh and Hung 2009). Chen et al. reported the use of two PCA methods to uncover outlier samples in multiple simulated and real RNA-seq data (Oh, Gao, and Rosenblatt 2008). Outlier influence can be mitigated depending on the specific type of outlier. In-plane outliers and bad leverage points can be harnessed using \\(\\ell_1\\)-norm Forero and Giannakis (2012), correntropy or M-estimators (Mandanas and Kotropoulos 2017). Outliers which violate the triangular inequality can be detected and corrected based on their pairwise distances (Blouvshtein and Cohen-Or 2019). Orthogonal outliers are another particular case, where outliers have an important component, orthogonal to the hyperspace where most data is located. These outliers often do not violate the triangular inequality, and thus require an alternative approach."
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#height-and-volume-of-n-simplices",
    "href": "posts/outlier-detection/DeCOr-MDS.html#height-and-volume-of-n-simplices",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Height and Volume of n-simplices",
    "text": "Height and Volume of n-simplices\nWe recall some geometric properties of simplices, which our method is based on. For a set of \\(n\\) points \\((x_1,\\ldots, x_n)\\), the associated \\(n\\)-simplex is the polytope of vertices \\((x_1,\\ldots, x_n)\\) (a 3-simplex is a triangle, a 4-simplex is a tetrahedron and so on). The height \\(h(V_{n},x)\\) of a point \\(x\\) belonging to a \\(n\\)-simplex \\(V_{n}\\) can be obtained as (Sommerville 1929), \\[\n  h(V_{n},x) = n \\frac{V_n}{V_{n-1}},\n\\tag{1}\\] where \\(V_{n}\\) is the volume of the \\(n\\)-simplex, and \\(V_{n-1}\\) is the volume of the \\((n-1)\\)-simplex obtained by removing the point \\(x\\). \\(V_{n}\\) and \\(V_{n-1}\\) can be computed using the pairwise distances only, with the Cayley-Menger formula (Sommerville 1929):\n\\[\\begin{equation}\n\\label{eq:Vn}\nV_n = \\sqrt{\\frac{\\vert det(CM_n)\\vert}{2^n \\cdot (n!)^2}},\n\\end{equation}\\]\nwhere \\(det(CM_n)\\) is the determinant of the Cayley-Menger matrix \\(CM_n\\), that contains the pairwise distances \\(d_{i,j}=\\left\\lVert x_i -x_j \\right\\rVert\\), as \\[\\begin{equation}\n  CM_n = \\left[ \\begin{array}{cccccc} 0 & 1 & 1 & ... & 1 & 1 \\\\\n\n  1 & 0 & d_{1,2}^2 & ... & d_{1,n}^2 & d_{1,n+1}^2 \\\\\n  1 & d_{2,1}^2 & 0 & ... & d_{2,n}^2 & d_{2,n+1}^2 \\\\\n  ... & ... & ... & ... & ... & ... \\\\\n  1 & d_{n,1}^2 & d_{n,2}^2 & ... & 0 & d_{n,n+1}^2 \\\\\n  1 & d_{n+1,1}^2 & d_{n+1,2}^2 & ... & d_{n+1,n}^2 & 0 \\\\\n  \\end{array}\\right].\n\\end{equation}\\]"
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#sec-part1",
    "href": "posts/outlier-detection/DeCOr-MDS.html#sec-part1",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Orthogonal outlier detection and dimensionality estimation",
    "text": "Orthogonal outlier detection and dimensionality estimation\nWe now consider a dataset \\(\\mathbf{X}\\) of size \\(N\\times d\\), where \\(N\\) is the sample size and \\(d\\) the dimension of the data. We associate with \\(\\mathbf{X}\\) a matrix \\(\\mathbf{D}\\) of size \\(N\\times N\\), which represents all the pairwise distances between observations of \\(\\mathbf{X}\\). We also assume that the data points can be mapped into a vector space with regular observations that form a main subspace of unknown dimension \\(d^*\\) with some small noise, and additional orthogonal outliers of relatively large orthogonal distance to the main subspace (see Figure 1.A). Our proposed method aims to infer from \\(\\mathbf{D}\\) the dimension of the main data subspace \\(d^*\\), using the geometric properties of simplices with respect to their number of vertices: Consider a \\((n+2)\\)-simplex containing a data point \\(x_i\\) and its associated height, that can be computed using equation Equation 1. When \\(n&lt;d^*\\) and for \\(S\\) large enough, the distribution of heights obtained from different simplices containing \\(x_i\\) remains similar, whether \\(x_i\\) is an orthogonal outlier or a regular observation (see Figure 1.B). In contrast, when \\(n\\geq d^*\\), the median of these heights approximately yields the distance of \\(x_i\\) to the main subspace (see Figure 1.C). This distance should be significantly larger when \\(x_i\\) is an orthogonal outlier, compared with regular points, for which these distances are tantamount to the noise.\n\n\n\n\n\n\nFigure 1: Example of a dataset with orthogonal outliers and n-simplices. Representation of a dataset with regular data points (blue) belonging to a main subspace of dimension 2 with some noise, and orthogonal outliers (red triangle symbols) in the third dimension. View of two instances of 3-simplices (triangles), one with only regular points (left) and the other one containing one outlier (right). The height drawn from the outlier is close to the height of the regular triangle. Upon adding other regular points to obtain tetrahedrons (4-simplices), the height drawn from the outlier (right) becomes significantly larger than the height drawn from the same point (left) as in .\n\n\n\nTo estimate \\(d^*\\) and for a given dimension \\(n\\) tested, we thus randomly sample, for every \\(x_i\\) in \\(\\mathbf{X}\\), \\(S(n+2)\\)-simplices containing \\(x_i\\), and compute the median of the heights \\(h_i^n\\) associated with these \\(S\\) simplices. Upon considering, as a function of the dimension \\(n\\) tested, the distribution of median heights \\((h_1^{n},...,h_N^{n})\\) (with \\(1\\leq i \\leq N\\)), we then identify \\(d^*\\) as the dimension at which this function presents a sharp transition towards a highly peaked distribution at zero. To do so, we compute \\(\\tilde{h}_n\\), as the mean of \\((h_1^{n},...,h_N^{n})\\), and estimate \\(d^*\\) as\n\\[\\begin{equation}\n  \\bar{n}=\\underset{n}{\\operatorname{argmax}} \\frac{\\tilde{h}_{n-1}}{\\tilde{h}_{n}}.\n  \\label{Eq:Dim}\n\\end{equation}\\]\nFurthermore, we detect orthogonal outliers using the distribution obtained in \\(\\bar{n}\\), as the points for which \\(h_i^{\\bar{n}}\\) largely stands out from \\(\\tilde{h}_{\\bar{n}}\\). To do so, we compute \\(\\sigma_{\\bar{n}}\\) the standard deviation observed for the distribution \\((h_1^{\\bar{n}},...,h_N^{\\bar{n}})\\), and obtain the set of orthogonal outliers \\(\\mathbf{O}\\) as\n\\[\n  \\mathbf{O}= \\left\\{ i\\;|\\;h_i^{\\bar{n}}&gt; \\tilde{h}_{\\bar{n}} + c \\times \\sigma_{\\bar{n}} \\right\\},\n\\tag{2}\\]\nwhere \\(c&gt;0\\) is a parameter set to achieve a reasonable trade-off between outlier detection and false detection of noisy observations."
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#correcting-the-dimensionality-estimation-for-a-large-outlier-fraction",
    "href": "posts/outlier-detection/DeCOr-MDS.html#correcting-the-dimensionality-estimation-for-a-large-outlier-fraction",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Correcting the dimensionality estimation for a large outlier fraction",
    "text": "Correcting the dimensionality estimation for a large outlier fraction\nThe method presented in the previous section assumes that at dimension \\(d^*\\), the median height calculated for each point reflects the distance to the main subspace. This assumption is valid when the fraction of orthogonal outliers is small enough, so that the sampled \\(n\\)-simplex likely contains regular observations only, aside from the evaluated point. However, if the number of outliers gets large enough so that a significant fraction of \\(n\\)-simplices %drawn to compute a height also contains outliers, then the calculated heights would yield the distance between \\(x_i\\) and an outlier-containing hyperplane, whose dimension is larger than a hyperplane containing only regular observations. The apparent dimensionality of the main subspace would thus increase and generates a positive bias on the estimate of \\(d^*\\).\nSpecifically, if \\(\\mathbf{X}\\) contains a fraction of \\(p\\) outliers, and if we consider \\(o_{n,p,N}\\) the number of outliers drawn after uniformly sampling \\(n+1\\) points (to test the dimension \\(n\\)), then \\(o_{n,p,N}\\) follows a hypergeometric law, with parameters \\(n+1\\), the fraction of outliers \\(p=N_o/N\\), and \\(N\\). Thus, the expected number of outliers drawn from a sampled simplex is \\((n+1) \\times p\\). After estimating \\(\\bar{n}\\) (from Section 3.1), and finding a proportion of outliers \\(\\bar p = |\\mathbf{O}|/N\\) using Equation 2, we hence correct \\(\\bar{n}\\) by substracting the estimated bias \\(\\delta\\), as the integer part of the expectation of \\(o_{n,p,N}\\), so the debiased dimensionality estimate \\(n^*\\) is\n\\[\\begin{equation}\n  n^* =\\bar{n} - \\lfloor (\\bar{n}+1) \\times p \\rfloor.\n  \\label{eq:corrected_n}\n\\end{equation}\\]"
  },
  {
    "objectID": "posts/outlier-detection/DeCOr-MDS.html#outlier-distance-correction",
    "href": "posts/outlier-detection/DeCOr-MDS.html#outlier-distance-correction",
    "title": "Orthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets",
    "section": "Outlier distance correction",
    "text": "Outlier distance correction\nUpon identifying the main subspace containing regular points, our procedure finally corrects the pairwise distances that contain outliers in the matrix \\(\\mathbf{D}\\), in order to apply a MDS that projects the outliers in the main subspace. In the case where the original coordinates cannot be used (e.g, as a result of some transformation or if the distance is non Euclidean), we perform the two following steps: (i) We first apply a MDS on \\(\\mathbf{D}\\) to place the points in a euclidean space of dimension \\(d\\), as a new matrix of coordinates \\(\\tilde{X}\\). (ii) We run a PCA on the full coordinates of the estimated set of regular data points (i.e. \\(\\tilde{X}\\setminus O\\)), and project the outliers along the first \\(\\bar{n}^*\\) principal components of the PCA, since these components are sufficient to generate the main subspace. Using the projected outliers, we accordingly update the pairwise distances in \\(\\mathbf{D}\\) to obtain the corrected distance matrix \\(\\mathbf{D^*}\\). Note that in the case where \\(\\mathbf{D}\\) derives from a euclidean distance between the original coordinates, we can skip step (i), and directly run step (ii) on the full coordinates of the estimated set of regular data points."
  },
  {
    "objectID": "posts/sy mds tunnel/index.html",
    "href": "posts/sy mds tunnel/index.html",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "",
    "text": "The ribosome exit tunnel is a sub-compartment of the ribosome whose geometry varies significantly across species, potentially affecting the translational dynamics and co-translational folding of nascent polypeptide1.\nAs the recent advances in imaging technologies result in a surge of high-resolution ribosome structures, we are now able to study the tunnel geometric heterogeneity comprehensively across three domains of life: bacteria, archaea and eukaryotes.\nHere, we present some methods for large-scale analysis and comparison of tunnel structures."
  },
  {
    "objectID": "posts/sy mds tunnel/index.html#summary-and-background",
    "href": "posts/sy mds tunnel/index.html#summary-and-background",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "",
    "text": "The ribosome exit tunnel is a sub-compartment of the ribosome whose geometry varies significantly across species, potentially affecting the translational dynamics and co-translational folding of nascent polypeptide1.\nAs the recent advances in imaging technologies result in a surge of high-resolution ribosome structures, we are now able to study the tunnel geometric heterogeneity comprehensively across three domains of life: bacteria, archaea and eukaryotes.\nHere, we present some methods for large-scale analysis and comparison of tunnel structures."
  },
  {
    "objectID": "posts/sy mds tunnel/index.html#tunnel-shape",
    "href": "posts/sy mds tunnel/index.html#tunnel-shape",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "Tunnel Shape",
    "text": "Tunnel Shape\nThe ribosome exit tunnel spans from the peptidyl-transferase center (PTC), where amino acids are polymerized onto the growing nascent chain, to the surface of the ribosome.\nTypically, it measures 80-100 Å in length and 10-20 Å in diameter. While the eukaryotic tunnels are, on average, shorter and substantially narrower than prokaryote ones1.\nIn all domains of life, the tunnel features a universally conserved narrow region downstream of the PTC, so-called constriction site. However, the eukaryotic exit tunnel exhibit an additional (second) constriction site due to the modified structure of the surrounding ribosomal proteins.\n\n\n\nIllustration of the tunnel structure of H.sapiens."
  },
  {
    "objectID": "posts/sy mds tunnel/index.html#ribosome-dataset",
    "href": "posts/sy mds tunnel/index.html#ribosome-dataset",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "Ribosome Dataset",
    "text": "Ribosome Dataset\nCryo-EM reconstructions and X-ray crystallography structures of ribosomes were retrived from the Protein Data Bank (https://www.rcsb.org) including 762 structures across 34 species domain.\nThe exit tunnels were extracted from the ribosomes using our developed tunnel-searching pipeline based on the MOLE cavity extraction algorithm developed by Sehnal et al.2."
  },
  {
    "objectID": "posts/sy mds tunnel/index.html#pairwise-distance",
    "href": "posts/sy mds tunnel/index.html#pairwise-distance",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "Pairwise Distance",
    "text": "Pairwise Distance\nTo simplify the geomertic comparisons, we first reduced the tunnel structure into a coordinate set that describes both the centerline trajectory and the tunnel radius at each centerline position,\nWe then applied the pairwise distance metrics developed by Dao Duc et al.1 to compute the geometric similarity between tunnels. More details can be found in the previous work1.\n\n\n\nPairwise comparison of radial varaition plots between H.sapiens and E.coli"
  },
  {
    "objectID": "posts/sy mds tunnel/index.html#mds",
    "href": "posts/sy mds tunnel/index.html#mds",
    "title": "Multi Dimensional Scaling of ribosome exit tunnel shapes",
    "section": "MDS",
    "text": "MDS\nThe Multidimensional Scaling (MDS) method developed by Li et al.3 was applied on the pairwise distance matrix to visualize the geometric similarity of tunnels. Each data point represents a single tunnel structure, and the Euclidean distance between data points represents the similarity.\n\n\n\nMDS plot of tunnel structures across prokaryotes and eukaryotes"
  },
  {
    "objectID": "posts/AFM-data/index.html",
    "href": "posts/AFM-data/index.html",
    "title": "Extracting cell geometry from Atomic Force Microscopy",
    "section": "",
    "text": "We present here the protocole to process biological images such as bacteria atomic force miroscopy data. We want to study the bacteria cell shape and extract the main geometrical feature."
  },
  {
    "objectID": "posts/AFM-data/index.html#biological-context",
    "href": "posts/AFM-data/index.html#biological-context",
    "title": "Extracting cell geometry from Atomic Force Microscopy",
    "section": "Biological context",
    "text": "Biological context\nMycobacterium smegmatis is Grahm-positive rod shape bacterium. It is 3 to 5 \\(\\mu m\\) long and around 500 \\(nm\\) wide. This non-pathogenic species is otften used a biological model to study the pathogenic Mycobacteria such as M.tuberculosis (responsible for the tubercuosis) or M.abscessus, with which it shares the same cell wall structure (Tyagi and Sharma 2002). In particular M.smegmatis has a fast growth (3-4 hours doubling time compared to 24h for M. tuberculosis), allowing for faster experimental protocols.\nHere are some know properties of M.smegmatis bacteria :\n\nThey present variation of cell diameter along their longitudinal axis (Eskandarian et al. 2017). The cell diameter is represented as a height profile along the cell centerline. We respectively name peaks and troughs the local maxima and minima of this profile.\n\n\n\n\n3D image of M.smegmatis. The orange line represents the height profile.\n\n\n\nThey grow following a biphasic and asymetrical polar dynamics (Hannebelle et al. 2020). The cells elongate from the poles, where material is added. After division, the pre-existing pole (OP) elongate at a high rate, whereas the newly created pole (NP) has first a slow growth, and then switches to a fast growth, after the New End Take Off (NETO).\n\n\n\n\nGrowth dynamics."
  },
  {
    "objectID": "posts/AFM-data/index.html#raw-image-pre-processing",
    "href": "posts/AFM-data/index.html#raw-image-pre-processing",
    "title": "Extracting cell geometry from Atomic Force Microscopy",
    "section": "Raw image pre-processing",
    "text": "Raw image pre-processing\n\nData\nSeveral data acquisitions were conducted with wild types and different mutant strains. The raw data is composed of AFM log files times series for each experiments. Each log file contain several images, each one representing a physical channel such as height, stiffness, adhesion etc. After extraction of the data, forward and backward cells are aligned, artefacts such as image scars are detected and corrected.\n\n\n\nAt each time step, images representing different physical variables are produced by the AFM"
  },
  {
    "objectID": "posts/AFM-data/index.html#segmentation",
    "href": "posts/AFM-data/index.html#segmentation",
    "title": "Extracting cell geometry from Atomic Force Microscopy",
    "section": "Segmentation",
    "text": "Segmentation\nAt each time steps, images are segmented to detect each cells using the cellpose package (Stringer et al. 2021). If available, different physical channels are combined to improve the segmentation. Forward and backward images are also combined.\n\n\n\nImages are combined to improve the segmentation\n\n\nHere is an example on how to use cellpose on an image. Different models are available (with the seg_mod variable), depending on the training datasets. With cellpose 3, different denoising models are also available (with the denoise_mod variable).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom cellpose import io, denoise, plot\nfrom PIL import Image\n\n\n'''\nParameters\n'''\n\nimage_path = 'raw_img.png'\npath_to_save = 'segmented_img'\n# Segmentation model type\nseg_mod = 'cyto'   \n# Denoizing model\ndenoise_mod = \"denoise_cyto3\"  \n# Expected cell diameter (pixels)\ndia = 40\n# Type of segmentation (with / without nuclei, different color channels or not)\nchan = [0,0] \n# Segmentation sensibility parameters\nthres = 0.8\ncelp = 0.4\n\n'''\nComputing segmentation\n'''\n\n\n# Opening image to segment\nimg=np.array(Image.open(image_path))[:,:,1]\n\n# Chosing a model type :\nmodel = denoise.CellposeDenoiseModel(gpu=False, model_type=seg_mod, restore_type=denoise_mod)\n\n# Computing segmentaion\nmasks, flows, st, diams = model.eval(img, diameter = dia, channels=chan, flow_threshold = thres, cellprob_threshold=celp)\n\n\n# Saving the results into a numpy file\nio.masks_flows_to_seg(img, masks, flows, path_to_save, channels=chan, diams=diams)\n\n\nWe plot the final results :\n\n\nCode\nplt.imshow(img,cmap='gray')\nplt.show()\n\n\n\n\n\nRaw image\n\n\n\n\n\n\nCode\nmask_RGB = plot.mask_overlay(img,masks)\nplt.imshow(mask_RGB)\nplt.show()\n\n\n\n\n\nImage with segmented masks overlaid"
  },
  {
    "objectID": "posts/AFM-data/index.html#centerline",
    "href": "posts/AFM-data/index.html#centerline",
    "title": "Extracting cell geometry from Atomic Force Microscopy",
    "section": "Centerline",
    "text": "Centerline\nSince we are interested in studying the variations of the cell diameter, we define height profile as the value of the cell height along the cell centerline. The cell centerline are computed using a skeletonization algorithm Lee, Kashyap, and Chu (1994). Here is an example of skeletonization\n\n\nCode\nfrom skimage.morphology import skeletonize\n\n# Selecting first mask\nfirst_mask =  masks == 1\n\nskel_img = skeletonize(first_mask, method='lee')  \nskel = np.argwhere(skel_img)\nplt.imshow(first_mask, cmap='gray')\n\nplt.scatter(skel[:,1], skel[:,0], 0.5*np.ones(np.shape(skel[:,0])), color='r', marker='.')\nplt.show()\n\n\n\n\n\n\n\n\n\nDepending on the masks shapes, centerlines may have branches :\n\n\nCode\nfrom skimage.morphology import skeletonize\n\n# Selecting first mask\nfirst_mask =  masks == 3\n\nskel_img = skeletonize(first_mask)  #, method='lee'\nskel = np.argwhere(skel_img)\nplt.imshow(first_mask, cmap='gray')\n\nplt.scatter(skel[:,1], skel[:,0], 0.5*np.ones(np.shape(skel[:,0])), color='r', marker='.')\nplt.show()\n\n\n\n\n\n\n\n\n\nIn practice, centerlines are pruned and extended to the cell poles, in order to capture the cell length. Other geometrical properties such as masks centroids or outlines are computed as well.\n\n\n\nFinal static processing results in real life data. White masks are excluded from the cell tracking algorithm (see part 2). Black dots are cell centroids. The yellow boxes represent artefacts cleaning."
  },
  {
    "objectID": "posts/cvt/index.html",
    "href": "posts/cvt/index.html",
    "title": "Centroidal Voronoi Tessellation",
    "section": "",
    "text": "Introduction\nIn this post we briefly explained Centroidal Voronoi Tessellation (CVT) as a point sampling method and how it rises from the Optimal Transport (OT) theory. Here we will explain the theory behing this method and prove the relation between CVT and OT.\n\n\nVoronoi cells and Centroidal Voronoi Tessellation\nAssume \\((X,d)\\) is a metric space. Given a set of \\(n\\) points \\(a_1,\\dots,a_n \\in X\\), the Voronoi diagram (Aurenhammer 1991) is formed by \\(n\\) cells \\(V_1,\\dots,V_n \\subset X\\) where \\(V_i\\) is defined as \\[V_i = \\{x \\in X | d(x, a_j) \\ge d(x,a_i) \\quad \\forall 1  \\le j \\le n \\},\\] and \\(a_i\\) is called the generator of \\(V_i\\). In addition, for all \\(x \\in X\\), let \\(i(x)\\) denote the index such that \\(x \\in V_{i(x)}\\). Bellow is an example of Voronoi diagrams formed by 20 points in \\([0, 1]^2\\) with \\(l_2\\) (right) and \\(l_1\\) (left) norm.\n\n\n\nAn example of Voronoi diagram formed by \\(l_1\\) (right) and \\(l_2\\) (left) norms.\n\n\nFor the rest of this post we assume \\(X\\) is \\(\\mathbb{R}^2\\) or \\(\\mathbb{R}^3\\) and \\(d\\) is the eclidean distance. For a given probability distribution \\(\\mathbf{p}\\) over \\(X\\), we say \\(a_1,\\dots,a_n \\in X\\) form a Centroidal Voronoi Tessellation if considering the Voronoi cells \\(V_1,\\dots,V_n\\) generated by them, we have \\[a_i = \\int_{V_i}x\\mathbf{p}(x)dx (\\forall 1 \\le i \\le n),\\] i.e., \\(a_i\\) is both the generator and the centroid of \\(V_i\\). Below an example of such a tessellation over a square with uniform distribution is illustrated.\n\n\n\nAn example of Centroidal Voronoi Tessellation formed by 5 points on a square with uniform distribution.\n\n\n\n\nSemidiscrete Wasserstein distance\nSemidescrete Wasserstein distance is a variant of Optimal Transport problem, specifically designed for comparing a discrete and a continuous probability distribution. Assume \\((X, d)\\) is a metric space, given a set of weighted points \\(\\mathbf{A} = \\{a_1,\\dots,a_n\\}\\) and weights \\(w_1 + \\dots + w_n = 1\\) we define the distribution \\(\\mathbf{p_A} = \\sum_i w_i \\delta_{a_i}\\), where \\(\\delta_{a_i}\\) is the Dirac delta function located at \\(a_i\\). Like the previouse section we assume \\(\\mathbf{p}\\) is a given distribution over \\(X\\). With this setting the non-regularized semidiscrete Wasserstein distance between \\(\\mathbf{p_A}\\) and \\(\\mathbf{p}\\), denoted \\(\\mathcal{W}(\\mathbf{p},\\mathbf{p_A})\\), is defined as\n\\[\n\\mathcal{W}(\\mathbf{p},\\mathbf{p_A}) = [\\min_{P : X \\times [n] \\rightarrow \\mathbb{R}_+} \\quad  \\ \\int_{X} \\sum_{i=1}^n d(x,a_i)P(x,i)dx]^{1/2} \\tag{1}\\] \\[\n\\textrm{s.t.} \\quad  \\int_X P(x,i)dx = w_i, \\sum_{i=1}^n P(x,i) = \\mathbf{p}(x).\n\\] Just like the previouse section we assume \\(X = \\mathbb{R}^2\\) or \\(\\mathbb{R}^3\\) and \\(d\\) is the equclidean distance for the rest of this post.\n\n\nThe relation of CVT and Semidiscrete Wasserstein distance\nAssume we are given \\(\\mathbf{p}\\) and we want to find a weighted point set \\(\\mathbf{A}\\) that minimizes \\[\\min_{w_i \\in \\mathbb{R}, \\mathbf{A} \\subset \\mathbb{R}^3} \\mathcal{W}(\\mathbf{p}, \\mathbf{p_A}). \\tag{2}\\] To solve this optimization problem we will prove the following theorem.\nTheorem 1. An optimal solution of Equation 2 is a set of points \\(\\mathbf{A} = \\{a_1,\\dots, a_n\\}\\) that forms a CVT over \\(\\mathbf{p}\\), and \\(w_i = \\int_{V_i} \\mathbf{p}(x)dx\\).\nWe will prove this theorem by splitting it into two lemmas.\nLemma 1. Given a probability distribution \\(\\mathbf{p}\\), a set of points \\(\\mathbf{A} = \\{ a_1,\\dots, a_n\\} \\subset \\mathbb{R}^3\\) and the Voronoi diagram associated with \\(\\mathbf{A}\\), the weights defined as \\(w_i = \\int_{V_i} \\mathbf{p}(x)dx\\) and the transport plan \\(P^*\\) defined as \\(P^*(x,i(x)) = \\mathbf{p}(x), P^*(x,j) = 0 \\text{ (for any }j\\ne i(x)\\text{)}\\) solve Equation 1 and Equation 2.\nProof. For a fixed set of points we can combine Equation 1 and Equation 2 and write \\[\\min_{w_i \\in \\mathbb{R}, \\mathbf{A} \\subset \\mathbb{R}^3} \\mathcal{W}(\\mathbf{p}, \\mathbf{p_A}) = \\min_{P : \\mathbb{R}^3 \\times [n] \\rightarrow \\mathbb{R}_+,w_i \\in \\mathbb{R}, \\mathbf{A} \\subset \\mathbb{R}^3} \\quad  \\ \\int_{\\mathbb{R}^3} \\sum_{i=1}^n \\lVert x - a_i\\rVert^2 P(x,i)dx]^{1/2} \\tag{3}\\] \\[\\textrm{s.t.} \\quad  \\int_{\\mathbb{R}^3} P(x,i)dx = w_i, \\sum_{i=1}^n P(x_0,i) = \\mathbf{p}(x_0)\\] As \\(w_1,\\dots,w_n\\) only appear in the condition and parameters of the optimization problem Equation 3 we can ignore them and assume \\(w_i = \\int_{\\mathbb{R}^3} P(x,i)dx\\) by default. This simplifies the problem to \\[\\min_{w_i \\in \\mathbb{R}, \\mathbf{A} \\subset \\mathbb{R}^3} \\mathcal{W}(\\mathbf{p}, \\mathbf{p_A}) =\n[\\min_{P : \\mathbb{R}^3 \\times [n] \\rightarrow \\mathbb{R}_+, \\mathbf{A} \\subset \\mathbb{R}^3} \\quad  \\ \\int_{\\mathbb{R}^3} \\sum_i \\lVert x - a_i\\rVert^2 P(x,i)dx]^{1/2} \\tag{4}\\] \\[\\textrm{s.t.} \\quad  \\sum_{i=1}^n P(x_0,i) = \\mathbf{p}(x_0)\\] \\[ \\ge [\\min_{\\mathbf{A} \\subset \\mathbb{R}^3} \\int_{\\mathbb{R}^3}\\lVert x - a_{i(x)}\\rVert^2\\mathbf{p}(x)dx]^{1/2}.\\] In the last line, we use the fact that \\(x\\) is in the Voronoi cell of \\(a_{i(x)}\\), i.e., for all \\(i \\in [n]\\) we have \\(\\lVert x-a_i\\rVert \\ge \\lVert x - a_{i(x)}\\rVert\\). Take note that the last line is itself expressing the Optimal Transport problem between \\(\\mathbf{p}\\) and \\(\\mathbf{p}_\\mathbf{A}\\) with a specific choice of \\(P\\) that assigns every point \\(x\\) to \\(i(x)\\). Hence in our optimal solution, \\(P^*\\) assigns all points in \\(V_i\\) to \\(a_i\\) for all \\(i \\in [n]\\), i.e., \\(P^*(x,i(x)) = \\mathbf{p}(x)\\) and \\(P^*(x,j) = 0\\) for any \\(j \\ne i(x)\\).\nLemma 2. Given a region \\(V_i\\) and a fixed transportation plan \\(P\\) with the property that \\(P(x,i)\\) is equal to $ (x)$ for all \\(x \\in V_i\\) and \\(0\\) otherwise, \\(a_i = \\int_{V_i}x\\mathbf{p}(x)dx / \\int_{V_i}\\mathbf{p}(x)dx\\) solves Equation 2.\nProof. Assume we want to minimize the integral \\(\\int_{\\mathbb{R}^3}\\lVert x-a_i\\rVert^2P(x,i)dx\\) by choosing \\(a_i\\). First, using the assumption on \\(P\\) we can simplify it as \\[\\int_{\\mathbb{R}^3}\\lVert x-a_i\\rVert^2P(x,i)dx = \\int_{V_i}\\lVert x-a_i \\rVert^2\\mathbf{p}(x)dx\\] \\[= \\int_{V_i}[\\lVert x\\rVert^2 + \\lVert a_i \\rVert^2  - 2\\langle a_i, x \\rangle]\\mathbf{p}(x)dx\\] \\[= \\int_{V_i}\\lVert x \\rVert^2 \\mathbf{p}(x)dx + \\lVert a_i\\rVert^2\\int_{V_i}\\mathbf{p}(x)dx\\] \\[\\quad\\quad-2 \\langle a_i , \\int_{V_i} x\\mathbf{p}(x)dx\\rangle.\\] Also, as this integral is invariant to rigid body transformations, we can assume \\(\\int x\\mathbf{p}(x)dx = 0\\) (after applying an appropriate translation to \\(\\mathbf{A}\\) and \\(\\mathbf{p}\\)). This assumption yields \\[\\int_{\\mathbb{R}^3}\\lVert x-a_i \\rVert^2P(x,i)dx =\\int_{V_i}\\lVert x\\rVert^2 \\mathbf{p}(x)dx + \\lVert a_i \\rVert^2\\int_{V_i}\\mathbf{p}(x)dx.\\] The minimum of this equation is \\(a_i = 0\\), so we conclude that the optimal choice for \\(a_i\\) is the centroid of \\(V_i\\). In other words, \\(a_i = \\int_{V_i}x\\mathbf{p}(x)dx / \\int_{V_i}\\mathbf{p}(x)dx\\).\n\n\n\n\n\nReferences\n\nAurenhammer, Franz. 1991. “Voronoi Diagrams—a Survey of a Fundamental Geometric Data Structure.” ACM Computing Surveys (CSUR) 23 (3): 345–405."
  },
  {
    "objectID": "posts/elastic-metric/osteosarcoma_analysis.html",
    "href": "posts/elastic-metric/osteosarcoma_analysis.html",
    "title": "Shape Analysis of Cancer Cells",
    "section": "",
    "text": "This notebook is adapted from this notebook (Lead author: Nina Miolane).\nThis notebook studies Osteosarcoma (bone cancer) cells and the impact of drug treatment on their morphological shapes, by analyzing cell images obtained from fluorescence microscopy.\nThis analysis relies on the elastic metric between discrete curves from Geomstats. We will study to which extent this metric can detect how the cell shape is associated with the response to treatment.\nThe full papers analyzing this dataset are available at Li et al. (2023), Li et al. (2024).\nFigure 1: Representative images of the cell lines using fluorescence microscopy, studied in this notebook (Image credit : Ashok Prasad). The cells nuclei (blue), the actin cytoskeleton (green) and the lipid membrane (red) of each cell are stained and colored. We only focus on the cell shape in our analysis."
  },
  {
    "objectID": "posts/elastic-metric/osteosarcoma_analysis.html#compute-mean-cell-shape-of-the-whole-dataset-global-mean-shape",
    "href": "posts/elastic-metric/osteosarcoma_analysis.html#compute-mean-cell-shape-of-the-whole-dataset-global-mean-shape",
    "title": "Shape Analysis of Cancer Cells",
    "section": "Compute Mean Cell Shape of the Whole Dataset: “Global” Mean Shape",
    "text": "Compute Mean Cell Shape of the Whole Dataset: “Global” Mean Shape\nWe want to compute the mean cell shape of the whole dataset. Thus, we first combine all the cell shape data into a single array.\n\nCURVES_SPACE_SRV = DiscreteCurvesStartingAtOrigin(ambient_dim=2, k_sampling_points=k_sampling_points)\n\n\ncell_shapes_list = {}\nfor metric in METRICS:\n    cell_shapes_list[metric] = []\n    for treatment in TREATMENTS:\n        for line in LINES:\n            cell_shapes_list[metric].extend(ds_align[metric][treatment][line])\n\ncell_shapes = {}\nfor metric in METRICS:\n    cell_shapes[metric] = gs.array(cell_shapes_list[metric])\nprint(cell_shapes['SRV'].shape)\n\n(625, 1999, 2)\n\n\nRemove outliers using DeCOr-MDS, together for DUNN and DLM8 cell lines.\n\ndef linear_dist(cell1, cell2):\n    return gs.linalg.norm(cell1 - cell2)\n\ndef srv_dist(cell1, cell2):\n    CURVES_SPACE_SRV.equip_with_metric(SRVMetric)\n    return CURVES_SPACE_SRV.metric.dist(cell1, cell2)\n \n# compute pairwise distances, we only need to compute it once and save the results \npairwise_dists = {}\n\nif first_time:\n    metric = 'SRV'\n    pairwise_dists[metric] = parallel_dist(cell_shapes[metric], srv_dist, k_sampling_points)\n\n    metric = 'Linear' \n    pairwise_dists[metric] = parallel_dist(cell_shapes[metric], linear_dist, k_sampling_points)\n\n    for metric in METRICS:\n        np.savetxt(os.path.join(data_path, dataset_name, \"distance_matrix\", f\"{metric}_matrix.txt\"), pairwise_dists[metric])\nelse:\n    for metric in METRICS:\n        pairwise_dists[metric] = np.loadtxt(os.path.join(data_path, dataset_name, \"distance_matrix\", f\"{metric}_matrix.txt\"))\n\n\n# to remove 132 and 199\none_cell = cell_shapes['Linear'][199]\nplt.plot(one_cell[:, 0], one_cell[:, 1], c=f\"gray\")\n\n\n\n\n\n\n\n\n\n# run DeCOr-MDS\nmetric = 'SRV'\ndim_start = 2 # we know the subspace dimension is 3, we set start and end to 3 to reduce runtime \ndim_end = 10\n# dim_start = 3\n# dim_end = 3\nstd_multi = 1\nif first_time:\n    subspace_dim, outlier_indices = find_subspace_dim(pairwise_dists[metric], dim_start, dim_end, std_multi)\n    print(f\"subspace dimension is: {subspace_dim}\")\n    print(f\"outlier_indices are: {outlier_indices}\")\n\nVisualize outlier cells to see if they are artifacts\n\nif first_time:\n    fig, axes = plt.subplots(\n        nrows= 1,\n        ncols=len(outlier_indices),\n        figsize=(2*len(outlier_indices), 2),\n    )\n\n    for i, outlier_index in enumerate(outlier_indices):\n        one_cell = cell_shapes[metric][outlier_index]\n        ax = axes[i]\n        ax.plot(one_cell[:, 0], one_cell[:, 1], c=f\"C{j}\")\n        ax.set_title(f\"{outlier_index}\", fontsize=14)\n        # Turn off tick labels\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"bottom\"].set_visible(False)\n        ax.spines[\"left\"].set_visible(False)\n\n    plt.tight_layout()\n    plt.suptitle(f\"\", y=-0.01, fontsize=24)\n    # plt.savefig(os.path.join(figs_dir, \"outlier.svg\"))\n\n\ndelete_indices = [132, 199]\n\n\nfig, axes = plt.subplots(\n    nrows= 1,\n    ncols=len(delete_indices),\n    figsize=(2*len(delete_indices), 2),\n)\n\n\nfor i, outlier_index in enumerate(delete_indices):\n    one_cell = cell_shapes[metric][outlier_index]\n    ax = axes[i]\n    ax.plot(one_cell[:, 0], one_cell[:, 1], c=f\"gray\")\n    ax.set_title(f\"{outlier_index}\", fontsize=14)\n    # ax.axis(\"off\")\n    # Turn off tick labels\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n\nplt.tight_layout()\nplt.suptitle(f\"\", y=-0.01, fontsize=24)\n\nif savefig:\n    plt.savefig(os.path.join(figs_dir, \"delete_outlier.svg\"))\n    plt.savefig(os.path.join(figs_dir, \"delete_outlier.pdf\"))\n\n\n\n\n\n\n\n\nAfter visual inspection, we decide to remove the outlier cells\n\ndef remove_ds_two_layer(ds, delete_indices):\n    global_i = sum(len(v) for values in ds.values() for v in values.values())-1\n\n    for treatment in reversed(list(ds.keys())):\n        treatment_values = ds[treatment]\n        for line in reversed(list(treatment_values.keys())):\n            line_cells = treatment_values[line]\n            for i, _ in reversed(list(enumerate(line_cells))):\n                if global_i in delete_indices:\n                    print(np.array(ds[treatment][line][:i]).shape, np.array(ds[treatment][line][i+1:]).shape)\n                    if len(np.array(ds[treatment][line][:i]).shape) == 1:\n                        ds[treatment][line] = np.array(ds[treatment][line][i+1:])\n                    elif len(np.array(ds[treatment][line][i+1:]).shape) == 1:\n                        ds[treatment][line] = np.array(ds[treatment][line][:i])\n                    else:\n                        ds[treatment][line] = np.concatenate((np.array(ds[treatment][line][:i]), np.array(ds[treatment][line][i+1:])), axis=0)            \n                global_i -= 1\n    return ds\n\n\n\ndef remove_cells_two_layer(cells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align, delete_indices):\n    \"\"\" \n    Remove cells of control group from cells, cell_shapes, ds,\n    the parameters returned from load_treated_osteosarcoma_cells\n    Also update n_cells\n\n    :param list[int] delete_indices: the indices to delete\n    \"\"\"\n    delete_indices = sorted(delete_indices, reverse=True) # to prevent change in index when deleting elements\n    \n    # Delete elements\n    cells = del_arr_elements(cells, delete_indices)    \n    lines = list(np.delete(np.array(lines), delete_indices, axis=0))\n    treatments = list(np.delete(np.array(treatments), delete_indices, axis=0))\n    ds_proc = remove_ds_two_layer(ds_proc, delete_indices)\n    \n    for metric in METRICS:\n        cell_shapes[metric] = np.delete(np.array(cell_shapes[metric]), delete_indices, axis=0)\n        ds_align[metric] = remove_ds_two_layer(ds_align[metric], delete_indices)\n        pairwise_dists[metric] = np.delete(pairwise_dists[metric], delete_indices, axis=0)\n        pairwise_dists[metric] = np.delete(pairwise_dists[metric], delete_indices, axis=1)\n\n\n    return cells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align\n\n\ncells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align = remove_cells_two_layer(cells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align, delete_indices)\n\n(85, 2000, 2) (118, 2000, 2)\n(18, 2000, 2) (184, 2000, 2)\n(86, 1999, 2) (112, 1999, 2)\n(19, 1999, 2) (178, 1999, 2)\n(86, 1999, 2) (112, 1999, 2)\n(19, 1999, 2) (178, 1999, 2)\n\n\nCheck we did not loss any other cells after the removal\n\ndef check_num(cell_shapes, treatments, lines, pairwise_dists, ds_align):\n    \n    print(f\"treatments number is: {len(treatments)}, lines number is: {len(lines)}\")\n    for metric in METRICS:\n        print(f\"pairwise_dists for {metric} shape is: {pairwise_dists[metric].shape}\")\n        print(f\"cell_shapes for {metric} number is : {len(cell_shapes[metric])}\")\n        \n        for line in LINES:\n            for treatment in TREATMENTS:\n                print(f\"ds_align {treatment} {line} using {metric}: {len(ds_align[metric][treatment][line])}\")\n\n\ncheck_num(cell_shapes, treatments, lines, pairwise_dists, ds_align)\n\ntreatments number is: 623, lines number is: 623\npairwise_dists for SRV shape is: (623, 623)\ncell_shapes for SRV number is : 623\nds_align control dlm8 using SRV: 113\nds_align cytd dlm8 using SRV: 74\nds_align jasp dlm8 using SRV: 56\nds_align control dunn using SRV: 197\nds_align cytd dunn using SRV: 92\nds_align jasp dunn using SRV: 91\npairwise_dists for Linear shape is: (623, 623)\ncell_shapes for Linear number is : 623\nds_align control dlm8 using Linear: 113\nds_align cytd dlm8 using Linear: 74\nds_align jasp dlm8 using Linear: 56\nds_align control dunn using Linear: 197\nds_align cytd dunn using Linear: 92\nds_align jasp dunn using Linear: 91\n\n\nWe compute the mean cell shape by using the SRV metric defined on the space of curves’ shapes. The space of curves’ shape is a manifold: we use the Frechet mean, associated to the SRV metric, to get the mean cell shape.\nDo not include cells with duplicate points when calculating the mean shapes\n\ndef check_duplicate(cell):\n    \"\"\" \n    Return true if there are duplicate points in the cell\n    \"\"\"\n    for i in range(cell.shape[0]-1):\n        cur_coord = cell[i]\n        next_coord = cell[i+1]\n        if np.linalg.norm(cur_coord-next_coord) == 0:\n            return True\n        \n    # Checking the last point vs the first poit\n    if np.linalg.norm(cell[-1]-cell[0]) == 0:\n        return True\n    \n    return False\n\n\ndelete_indices = []\nfor metric in METRICS:\n    for i, cell in reversed(list(enumerate(cell_shapes[metric]))):\n        if check_duplicate(cell):\n            if i not in delete_indices:\n                delete_indices.append(i)\n\n\ncells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align = \\\n    remove_cells_two_layer(cells, cell_shapes, lines, treatments, pairwise_dists, ds_proc, ds_align, delete_indices)\n\nRecheck cell number after removing cells with duplicated points\n\ncheck_num(cell_shapes, treatments, lines, pairwise_dists, ds_align)\n\ntreatments number is: 623, lines number is: 623\npairwise_dists for SRV shape is: (623, 623)\ncell_shapes for SRV number is : 623\nds_align control dlm8 using SRV: 113\nds_align cytd dlm8 using SRV: 74\nds_align jasp dlm8 using SRV: 56\nds_align control dunn using SRV: 197\nds_align cytd dunn using SRV: 92\nds_align jasp dunn using SRV: 91\npairwise_dists for Linear shape is: (623, 623)\ncell_shapes for Linear number is : 623\nds_align control dlm8 using Linear: 113\nds_align cytd dlm8 using Linear: 74\nds_align jasp dlm8 using Linear: 56\nds_align control dunn using Linear: 197\nds_align cytd dunn using Linear: 92\nds_align jasp dunn using Linear: 91\n\n\n\nfrom geomstats.learning.frechet_mean import FrechetMean\n\nmetric = 'SRV'\nCURVES_SPACE_SRV = DiscreteCurvesStartingAtOrigin(ambient_dim=2, k_sampling_points=k_sampling_points)\nmean = FrechetMean(CURVES_SPACE_SRV)\nprint(cell_shapes[metric].shape)\ncells = cell_shapes[metric]\nmean.fit(cells)\n\nmean_estimate = mean.estimate_\n\n(623, 1999, 2)\n\n\n\nmean_estimate_aligned = {}\n\nmean_estimate_clean = mean_estimate[~gs.isnan(gs.sum(mean_estimate, axis=1)), :]\nmean_estimate_aligned[metric] = (\n    mean_estimate_clean - gs.mean(mean_estimate_clean, axis=0)\n)\n\nAlso we compute the linear mean\n\nmetric = 'Linear'\nlinear_mean_estimate = gs.mean(cell_shapes[metric], axis=0)\nlinear_mean_estimate_clean = linear_mean_estimate[~gs.isnan(gs.sum(linear_mean_estimate, axis=1)), :]\n\nmean_estimate_aligned[metric] =  (\n    linear_mean_estimate_clean - gs.mean(linear_mean_estimate_clean, axis=0)\n)\n\nPlot SRV mean cell versus linear mean cell\n\nfig = plt.figure(figsize=(6, 3))\n\nfig.add_subplot(121)\nmetric = 'SRV'\nplt.plot(mean_estimate_aligned[metric][:, 0], mean_estimate_aligned[metric][:, 1])\nplt.axis(\"equal\")\nplt.title(\"SRV\")\nplt.axis(\"off\")\n\nfig.add_subplot(122)\nmetric = 'Linear'\nplt.plot(mean_estimate_aligned[metric][:, 0], mean_estimate_aligned[metric][:, 1])\nplt.axis(\"equal\")\nplt.title(\"Linear\")\nplt.axis(\"off\")\n\nif savefig:\n    plt.savefig(os.path.join(figs_dir, \"global_mean.svg\"))\n    plt.savefig(os.path.join(figs_dir, \"global_mean.pdf\"))"
  },
  {
    "objectID": "posts/quasiconformalmap/index.html#theorem",
    "href": "posts/quasiconformalmap/index.html#theorem",
    "title": "Quasiconformal mapping for shape representation",
    "section": "Theorem",
    "text": "Theorem"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html",
    "href": "posts/ribosome-tunnel-new/index.html",
    "title": "3D tessellation of biomolecular cavities",
    "section": "",
    "text": "We present a protocol to extract the surface of a biomolecular cavity for shape analysis and molecular simulations.\nWe apply and illustrate the protocol on the ribosome structure, which contains a subcompartment known as the ribosome exit tunnel. More details on the tunnel features and biological importance can be found in our previous works1,2. The protocol was also design to refine the output obtained from MOLE software3\n\n\n\nIllustration of the ribosome exit tunnel (from Dao Duc et al., NAR 2019)"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html#summary-and-background",
    "href": "posts/ribosome-tunnel-new/index.html#summary-and-background",
    "title": "3D tessellation of biomolecular cavities",
    "section": "",
    "text": "We present a protocol to extract the surface of a biomolecular cavity for shape analysis and molecular simulations.\nWe apply and illustrate the protocol on the ribosome structure, which contains a subcompartment known as the ribosome exit tunnel. More details on the tunnel features and biological importance can be found in our previous works1,2. The protocol was also design to refine the output obtained from MOLE software3\n\n\n\nIllustration of the ribosome exit tunnel (from Dao Duc et al., NAR 2019)"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html#data-preparation",
    "href": "posts/ribosome-tunnel-new/index.html#data-preparation",
    "title": "3D tessellation of biomolecular cavities",
    "section": "0. Data preparation",
    "text": "0. Data preparation"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html#pre-processing",
    "href": "posts/ribosome-tunnel-new/index.html#pre-processing",
    "title": "3D tessellation of biomolecular cavities",
    "section": "1. Pre-processing",
    "text": "1. Pre-processing"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html#voxelization",
    "href": "posts/ribosome-tunnel-new/index.html#voxelization",
    "title": "3D tessellation of biomolecular cavities",
    "section": "2. Voxelization",
    "text": "2. Voxelization"
  },
  {
    "objectID": "posts/ribosome-tunnel-new/index.html#tessellation",
    "href": "posts/ribosome-tunnel-new/index.html#tessellation",
    "title": "3D tessellation of biomolecular cavities",
    "section": "3. Tessellation",
    "text": "3. Tessellation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biological shape analysis (under construction)",
    "section": "",
    "text": "Welcome to MATH 612\n\n\nInstructions and tips for MATH 612 students\n\n\n\nMATH 612\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHorizontal Diffusion Map\n\n\n\n\n\n\ntheory\n\n\n\n\n\n\n\n\n\nAug 30, 2024\n\n\nWenjun Zhao\n\n\n\n\n\n\n\n\n\n\n\n\nOrthogonal outlier detection and dimension estimation for improved MDS embedding of biological datasets\n\n\n\n\n\n\nbiology\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nAug 29, 2024\n\n\nWanxin Li\n\n\n\n\n\n\n\n\n\n\n\n\nCentroidal Voronoi Tessellation\n\n\nRelations with Semidiscrete Wasserstein distance\n\n\n\ntheory\n\n\n\n\n\n\n\n\n\nAug 26, 2024\n\n\nAryan Tajmir Riahi\n\n\n\n\n\n\n\n\n\n\n\n\nRiemannian elastic metric for curves\n\n\n\n\n\n\nbiology\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nWanxin Li\n\n\n\n\n\n\n\n\n\n\n\n\nShape Analysis of Cancer Cells\n\n\n\n\n\n\nbiology\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nWanxin Li\n\n\n\n\n\n\n\n\n\n\n\n\nPoint cloud representation of 3D volumes\n\n\nApplication to cryoEM density maps\n\n\n\nbiology\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nAryan Tajmir Riahi, Khanh Dao Duc\n\n\n\n\n\n\n\n\n\n\n\n\nMulti Dimensional Scaling of ribosome exit tunnel shapes\n\n\nAnalyze and compare the geometry of the ribosome exit tunnel\n\n\n\ncryo-EM\n\n\nribosome\n\n\nMDS\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nShiqi Yu, Artem Kushner, Khanh Dao Duc\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation of tomograms of membrane-embedded spike proteins\n\n\n\n\n\n\ncryo-ET\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nQiyu Wang\n\n\n\n\n\n\n\n\n\n\n\n\nAlpha Shapes in 2D and 3D\n\n\n\n\n\n\ntheory\n\n\n\n\n\n\n\n\n\nAug 14, 2024\n\n\nWenjun Zhao\n\n\n\n\n\n\n\n\n\n\n\n\nQuasiconformal mapping for shape representation\n\n\n\n\n\n\ntheory\n\n\n\n\n\n\n\n\n\nAug 9, 2024\n\n\nClément Soubrier\n\n\n\n\n\n\n\n\n\n\n\n\n3D tessellation of biomolecular cavities\n\n\nProtocol for analyzing the ribosome exit tunnel\n\n\n\nexample\n\n\ncryo-EM\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\nArtem Kushner, Khanh Dao Duc\n\n\n\n\n\n\n\n\n\n\n\n\nAlignment of 3D volumes with Optimal Transport\n\n\nApplication to cryoEM density maps\n\n\n\nexample\n\n\ncryo-EM\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\nAryan Tajmir Riahi, Khanh Dao Duc\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Eye Tracking Data\n\n\n\n\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\nLisa\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting cell geometry from Atomic Force Microscopy\n\n\nPart 1: Static analysis\n\n\n\nbiology\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\nClément Soubrier, Khanh Dao Duc\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/ET/ey.html",
    "href": "posts/ET/ey.html",
    "title": "Analysis of Eye Tracking Data",
    "section": "",
    "text": "Eye Tracking\n\nEye tracking (ET) is a process by which a device measures the gaze of a participant – with a number of variables that can be captured, such as duration of fixation, re-fixation (go-backs), saccades, blinking, pupillary response. The ‘strong eye-mind hypothesis’ provides the theoretical ground where the underlying assumption is that duration of fixation is a reflection of preference, and that information is processed with immediacy. ET also is a non-invasive technique that has recently garnered attention in autism research as a method to elucidate or gather more information about the supposed central cognitive deficit (Flack-Ytter et al., 2013, Senju et al., 2009).\n\nExperimental set up\n\n22 youth (13-17) with high functioning autism and without autism will be recruited into this study.Students will be brought into a quiet room and asked to read a manga comic displayed on a monitor connected to the eye tracking device (Tobii pro eye tracker, provided by Professor Conati’s lab)"
  },
  {
    "objectID": "posts/ET/ey.html#eye-tracking-backagroud",
    "href": "posts/ET/ey.html#eye-tracking-backagroud",
    "title": "Analysis of Eye Tracking Data",
    "section": "",
    "text": "Eye Tracking\n\nEye tracking (ET) is a process by which a device measures the gaze of a participant – with a number of variables that can be captured, such as duration of fixation, re-fixation (go-backs), saccades, blinking, pupillary response. The ‘strong eye-mind hypothesis’ provides the theoretical ground where the underlying assumption is that duration of fixation is a reflection of preference, and that information is processed with immediacy. ET also is a non-invasive technique that has recently garnered attention in autism research as a method to elucidate or gather more information about the supposed central cognitive deficit (Flack-Ytter et al., 2013, Senju et al., 2009).\n\nExperimental set up\n\n22 youth (13-17) with high functioning autism and without autism will be recruited into this study.Students will be brought into a quiet room and asked to read a manga comic displayed on a monitor connected to the eye tracking device (Tobii pro eye tracker, provided by Professor Conati’s lab)"
  },
  {
    "objectID": "posts/ET/ey.html#visualisation",
    "href": "posts/ET/ey.html#visualisation",
    "title": "Analysis of Eye Tracking Data",
    "section": "2 Visualisation",
    "text": "2 Visualisation\nOne way of visualizing your data in Tobii Pro Lab is by creating Heat maps. Heat maps visualize where a participant’s (or a group of participants’) fixations or gaze data samples were distributed on a still image or a video frame. The distribution of the data is represented with colors.Each sample corresponds to a gaze point from the eye tracker, consistently sampled every 1.6 to 33 milliseconds (depending on the sampling data rate of the eye tracker). When using an I-VT Filter, it will group the raw eye tracking samples into fixations. The duration of each fixation depends on the gaze filter used to identify the fixations.\n\n\n\nHeatmap"
  },
  {
    "objectID": "posts/ET/ey.html#features",
    "href": "posts/ET/ey.html#features",
    "title": "Analysis of Eye Tracking Data",
    "section": "3 Features",
    "text": "3 Features\n\nData processing of eye tracking recordings\n\nTo run a statistical study on the data recorded, we carried out in two stages data processing. First using Tobio Pro Lab, then the EMADAT package. Following the experiments, the files are processed using Tobii Pro Lab software. We delimited the AOI for each page, manually pointed the gazes points for the 22 participants on the 12 selected pages. Then exported the data for each participant in a tsv format.\nThen EMDAT was used to generate the datasets. Indeed, to extract the gaze features we used EMDAT python 2.7. EMDAT stands for Eye Movement Data Analysis Toolkit, it is an open-source toolkit developed by our group. EMDAT receives three types of input folder: a folder containing the recordings from Tobii in a tsv format, a Segment folder containing the timestamp for the start and end of page reading for each participant, and an AOI folder containing the coordinates and the time spent per participant of each AOI per page. We have also automated the writing of the Segments and AOIs folders. Then we run the EMDAT script for each page. EMDAT also validates the quality of the recordings per page, here the parameter has been set to VALIDITY_METHOD = 1 (see documentation). In particular, we found that the quality of the data did not diminish over the course of the recordings.\n\nEye tracking features\n\nUpon following the data processing protocol, we extracted the following features:\n\nnumber of fixation (quantitative feature): The number of fixations denoted by is defined as the total number of fixations recorded over the total duration spent on a page by a participant.\nmean fixation duration (duration feature): The mean fixation duration denoted by is defined as as the average fixation duration during page reading.\nstandard deviation of the relative path angle (spatial feature): The standard deviation of the relative path angle denoted by is defined as as the average fixation duration during page reading.the standard deviation of the relative angle between two successive saccades. This component enables us to capture the consistency of a participant’s gaze pattern. The greater the standard deviation, the more likely the participant is to look across the different areas of a page."
  },
  {
    "objectID": "posts/ET/ey.html#t-test",
    "href": "posts/ET/ey.html#t-test",
    "title": "Analysis of Eye Tracking Data",
    "section": "4 T-test",
    "text": "4 T-test\nFirst, we wondered whether there were any major differences in the way the two groups read. To do this, we compared the two populations along the three axes - quantitative, duration and spatial - defined in the previous section. To quantify these differences, we used a t-test to compare the means of the distributions, and a Kolmogorov-Smirnov test to compare the distributions. Concerning the total number of fixations per page, the two populations seem to have the same characteristics (p-value&gt;0.1 and Cohen’s d=0.2) and to be from the same distribution (two sided K-s test p-value&gt;0.1). However, on the other two criteria, the autistic adolescents had a shorter mean fixation time and a lower standard deviation (p-value&lt;0.05, Cohen’s d &gt; 0.5), and their associated distribution was lower than that of the control population (less K-S test p-value&gt;0.1).\n\n\n\n\n\n\n\n\n\nT-test\nK-S test\n\n\n\n\nNum fixations\nNo statistically significant differences in the mean number of fixation (small effect size, two-sided p-value &gt; 0.1)\nThe distributions of the number of fixations per page look similar across the two populations (KS two-sided p-value &gt; 0.1)\n\n\nMean fixation duration\nND seems to have a shorter mean duration fixation (Negative medium effect size, two-sided p-value &lt; 0.01)\nThe ND mean fixation duration distribution is smaller than the NT mean fixation duration distribution (KS less p-value &gt; 0.1)\n\n\nStandard deviation relative path angle\nND seems to have on average a smaller std (Negative medium effect size, two-sided p-value &lt; 0.01)\nThe ND std relative path angle distribution is smaller than the NT std relative path angle distribution (KS less p-value &gt; 0.1)"
  },
  {
    "objectID": "posts/elastic-metric/elastic_metric.html",
    "href": "posts/elastic-metric/elastic_metric.html",
    "title": "Riemannian elastic metric for curves",
    "section": "",
    "text": "This page introduces basic concepts of elastic metric, square root velocity metric, geodesic distance and Fréchet mean associated with it."
  },
  {
    "objectID": "posts/point-cloud/pointcloud.html",
    "href": "posts/point-cloud/pointcloud.html",
    "title": "Point cloud representation of 3D volumes",
    "section": "",
    "text": "In the context of cryo-EM, many computationally exhaustive methods rely on simpler representations of cryo-EM density maps to overcome their scalability challenges. There are many choices for the form of the simpler representation, such as vectors (Han et al. 2021) or a mixture of Gaussians (Kawabata 2008). In this post, we discuss a format that is probably the simplest and uses a set of points (called a point cloud).\nThis problem can be formulated in a much more general sense rather than cryo-EM. In this sense, we are given a probability distribution over \\(\\mathbb{R}^3\\) and we want to generate a set of 3D points that represent this distribution. The naive approach for finding such a point cloud is to just sample points from the distribution. Although this approach is guaranteed to find a good representation, it needs many points to cover the distribution evenly. Since methods used in this field can be computationally intensive with cubic or higher time complexity, generating a point cloud that covers the given distribution with a smaller point-cloud size leads to a significant improvement in their runtime.\nIn this approach, we present two methods for generating a point cloud from a cryo-EM density map or a distribution in general. The first one is based on the Topological Representing Network (TRN) (Martinetz and Schulten 1994) and the second one combines the usage of the Optimal Transport (OT) (Peyré, Cuturi, et al. 2019) theory and a computational geometry object named Centroidal Voronoi Tessellation (CVT).\n\n\nFor the sake of simplicity in this post, we assume we are given a primal distribution over \\(\\mathbb{R}^2\\). As an example, we will work on a multivariate Gaussian distribution that it’s domain is limited to \\([0, 1]^2\\). The following code prepares and illustrates the pdf of the example distribution.\n\nimport numpy as np\nimport scipy as scp\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\n\n\nmean = np.array([0,0])\ncov = np.array([[0.5, 0.25], [0.25, 0.5]])\ndistr = scp.stats.multivariate_normal(cov = cov, mean = mean, seed = 1)\n\n\nfig, ax = plt.subplots(figsize=(8,8))\nim = ax.imshow([[distr.pdf([i/100,j/100]) for i in range(100,-100,-1)] for j in range(-100,100)], extent=[-1, 1, -1, 1])\ncbar = ax.figure.colorbar(im, ax=ax)\nplt.title(\"The pdf of our primal distribution\")\nplt.show()\n\n\n\n\n\n\n\n\nBoth of the methods that we are going to cover are iterative methods relying on an initial sample of points. For generating a point cloud with size \\(n\\), they begin by randomly sampling \\(n\\) points and refining it over iterations. We use \\(n=200\\) in our examples.\n\ndef sampler(rvs):\n    while True:\n        sample = rvs(1)\n        if abs(sample[0]) &gt; 1 or abs(sample[1]) &gt; 1:\n            continue\n        return sample\n\ninitial_samples = []\nwhile len(initial_samples) &lt; 200:\n    sample = sampler(distr.rvs)\n    initial_samples.append(list(sample))\ninitial_samples = np.array(initial_samples)\n\nl = list(zip(*initial_samples))\nx = list(l[0])\ny = list(l[1])\n\nfig, ax = plt.subplots(figsize=(8,8))\nax.scatter(x, y)\nax.plot((-1,-1), (-1,1), 'k-')\nax.plot((-1,1), (-1,-1), 'k-')\nax.plot((1,1), (1,-1), 'k-')\nax.plot((-1,1), (1,1), 'k-')\nplt.ylim(-1.1,1.1)\nplt.xlim(-1.1,1.1)\nplt.xticks([])\nplt.yticks([])\nplt.show()"
  },
  {
    "objectID": "posts/point-cloud/pointcloud.html#data",
    "href": "posts/point-cloud/pointcloud.html#data",
    "title": "Point cloud representation of 3D volumes",
    "section": "",
    "text": "For the sake of simplicity in this post, we assume we are given a primal distribution over \\(\\mathbb{R}^2\\). As an example, we will work on a multivariate Gaussian distribution that it’s domain is limited to \\([0, 1]^2\\). The following code prepares and illustrates the pdf of the example distribution.\n\nimport numpy as np\nimport scipy as scp\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (20,20)\n\n\n\nmean = np.array([0,0])\ncov = np.array([[0.5, 0.25], [0.25, 0.5]])\ndistr = scp.stats.multivariate_normal(cov = cov, mean = mean, seed = 1)\n\n\nfig, ax = plt.subplots(figsize=(8,8))\nim = ax.imshow([[distr.pdf([i/100,j/100]) for i in range(100,-100,-1)] for j in range(-100,100)], extent=[-1, 1, -1, 1])\ncbar = ax.figure.colorbar(im, ax=ax)\nplt.title(\"The pdf of our primal distribution\")\nplt.show()\n\n\n\n\n\n\n\n\nBoth of the methods that we are going to cover are iterative methods relying on an initial sample of points. For generating a point cloud with size \\(n\\), they begin by randomly sampling \\(n\\) points and refining it over iterations. We use \\(n=200\\) in our examples.\n\ndef sampler(rvs):\n    while True:\n        sample = rvs(1)\n        if abs(sample[0]) &gt; 1 or abs(sample[1]) &gt; 1:\n            continue\n        return sample\n\ninitial_samples = []\nwhile len(initial_samples) &lt; 200:\n    sample = sampler(distr.rvs)\n    initial_samples.append(list(sample))\ninitial_samples = np.array(initial_samples)\n\nl = list(zip(*initial_samples))\nx = list(l[0])\ny = list(l[1])\n\nfig, ax = plt.subplots(figsize=(8,8))\nax.scatter(x, y)\nax.plot((-1,-1), (-1,1), 'k-')\nax.plot((-1,1), (-1,-1), 'k-')\nax.plot((1,1), (1,-1), 'k-')\nax.plot((-1,1), (1,1), 'k-')\nplt.ylim(-1.1,1.1)\nplt.xlim(-1.1,1.1)\nplt.xticks([])\nplt.yticks([])\nplt.show()"
  },
  {
    "objectID": "posts/HDM/index.html",
    "href": "posts/HDM/index.html",
    "title": "Horizontal Diffusion Map",
    "section": "",
    "text": "This post is based on the following references:\n\nShan Shan, Probabilistic Models on Fibre Bundles (https://dukespace.lib.duke.edu/server/api/core/bitstreams/21bc2e06-ee66-4331-83af-115fe9518e80/content)\nTingran Gao, The Diffusion Geometry of Fibre Bundles: Horizontal Diffusion Maps (https://arxiv.org/pdf/1602.02330)"
  },
  {
    "objectID": "posts/HDM/index.html#references",
    "href": "posts/HDM/index.html#references",
    "title": "Horizontal Diffusion Map",
    "section": "",
    "text": "This post is based on the following references:\n\nShan Shan, Probabilistic Models on Fibre Bundles (https://dukespace.lib.duke.edu/server/api/core/bitstreams/21bc2e06-ee66-4331-83af-115fe9518e80/content)\nTingran Gao, The Diffusion Geometry of Fibre Bundles: Horizontal Diffusion Maps (https://arxiv.org/pdf/1602.02330)"
  },
  {
    "objectID": "posts/HDM/index.html#introduction",
    "href": "posts/HDM/index.html#introduction",
    "title": "Horizontal Diffusion Map",
    "section": "Introduction",
    "text": "Introduction\nHorizontal Diffusion Maps are a variant of diffusion maps used in dimensionality reduction and data analysis. They focus on preserving the local structure of data points in a lower-dimensional space by leveraging diffusion processes. Here’s a simple overview:\n\nDiffusion Maps Overview\n\nDiffusion Maps: These are a powerful technique in machine learning and data analysis for reducing dimensionality and capturing intrinsic data structures. They are based on the concept of diffusion processes over a graph or data manifold.\nConcept: Imagine a diffusion process where particles spread out over a data set according to some probability distribution. The diffusion map captures the way these particles spread and organizes the data into a lower-dimensional space that retains the local and global structure.\n\nHorizontal Diffusion Maps\n\nPurpose: Horizontal Diffusion Maps specifically aim to capture and visualize the horizontal or local structure of the data manifold. This can be particularly useful when you want to emphasize local relationships while reducing dimensionality.\nDifference from Standard Diffusion Maps: While standard diffusion maps focus on capturing both local and global structures, horizontal diffusion maps emphasize local, horizontal connections among data points. This means they preserve local neighborhoods and horizontal relationships more explicitly."
  },
  {
    "objectID": "posts/HDM/index.html#example-möbius-strip",
    "href": "posts/HDM/index.html#example-möbius-strip",
    "title": "Horizontal Diffusion Map",
    "section": "Example: Möbius Strip",
    "text": "Example: Möbius Strip\nIn this section, we show how horizontal diffusion map works on Möbius Strip parameterized by:\n\\[\nx = (1 + v\\cos(\\frac{u}{2}))\\cos(u),\\quad y= (1 + v\\cos(\\frac{u}{2}))\\sin(u),\n\\] for \\(u\\in [0,2\\pi)\\) and \\(v \\in [-1,1]\\).\nIt is known as one of the most simple yet nontrivial fibre bundle. See below for a visualization:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef mobius_strip(u, v):\n    \"\"\"\n    Generate coordinates for a Möbius strip.\n    \n    Parameters:\n    - u: Parameter that varies from 0 to 2*pi\n    - v: Parameter that varies from -0.5 to 0.5\n    \n    Returns:\n    - x, y, z: Coordinates of the Möbius strip\n    \"\"\"\n    # Parameters for the Möbius strip\n    radius = 1.0\n    width = 1.0\n    \n    # Compute coordinates\n    x = (radius + width * v * np.cos(u / 2)) * np.cos(u)\n    y = (radius + width * v * np.cos(u / 2)) * np.sin(u)\n    z = width * v * np.sin(u / 2)\n    \n    return x, y, z\n\ndef plot_mobius_strip():\n    u = np.linspace(0, 2 * np.pi, 100)\n    v = np.linspace(-1, 1, 10)\n    \n    u, v = np.meshgrid(u, v)\n    x, y, z = mobius_strip(u, v)\n    \n    fig = plt.figure(figsize=(10, 7))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    # Plot the Möbius strip\n    ax.plot_surface(x, y, z, cmap='inferno', edgecolor='none')\n    \n    # Set labels and title\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    ax.set_title('Möbius Strip')\n    \n    plt.show()\n\n# Run the function to plot the Möbius strip\nplot_mobius_strip()\n\n\n\n\n\n\n\n\nNow we generate samples from the surface uniformly by first sample \\(N_{base}\\) points on the `base manifold’, parameterized by the \\(v\\) component. Then we sample \\(N_{fibre}\\) points along each fibre:\n\nN_fibre = 20\nv = np.linspace(-1,1,N_fibre,endpoint=False) #samples on each fibre\nN_base = 50\nu = np.linspace(0,2*np.pi,N_base,endpoint=False) #different objects\n# Here we concatenate all fibres to create the overall object\nV = np.tile(v,len(u))\nU= np.array([num for num in u for _ in range(len(v)) ])\nN = U.shape[0]\n\nHere we visualize the points to see how they are distributed on the manifold:\n\nu, v = np.meshgrid(U,V)\nx, y, z = mobius_strip(u, v)\n    \nfig = plt.figure(figsize=(10, 7))\nax = fig.add_subplot(111, projection='3d')\n    \n# Plot the Möbius strip\nax.scatter(x, y, z, c=v, s=1)\n    \n# Set labels and title\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\nax.set_title('Möbius Strip')\n    \nplt.show()\n\n\n\n\n\n\n\n\nLater on, we will go over the horizontal diffusion map and apply it to the data we just created!"
  },
  {
    "objectID": "posts/HDM/index.html#horizontal-diffusion-map-hdm",
    "href": "posts/HDM/index.html#horizontal-diffusion-map-hdm",
    "title": "Horizontal Diffusion Map",
    "section": "Horizontal diffusion map (HDM)",
    "text": "Horizontal diffusion map (HDM)\nThe first step is to create a kernel matrix. As outlined by the references, two common approaches are:\nHorizontal diffusion kernel:  For two data points \\(e=(u,v)\\) and \\(e' = (u',v')\\): \\[\nK_{\\epsilon}(e, e') = \\exp( -(u - u')^2/\\epsilon) \\text{ if }v' = P_{uu'}v,\n\\] and zero otherwise. Here \\(P_{uu'}\\) is the map which connects every point from \\(v\\) to its image \\(v'\\), which, for our case, maps \\(v\\) to itself.\n\ndef horizontal_diffusion_kernel(U,V,eps):\n    \n    N = U.shape[0]\n    K = np.zeros((N,N))\n    for i in range(N):\n        for j in range(N):\n            if V[i] == V[j]:# and U[i] != U[j]:\n                #print('match')\n                K[i,j] = np.exp(-(U[i]-U[j])**2/eps)\n    return K\n\neps = 0.2\nK = horizontal_diffusion_kernel(U,V,0.2)\nplt.imshow(K)\nplt.show()\n\n\n\n\n\n\n\n\nAn alternative, soft version of the kernel above is the coupled diffusion kernel: \n\\[\nK_{\\epsilon, \\delta}(e,e') = \\exp( -(u - u')^2/\\epsilon) \\exp( -(v-v')^2/\\delta ).\n\\]\n\ndef coupled_diffusion_kernel(U,V,eps,delta):\n    N = U.shape[0]\n    K_c = np.zeros((N,N))\n    for i in range(N):\n        for j in range(N):\n            if True:#U[i] != U[j]:\n                #print('match')\n                K_c[i,j] = np.exp(-(U[i]-U[j])**2/eps) * np.exp( -(V[i]-V[j])**2/delta )\n    return K_c\n\neps = .2\ndelta = .01  \nK_c = coupled_diffusion_kernel(U,V,eps,delta)   \nplt.imshow(K_c)\nplt.show()\n\n\n\n\n\n\n\n\nAfter we created the kernel matrix, we can then proceed with the regular diffusion map by (1) Create the diffusion operator by normalizing the kernel matrix and computing its eigendecomposition, and (2) extract the diffusion coordinates by using the eigenvectors corresponding to the largest eigenvalues (excluding the trivial eigenvalue) to form the diffusion coordinates.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import eigh\nfrom sklearn.preprocessing import normalize\n\ndef compute_diffusion_map(kernel_matrix, num_components=2):\n    \"\"\"\n    Compute the diffusion map from a kernel matrix.\n\n    Parameters:\n    - kernel_matrix: The kernel matrix (e.g., RBF kernel matrix).\n    - num_components: Number of diffusion map dimensions to compute.\n\n    Returns:\n    - diffusion_coordinates: The 2D diffusion map coordinates.\n    \"\"\"\n    # Compute the degree matrix\n    degree_matrix = np.diag(np.sum(kernel_matrix, axis=1))\n    \n    # Compute the normalized Laplacian matrix\n    laplacian = np.linalg.inv(degree_matrix) @ kernel_matrix\n    \n    # Compute eigenvalues and eigenvectors\n    eigvals, eigvecs = eigh(laplacian)\n    \n    # Sort eigenvalues and eigenvectors\n    sorted_indices = np.argsort(eigvals)[::-1]\n    eigvals = eigvals[sorted_indices]\n    #print(eigvals)\n    eigvecs = eigvecs[:, sorted_indices]\n    \n    # Take the first `num_components` eigenvectors (excluding the first one which is trivial)\n    diffusion_coordinates = eigvecs[:, 1:num_components+1] @ np.diag(np.sqrt(eigvals[1:num_components+1]))\n    \n    return diffusion_coordinates\n\n\ndef plot_diffusion_map(diffusion_coordinates,color):\n    \"\"\"\n    Plot the 2D diffusion map.\n\n    Parameters:\n    - diffusion_coordinates: The 2D diffusion map coordinates.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    plt.scatter(diffusion_coordinates[:, 0], diffusion_coordinates[:, 1], c=color, s=10, alpha=0.7)\n    plt.title('2D Diffusion Map')\n    plt.xlabel('Dimension 1')\n    plt.ylabel('Dimension 2')\n    plt.grid(True)\n    plt.show()\n\nNow project the data points into a lower-dimensional space defined by the significant diffusion coordinates. This projection helps in visualizing and analyzing the local structure of the data.\n\n# Compute the diffusion map\neps = 0.2\nK = horizontal_diffusion_kernel(U,V,eps)\ndiffusion_coordinates = compute_diffusion_map( K, num_components=2)\n#print(diffusion_coordinates)\n# Plot the 2D diffusion map, where color represents where they were on the fibre. Points that are mapped \nplot_diffusion_map(diffusion_coordinates,V)\n\n\n\n\n\n\n\n\nSimilarly we perform the same procedure for the coupled diffusion matrix:\n\n# Compute the diffusion map\neps = 0.2\ndelta = 0.01\nK_c = coupled_diffusion_kernel(U,V,eps,delta)\n\ndiffusion_coordinates = compute_diffusion_map( K_c, num_components=2)\n#print(diffusion_coordinates)\n# Plot the 2D diffusion map\nplot_diffusion_map(diffusion_coordinates,V)\n#plot_diffusion_map(diffusion_coordinates,U)\n\n\n\n\n\n\n\n\nThe points are colored according to their correspondence on all the fibres through component \\(v\\). If two points correspond to each other across different but nearby fibres, they are likely to be neighbors in the visualization above."
  },
  {
    "objectID": "posts/HDM/index.html#horizontal-base-diffusion-map-hbdm",
    "href": "posts/HDM/index.html#horizontal-base-diffusion-map-hbdm",
    "title": "Horizontal Diffusion Map",
    "section": "Horizontal base diffusion map (HBDM)",
    "text": "Horizontal base diffusion map (HBDM)\nIn addition to embed all the data points, the framework also allows for embedding different objects (fibres). The new kernel is defined as the Frobenius norm of all entries in the previous kernel matrix that correspond to the two fibres:\n\neps = .2\nK = horizontal_diffusion_kernel(U,V,eps)\nK_base = np.zeros( (N_base,N_base) )\nfor i in range(N_base):\n    for j in range(N_base):\n        #print( np.ix_( range(N_fibre*(i),N_fibre*(i+1)), range(N_fibre*(j),N_fibre*(j+1)) ) )\n        K_base[i,j] = np.linalg.norm( K[ np.ix_( range(N_fibre*(i),N_fibre*(i+1)), range(N_fibre*(j),N_fibre*(j+1)) ) ] ,'fro')\n#plt.imshow(K_base)\n#plt.show()\n\n\n# Compute the diffusion map\ndiffusion_coordinates = compute_diffusion_map( K_base, num_components=2)\n\n# Plot the 2D diffusion map\n\nplot_diffusion_map(diffusion_coordinates, np.sort(list(set(list(U)) ) ) )\n\n\n\n\n\n\n\n\nThe embedded points are colored according to the `ground truth’ \\(u\\). The smooth color transition shows that the embedding uncovers the information of all fibres on the base manifold."
  },
  {
    "objectID": "posts/HDM/index.html#applications-in-shape-data",
    "href": "posts/HDM/index.html#applications-in-shape-data",
    "title": "Horizontal Diffusion Map",
    "section": "Applications in shape data",
    "text": "Applications in shape data\nThe horizontal diffusion map framework is particularly useful in the two following espects, both demonstrated in Gao et al.:\n\nHorizontal diffusion map (embedding all data points): The embedding automatically suggests a global registration for all fibres that respects a mutual similarity measure.\nHorizontal base diffusion map (embedding all data objects/fibres): Compared to the classical diffusion map without correspondences, the horizontal base diffusion map is more robust to noises and often demonstrate a clearer pattern of clusters."
  },
  {
    "objectID": "posts/AlphaShape/index.html",
    "href": "posts/AlphaShape/index.html",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "",
    "text": "Alpha shapes are a generalization of the convex hull used in computational geometry. They are particularly useful for understanding the shape of a point cloud in both 2D and 3D spaces. In this document, we will explore alpha shapes in both dimensions using Python.\nWhat is \\(\\alpha\\) shape? My favorite analogy (reference https://doc.cgal.org/latest/Alpha_shapes_2/index.html):\nImagine you have a huge mass of ice cream in either 2D or 3D, and the points are “hard” chocolate pieces which we would like to avoid. Using one of these round-shaped ice-cream spoons with radius \\(1/\\alpha\\), we carve out all the ice cream without bumping into any of the chocolate pieces. Finally we straighten the round boundaries to obtain the so-called \\(\\alpha\\) shape.\nWhat is the \\(\\alpha\\) parameter? \\(1/\\alpha\\) is the radius of your “carving spoon” and controls the roughness of your boundary. If the radius of spoon is too small (\\(\\alpha\\to \\infty\\)), all the ice cream can be carved out except the chocolate chips themselves, so eventually all data points become singletons and no information regarding the shape can be revealed. However, choosing big radius (\\(\\alpha \\approx 0\\)) may not be ideal either because it does not allow carving out anything, so we end up with a convex hull of all data points."
  },
  {
    "objectID": "posts/AlphaShape/index.html#introduction",
    "href": "posts/AlphaShape/index.html#introduction",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "",
    "text": "Alpha shapes are a generalization of the convex hull used in computational geometry. They are particularly useful for understanding the shape of a point cloud in both 2D and 3D spaces. In this document, we will explore alpha shapes in both dimensions using Python.\nWhat is \\(\\alpha\\) shape? My favorite analogy (reference https://doc.cgal.org/latest/Alpha_shapes_2/index.html):\nImagine you have a huge mass of ice cream in either 2D or 3D, and the points are “hard” chocolate pieces which we would like to avoid. Using one of these round-shaped ice-cream spoons with radius \\(1/\\alpha\\), we carve out all the ice cream without bumping into any of the chocolate pieces. Finally we straighten the round boundaries to obtain the so-called \\(\\alpha\\) shape.\nWhat is the \\(\\alpha\\) parameter? \\(1/\\alpha\\) is the radius of your “carving spoon” and controls the roughness of your boundary. If the radius of spoon is too small (\\(\\alpha\\to \\infty\\)), all the ice cream can be carved out except the chocolate chips themselves, so eventually all data points become singletons and no information regarding the shape can be revealed. However, choosing big radius (\\(\\alpha \\approx 0\\)) may not be ideal either because it does not allow carving out anything, so we end up with a convex hull of all data points."
  },
  {
    "objectID": "posts/AlphaShape/index.html#d-alpha-shape",
    "href": "posts/AlphaShape/index.html#d-alpha-shape",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "2D Alpha Shape",
    "text": "2D Alpha Shape\nTo illustrate alpha shapes in 2D, we’ll use the alphashape library. Let’s start by generating a set of random points and compute their alpha shape.\nFirst we create a point cloud:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport alphashape\nfrom matplotlib.path import Path\nfrom scipy.spatial import ConvexHull\n\ndef generate_flower_shape(num_petals, num_points_per_petal):\n    angles = np.linspace(0, 2 * np.pi, num_points_per_petal, endpoint=False)\n    r = 1 + 0.5 * np.sin(num_petals * angles)\n    \n    x = r* np.cos(angles)\n    \n    y = r * np.sin(angles)\n    \n    return np.column_stack((x, y))\n\ndef generate_random_points_within_polygon(polygon, num_points):\n    \"\"\"Generate random points inside a given polygon.\"\"\"\n    min_x, max_x = polygon[:, 0].min(), polygon[:, 0].max()\n    min_y, max_y = polygon[:, 1].min(), polygon[:, 1].max()\n    \n    points = []\n    while len(points) &lt; num_points:\n        x = np.random.uniform(min_x, max_x)\n        y = np.random.uniform(min_y, max_y)\n        if Path(polygon).contains_point((x, y)):\n            points.append((x, y))\n    \n    return np.array(points)\n\nplt.figure(figsize=(8, 6))\npoints = generate_flower_shape(num_petals=6, num_points_per_petal=100)\npoints = generate_random_points_within_polygon(points, 1000)\nplt.scatter(points[:, 0], points[:, 1], s=10, color='blue', label='Points')\n\n/Users/wenjunzhao/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning:\n\nA NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.3\n\n\n\n\n\n\n\n\n\n\nTry run this with \\(\\alpha=0.1\\):\n\n# Create alpha shape\nalpha = 0.1\nalpha_shape = alphashape.alphashape(points, alpha)\n\n# Plot points and alpha shape\nplt.figure(figsize=(8, 6))\nplt.scatter(points[:, 0], points[:, 1], s=10, color='blue', label='Points')\nplt.plot(*alpha_shape.exterior.xy, color='red', lw=2, label='Alpha Shape')\nplt.title('2D Alpha Shape')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nOops, it seems the radius we picked is too big! Let’s try a few other choices.\n\nalpha_values = [0.1, 5.0, 10.0, 15.0]\n# Plot the flower shape and alpha shapes with varying alpha values\nfig, axes = plt.subplots(2, 2, figsize=(6,6))\naxes = axes.flatten()\n\nfor i, alpha in enumerate(alpha_values):\n    # Compute alpha shape\n    alpha_shape = alphashape.alphashape(points, alpha)\n    \n    # Plot the points and the alpha shape\n    ax = axes[i]\n    #print(alpha_shape.type)\n    if alpha_shape.type == 'Polygon':\n        ax.plot(*alpha_shape.exterior.xy, color='red', lw=2, label='Alpha Shape')\n    ax.scatter(points[:, 0], points[:, 1], color='orange', s=10, label='Point Cloud')\n    \n    \n    \n    ax.set_title(f'Alpha Shape with alpha={alpha}')\n    ax.legend()\n    ax.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/k7/s0t_zwg11h56xb5xp339s5pm0000gp/T/ipykernel_29951/885549844.py:13: ShapelyDeprecationWarning:\n\nThe 'type' attribute is deprecated, and will be removed in the future. You can use the 'geom_type' attribute instead."
  },
  {
    "objectID": "posts/AlphaShape/index.html#application-of-2d-alpha-shapes-on-reaction-diffusion-equation",
    "href": "posts/AlphaShape/index.html#application-of-2d-alpha-shapes-on-reaction-diffusion-equation",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "Application of 2D alpha shapes on reaction-diffusion equation",
    "text": "Application of 2D alpha shapes on reaction-diffusion equation\nNow we discuss an application of 2D alpha shape on quantifying the patterns that arise in reaction-diffusion equations modeling morphogenesis.\nReference: Zhao, Maffa, Sandstede. http://bjornsandstede.com/papers/Data_Driven_Continuation.pdf\nAs an example, let’s consider the Brusselator model in 2D, and below is a simple simulator that generates the snapshot of its solution over the spatial domain. The initial condition is random, and patterns start to arise after we evolve the system forward for a short time.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef brusselator_2d_simulation(A, B, Lx=100, Ly=100, Nx=100, Ny=100, dt=0.005, D_u=4, D_v=32, T=20):\n    \"\"\"\n    Simulate the 2D Brusselator model and return the concentration field u at time T.\n    \n    Parameters:\n    - A: Reaction parameter A\n    - B: Reaction parameter B\n    - Lx: Domain size in x direction\n    - Ly: Domain size in y direction\n    - Nx: Number of grid points in x direction\n    - Ny: Number of grid points in y direction\n    - dt: Time step\n    - D_u: Diffusion coefficient for u\n    - D_v: Diffusion coefficient for v\n    - T: Total simulation time\n    \n    Returns:\n    - u: Concentration field u at time T\n    \"\"\"\n    \n    # Generate random points\n    np.random.seed(0)  # For reproducibility\n\n    # Initialize variables\n    dx, dy = Lx / Nx, Ly / Ny\n    u = np.random.uniform(size=(Nx, Ny))\n    v = np.zeros((Nx, Ny))\n    \n    \n    # Prepare the grid\n    x = np.linspace(0, Lx, Nx)\n    y = np.linspace(0, Ly, Ny)\n    \n    # Compute Laplacian\n    def laplacian(field):\n        return (np.roll(field, 1, axis=0) + np.roll(field, -1, axis=0) +\n                np.roll(field, 1, axis=1) + np.roll(field, -1, axis=1) -\n                4 * field) / (dx * dy)\n    \n    # Time-stepping loop\n    num_steps = int(T / dt)\n    for _ in range(num_steps):\n        # Compute Laplacian\n        lap_u = laplacian(u)\n        lap_v = laplacian(v)\n        \n        # Brusselator model equations\n        du = D_u * lap_u + A - (B + 1) * u + u**2 * v\n        dv = D_v * lap_v + B * u - u**2 * v\n        \n        # Update fields\n        u += du * dt\n        v += dv * dt\n    \n    return u, x, y\n\n# Example usage\nA = 4.75\nB = 11.0\nu_at_T, x, y = brusselator_2d_simulation(A, B)\n\n# Plot the result\nplt.figure(figsize=(8, 8))\nplt.imshow(u_at_T, cmap='viridis', interpolation='bilinear', origin='lower')\nplt.colorbar(label='Concentration of u')\nplt.title(f'Concentration of u at T=100 with A={A}, B={B}')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nNow we create point cloud via thresholding the solution:\n\ndef get_threshold_points(u, threshold=0.7):\n    \"\"\"\n    Get grid points where the concentration field u exceeds the specified threshold.\n    \n    Parameters:\n    - u: Concentration field\n    - threshold: The threshold value as a percentage of the maximum value in u\n    \n    Returns:\n    - coords: Array of grid points where u exceeds the threshold\n    \"\"\"\n    max_u = np.max(u)\n    threshold_value = threshold * max_u\n    coords = np.argwhere(u &gt; threshold_value)\n    return coords\n\n# Get grid points above 70% of the maximum value\ncoords = get_threshold_points(u_at_T, threshold=0.7)\n# Highlight points above threshold\nx_coords, y_coords = coords[:, 1], coords[:, 0]\nplt.scatter(x_coords, y_coords, color='red', s=20, marker='o', edgecolor='w')\n\n\n\n\n\n\n\n\nAfter we obtain the point cloud, now we can run alpha shape on it. As mentioned before, picking a good alpha can be tricky, so let’s try a few alpha values to see which one identifies the boundary in an ideal way.\n\nalpha_values = [.3, 0.35, 0.5, 1.]\n# Plot the flower shape and alpha shapes with varying alpha values\nfig, axes = plt.subplots(2, 2, figsize=(6,6))\naxes = axes.flatten()\n\nfor i, alpha in enumerate(alpha_values):\n    # Scatter the plot\n    \n    # Compute alpha shape\n    alpha_shape = alphashape.alphashape(coords, alpha)\n    #print(alpha_shape.type)\n    # Plot the points and the alpha shape\n    plt.subplot(2,2,i+1)\n    #ax = axes[i]\n    \n    if alpha_shape.geom_type == 'GeometryCollection':\n        print(alpha_shape)\n        for geom in list( alpha_shape.geoms ):\n            \n            if geom.type == 'Polygon':\n                x, y = geom.exterior.xy\n                plt.plot(x, y, 'r-')\n    elif alpha_shape.geom_type == 'Polygon':\n                x, y = alpha_shape.exterior.xy\n                plt.plot(x, y, 'r-')\n    elif alpha_shape.geom_type == 'MultiPolygon':\n        \n        alpha_shape = list( alpha_shape.geoms )\n        for polygon in alpha_shape:\n            x, y = polygon.exterior.xy\n            plt.plot(x, y, 'r-')#, label='Alpha Shape')\n    plt.scatter(coords[:, 0], coords[:, 1], color='orange', s=10, label='Point Cloud')\n    \n    \n    \n    plt.title(f'alpha={alpha}')\n    #plt.legend()\n    #plt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nNow we can study different pattern statistics for these clusters! For example, the roundness of clusters are defined as \\(4\\pi Area/Perimeter^2\\), which is bounded between zero (stripe) and one (spot). For each cluster, a roundness score value can be computed. The resulting histogram of roundness scores of all clusters will follow a bimodal distribution, with its two peaks correspond to spots and stripes, respectively.\n\nalpha_values = [.3, 0.4, 0.6, 1.]\n# Plot the flower shape and alpha shapes with varying alpha values\nfig, axes = plt.subplots(2, 2, figsize=(6,6))\naxes = axes.flatten()\n\nfor i, alpha in enumerate(alpha_values):\n    plt.subplot(2,2,i+1)\n    # Compute alpha shape\n    alpha_shape = alphashape.alphashape(coords, alpha)\n    if alpha_shape.geom_type == 'MultiPolygon':\n        # Extract and print the area of each polygon\n        areas = [polygon.area for polygon in list(alpha_shape.geoms)]\n        perimeters = [polygon.length for polygon in list(alpha_shape.geoms)]\n        roundness = [4*np.pi*areas[i]/perimeters[i]**2 for i in range(len(list(alpha_shape.geoms))) ]\n    else:\n        areas = [ alpha_shape.area ]\n        perimeters = [alpha_shape.length]\n        roundness = [areas[0]*4*np.pi/perimeters[0]**2]\n    plt.hist(roundness,density=True, range=[0,1])\n    plt.xlim([0,1])\n    plt.title(f'Roundness with alpha={alpha}')\n    \n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/AlphaShape/index.html#d-alpha-shapes",
    "href": "posts/AlphaShape/index.html#d-alpha-shapes",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "3D Alpha shapes",
    "text": "3D Alpha shapes\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef plot_torus_with_random_points(R1=1.0, r1=0.3, R2=0.8, r2=0.3, num_points=1000):\n    \"\"\"\n    Plots a torus with random points filling its volume.\n\n    Parameters:\n    R (float): Major radius of the torus.\n    r (float): Minor radius of the torus.\n    num_points (int): Number of random points to generate inside the torus.\n    \"\"\"\n    \n    # Generate random points\n    np.random.seed(0)  # For reproducibility\n    theta = np.random.uniform(0, 2 * np.pi, num_points)  # Angle around the major circle\n    phi = np.random.uniform(0, 2 * np.pi, num_points)    # Angle around the minor circle\n    u = np.random.uniform(0, 1, num_points)              # Random uniform distribution for radial distance\n    \n    # Convert uniform distribution to proper volume inside the torus\n    u = np.sqrt(u)  # To spread points more evenly\n\n    # Parametric equations for the double torus\n    # First torus\n    x1 = .5*(R1 + r1 * np.cos(phi)) * np.cos(theta)\n    y1 = (R1 + r1 * np.cos(phi)) * np.sin(theta)\n    z1 = r1 * np.sin(phi)\n    \n    # Second torus\n    x2 = -1 + .5*(R2 + r2 * np.cos(phi)) * np.cos(theta)\n    y2 = (R2 + r2 * np.cos(phi)) * np.sin(theta)\n    z2 = r2 * np.sin(phi)# + 2 * (R2 + r2 * np.cos(phi)) * np.sin(theta)  # Shifted in z-direction for double torus effect\n\n    # Combine points from both tori\n    x = np.concatenate([x1, x2])\n    y = np.concatenate([y1, y2])\n    z = np.concatenate([z1, z2])\n\n      \n\n    # Plot the torus and the random points\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Plot the random points\n    ax.scatter(x, y, z, c='red', s=1, label='Random Points')  # Using a small point size for clarity\n\n\n    # Add titles and labels\n    ax.set_title('Torus with Random Points')\n    ax.set_xlabel('X axis')\n    ax.set_ylabel('Y axis')\n    ax.set_zlabel('Z axis')\n    #ax.set_xlim([-1.5,0.5])\n    #ax.set_ylim([-0.5,1.5])\n    ax.set_zlim([-1.5,1.5])\n    ax.legend()\n    plt.show()\n    return x,y,z\n\n# Example usage\nx, y, z = plot_torus_with_random_points(num_points=2000)\n\n\n\n\n\n\n\n\nThe intuition on picking alpha still holds! Let’s first try a big alpha (small radius and refined boundaries) and then a small one (big radius and rough boundaries)\n\nimport alphashape\n\n\nalpha_shape = alphashape.alphashape(np.column_stack((x,y,z)), 5.0)\nalpha_shape.show()\n\n\n\n\n\nalpha_shape = alphashape.alphashape(np.column_stack((x,y,z)), 3.0)\nalpha_shape.show()"
  },
  {
    "objectID": "posts/AlphaShape/index.html#application-of-3d-alpha-shape-protein-structure",
    "href": "posts/AlphaShape/index.html#application-of-3d-alpha-shape-protein-structure",
    "title": "Alpha Shapes in 2D and 3D",
    "section": "Application of 3D alpha shape: protein structure",
    "text": "Application of 3D alpha shape: protein structure\nIt would be ideal to find some good data and put them here. To be continued."
  },
  {
    "objectID": "posts/MATH-612/index.html#preliminaries",
    "href": "posts/MATH-612/index.html#preliminaries",
    "title": "Welcome to MATH 612",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nJupyter: Use Jupyter Notebooks for interactive coding and documentation. Great for running small code snippets and visualizing data. Learn more in the Jupyter Notebook Documentation.\nVS Code: A powerful IDE for writing and debugging code. Download it here, and install relevant extensions for Python and LaTeX.\nEnvironments: Use virtual environments like venv or conda to manage dependencies and ensure consistent results across different setups.\nQuarto: Use Quarto for creating high-quality documents, reports, and presentations from your code. It supports markdown and integrates seamlessly with Jupyter and VS Code for reproducible analysis and publication. Check out the Quarto Guide for more information. To get started quickly, you can refer to this GitHub Repository."
  },
  {
    "objectID": "posts/MATH-612/index.html#using-github",
    "href": "posts/MATH-612/index.html#using-github",
    "title": "Welcome to MATH 612",
    "section": "Using GitHub",
    "text": "Using GitHub\n\nCreate a GitHub Account: Sign up at GitHub.com.\nRepositories: Start by creating a repository to host your project files. Learn how in GitHub’s guide to repositories. Use a .gitignore file to exclude unnecessary files.\nBranches: Work on separate branches (main, dev, feature branches) to manage different versions of your project. More details in GitHub’s guide on branching.\nMerges: Merge changes into the main branch only after thorough review and testing. Learn about merging branches.\nCommit Messages: Write clear, descriptive commit messages to document changes effectively. Follow the best practices for commit messages."
  },
  {
    "objectID": "posts/MATH-612/index.html#using-quarto-to-create-blog-posts",
    "href": "posts/MATH-612/index.html#using-quarto-to-create-blog-posts",
    "title": "Welcome to MATH 612",
    "section": "Using Quarto to create blog posts",
    "text": "Using Quarto to create blog posts\n\nLog into GitHub: Make sure you have an account and are logged in.\nSend your account username/email to kdd@math.ubc.ca: This is needed to be added to the organization.\nClone the repository: After being added to the organization, clone the repository: https://github.com/bioshape-analysis/blog.\ngit clone https://github.com/bioshape-analysis/blog\nCreate a new branch: To contribute to the blog, create a new branch using:\ngit checkout -b &lt;branch_name&gt;\n\nVerify your branch and repository location: Use the following command to check if you are in the correct branch and repository:\ngit status\nThis command will show you the current branch you are on and the status of your working directory, ensuring you are working in the right place\n\nNavigate to posts: Go into the posts directory (found here). Create a new folder with a name that represents the content of your blog post.\nCreate or upload your content:\n\nIf using Jupyter Notebooks, upload your .ipynb file.\nIf preferred, create a new notebook for your post. Once done, convert it into Quarto using the command:\nquarto convert your_jupyter_notebook.ipynb -o output_file.qmd\n\nEdit the YAML in your .qmd file: Ensure your YAML is consistent with the main template. For example:\n---\ntitle: \"Title of your blog post\"\ndate: \"Date\" # Format example: August 9 2024\nauthor:\n  - name: \"Your Name\" \ncategories: [] # [biology, bioinformatics, theory, etc.]\nbibliography: references.bib # If referencing anything\n---\nFeel free to add further formatting, but ensure it remains consistent with the main template.\nDelete your Jupyter notebook: After converting it to a .qmd file, delete the original .ipynb file to prevent duplication in the blog post.\nCommit and push your changes: After completing your .qmd file, push your branch to GitHub. A pull request will be automatically created, and once reviewed, it will be merged into the main branch.\n\nAnatomy of a Quarto Document: \n\nAdditional Information for Quarto:\n\nAdd Images: You can add images to your Quarto document using markdown syntax:\n![Image Description](path/to/image.png)\nTo add images from a URL:\n![Image Description](https://example.com/image.png)\nAdd References: Manage references by creating a bibliography.bib file with your references in BibTeX format. Link the bibliography file in your Quarto document header (YAML). Cite references in your text using the following syntax:\nThis is a citation [@citation_key].\nOther Edits: Add headers, footnotes, and other markdown features as needed. Customize the layout by editing the YAML header."
  },
  {
    "objectID": "posts/MATH-612/index.html#multiple-environments-in-the-same-quarto-project",
    "href": "posts/MATH-612/index.html#multiple-environments-in-the-same-quarto-project",
    "title": "Welcome to MATH 612",
    "section": "Multiple environments in the same Quarto project",
    "text": "Multiple environments in the same Quarto project\nIn your blog post, you may want to use specific python packages, which may conflict with packages used in other post. To avoid this problem, you need to use a virtual environment. For simplicity please name your environment .venv.\n\nCreating the virtual environment: Go to your post folder (e.g blog/posts/my_post) and run :\npython -m venv .venv\nThe folder .venv was created and contains the environment.\nInstalling packages: First activate the environment,\nsource .venv/bin/activate\nand then install the packages you need:\npip install package1_name package2_name\nTo run code in Quarto, you need at least the package jupyter. Deactivate the environment with deactivate.\nUsing environment in VS Code: Link the virtual environment to VS Code using the command palette, with the command Python : Select Interpreter and entering the path to your interpreter ending with .venv/bin/python.\nExport your package requirements If you are installed non standard package, other that jupyter, numpy, matplotlib, pandas, plotly for example, you can export your package requirements, so that other can reproduce your environment. First go to your post directory and activate your environment. Then run:\npip freeze &gt; requirements.txt"
  },
  {
    "objectID": "posts/cryo_ET/demo.html",
    "href": "posts/cryo_ET/demo.html",
    "title": "Simulation of tomograms of membrane-embedded spike proteins",
    "section": "",
    "text": "Cryogenic electron tomography (cryo-ET) is an imaging technique to reconstruct high-resolution 3d structure, usually of biological macromolecules. Samples (usually small cells like bacteria and viruses) are prepared in standard aqueous median (unlike cryo-EM, where samples are frozen) are imaged in transmission electron microscope (TEM). The samples are tilted to different angles (e.g. from \\(-60^\\circ\\) to \\(+60^\\circ\\)), and images are obtained at every incremented degree (usually every \\(1^\\circ\\) or \\(2^\\circ\\)).\nThe main advantage of cryo-ET is that it allows the cells and macromolecules to be imaged at undisturbed state. This is very crucial in many applications such as drug discovery, when we need to know the in-situ binding state of the target of interest (e.g. viral spike protein) with the drug.\n\n\n\nTomographic slices of SARS-CoV-2 virions, with spike proteins embedded in the membrane(Shi et al. 2023)\n\n\nIn order to reconstruct macromolecules, tomographic slices need to be processed through a pipeline. A typical cryo-ET data processing pipeline includes: tilt series alignment, CTF estimation, tomogram reconstruction, particle picking, iterative subtomogram alignment and averaging, and heterogeneity analysis. Unlike cryo-EM, many algorithms for cryo-ET processing are still under development. Therefore, a large database of cryo-ET to test and tune algorithms is important. Unfortunately, collecting cryo-ET data is both time and money-consuming, and the current database of cryo-ET is not large enough, especially for deep learning training which requires a large amount of data. Therefore, simulation becomes a substitute to generate a large amount of data in a short time and at low expense. In this post, we will focus on the simimulation of membrane-embedded proteins."
  },
  {
    "objectID": "posts/cryo_ET/demo.html#background",
    "href": "posts/cryo_ET/demo.html#background",
    "title": "Simulation of tomograms of membrane-embedded spike proteins",
    "section": "",
    "text": "Cryogenic electron tomography (cryo-ET) is an imaging technique to reconstruct high-resolution 3d structure, usually of biological macromolecules. Samples (usually small cells like bacteria and viruses) are prepared in standard aqueous median (unlike cryo-EM, where samples are frozen) are imaged in transmission electron microscope (TEM). The samples are tilted to different angles (e.g. from \\(-60^\\circ\\) to \\(+60^\\circ\\)), and images are obtained at every incremented degree (usually every \\(1^\\circ\\) or \\(2^\\circ\\)).\nThe main advantage of cryo-ET is that it allows the cells and macromolecules to be imaged at undisturbed state. This is very crucial in many applications such as drug discovery, when we need to know the in-situ binding state of the target of interest (e.g. viral spike protein) with the drug.\n\n\n\nTomographic slices of SARS-CoV-2 virions, with spike proteins embedded in the membrane(Shi et al. 2023)\n\n\nIn order to reconstruct macromolecules, tomographic slices need to be processed through a pipeline. A typical cryo-ET data processing pipeline includes: tilt series alignment, CTF estimation, tomogram reconstruction, particle picking, iterative subtomogram alignment and averaging, and heterogeneity analysis. Unlike cryo-EM, many algorithms for cryo-ET processing are still under development. Therefore, a large database of cryo-ET to test and tune algorithms is important. Unfortunately, collecting cryo-ET data is both time and money-consuming, and the current database of cryo-ET is not large enough, especially for deep learning training which requires a large amount of data. Therefore, simulation becomes a substitute to generate a large amount of data in a short time and at low expense. In this post, we will focus on the simimulation of membrane-embedded proteins."
  },
  {
    "objectID": "posts/cryo_ET/demo.html#workflow",
    "href": "posts/cryo_ET/demo.html#workflow",
    "title": "Simulation of tomograms of membrane-embedded spike proteins",
    "section": "Workflow",
    "text": "Workflow\nWe will use the Membrane Embedded Proteins Simulator (MEPSi), a tool incorporated in PyCoAn to simulate SARS-CoV-2 spike protein (Rodríguez de Francisco et al. 2022). Here, I will briefly go through the workflow of MEPSi.\n\n1. Density modeling\nIn the density modeling, atom coordinate lists of macromolecules of interest are given, and a “ground-truth” volume representation is simulated by placing the given macromolecules on the membrane with specified geometry. The algorithm uses a 3D Archimedean spiral to place the molecules at approximately equidistant points along the membrane. Random translations with sa bounding box defined by the equidistance and the maximum XY radius of the molecules will then be applied. This ensures there is no overlap between macromolecules on the surface. The volume is generated using direct generation of membrane density and Gaussian convolution of the atom positions.\nOptionally, a solvent model can be generated and added to the density. In order to keep the computational cost low, a continuum solvent model with an adjustable contrast tuning parameter is used. A 3D version of Lapacian pyramid blending is used to account for displacements of one object from another to mitigate edge effects and emulates the existence of a hydration layer around the molecules.\n\n\n2. Basis tilt series generation\nIn this step, an unperturbed basis tilt series is generated from the simulated volume. The individual tilt images are obtained by rotating the volume around the Y axis and projecting the density along Z axis. The reason that a basis tilt series is generated before final tomogram simulation is to reduce computational cost. It can speed up the process quite a lot if a perturbation-free basis tilt series is first generated to allow the user explore perturbation parameters (e.g. contrast transfer function and noise) before generating final tomograms from perturbed basis tilt series.\n\n\n3. CTF\nOne possible perturbation we can add to the basis tilt series is the contrast transfer function (CTF), which models the effect of the microscope optics. One major determinant of the CTF is the defocus value at the scattering event, which changes while the electrons traverse the specimen. In order to simplify the problem, we assume that the simulated specimen as an infinitely thin slice so only focus changes caused by tilting need to be considered. Projected tilted specimen images are subjected to a CTF model in strips parallel to the tilt axis with the defocus value modulated according to the position of the strip center.\n\n\n4. Noise\nThe noise model is expressed as a mixture of Gaussian and Laplacian, in contrast of white additive Gaussian usually used in many other simulation applications. The noise in the low-dose images contrivuting to a tilt series tends to have statistically significant non-zero skewness, which cannot be modeled by Gaussian error model alone.\n\n\n\nOverlay of an experimental intensity histogram (blue) with noise modeling by Gaussian only (red) vs. with a mix of Gaussian and Laplacian noise (green)\n\n\n\n\n5. Tomogram generation\nFinally tomograms are simulated from the perturbed basis tilt series with user-specified tilt range and increment."
  },
  {
    "objectID": "posts/cryo_ET/demo.html#results",
    "href": "posts/cryo_ET/demo.html#results",
    "title": "Simulation of tomograms of membrane-embedded spike proteins",
    "section": "Results",
    "text": "Results\nIn order to fully demonstrate the capacity of MEPSi, tomograms were simulated from a sample containing three different conformations of SARS-Cov2 spike protein: 6VXX, 6VYB and 6X2B, with ratio 1:1:2. Protein coordinate files in .pdb format were obtained from RCSB PDB, and preprocessed in ChimeraX to align with z-axies in order to be modeled in orrect direction in density simulation.\n\n\n\nThree conformations of the prefusion trimer of SARS-Cov2 spike protein: all RBDs in the closed position (left, 6VXX); one RBD in the open position (center, 6VYB); two RBDs in the open position (right, 6X2B)\n\n\nSolvent and CTF were added. A SNR of 0.5 was used. Finally we generated tomograms every \\(1^\\circ\\) from \\(-60^\\circ\\) to \\(+60^\\circ\\). Below were four tomograms with different tilt angles simulated."
  }
]